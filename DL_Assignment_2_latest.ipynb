{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_Assignment_2_Latest.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Diksha Srivastava\n",
        "### Student id: 21235117"
      ],
      "metadata": {
        "id": "6Vo4n8p4qDsM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 1"
      ],
      "metadata": {
        "id": "zTMAq85xCKPj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xuqLsaFY94Ja"
      },
      "outputs": [],
      "source": [
        "# importing libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "%matplotlib inline\n",
        "import random\n",
        "\n",
        "import keras\n",
        "from keras import layers\n",
        "from keras import regularizers\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.losses import mse\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.layers import Input, Dense, BatchNormalization\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.models import Sequential, Model\n",
        "from keras.optimizers import adam_v2 \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loading google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "data_dir = \"gdrive/My Drive/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmGB2N7Y-FlJ",
        "outputId": "fa894e56-bae9-4ad9-e48e-6d12c2b085ed"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset\n",
        "\n",
        "For the assignment, I have chosen Fashion mnist dataset. It consists images of various fashion products like shirts, bag, shoes etc.\n",
        "\n",
        "This dataset consist of Zalando's article images. It consist of 60,000 training and 10,000 test set. Each image is a gray-scale image of 28*28 dimension. The images also have labels but we don't use it for this task. The pixel values lies in the range 0 to 255. \n",
        "\n",
        "### Steps to use dataset\n",
        "\n",
        "1. Download the dataset from the URL:  https://www.kaggle.com/datasets/zalando-research/fashionmnist\n",
        "\n",
        "2. The dataset has two CSV files, one for training set and the other for test set. The first column contains label which we discard. The other columns contain pixel value and hence contains 784 (28*28) columns.\n",
        "\n",
        "3. We also plot 9 samples from the image dataset using matplotlib library.\n",
        "\n",
        "### Application\n",
        "\n",
        "New samples generated from Fashion dataset can be used in recommendation system on e-commerce platforms. Recommendation system allows for personalised user-experience. These system recommends pants, shirts, tops, and bags etc. according to user preference and also helps user to discover new items in their 'You may also like/people also like' section. Not only this, people also want to mix and match different categories of product according to their liking. Example, recommending a bag along with a dress. Hence, an interactive fashion product application which can utilise VAE/GAN produced latent space which has new samples similar to users interest/search history can be recommended to users. "
      ],
      "metadata": {
        "id": "smuK5RUwvagL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# reading dataset\n",
        "X_train = pd.read_csv(data_dir + \"fashion-mnist_train.csv\")\n",
        "X_test = pd.read_csv(data_dir + \"fashion-mnist_test.csv\")"
      ],
      "metadata": {
        "id": "Hi85AzIE96zH"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# removing label column from dataset.\n",
        "del X_train['label']\n",
        "# converting train data to numpy array.\n",
        "X_train = X_train.values\n",
        "\n",
        "# removing labels from test set.\n",
        "del X_test['label'] \n",
        "# converting test data to numpy array.  \n",
        "X_test = X_test.values"
      ],
      "metadata": {
        "id": "_pZeVrSzAnkJ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_images(X):\n",
        "  ''' This function plots 9 images from the fashion-mnist dataset.'''\n",
        "  # plot images\n",
        "  for i in range(9):\n",
        "    # creating a subplot of 9 images.\n",
        "    plt.subplot(331 + i)\n",
        "    # keeping the cmap and reverse gray.\n",
        "    plt.imshow(X[i], cmap = plt.get_cmap('gray_r'))\n",
        "    # removing the axis as we only need to see images.\n",
        "    plt.axis('off')\n",
        "  plt.show()\n",
        "\n",
        "plot_images(X_train.reshape(60000, 28, 28))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "jGVDCtF6bDX6",
        "outputId": "60eab3f0-0f94-4c3b-ac43-577ec6385d50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 9 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAToAAADnCAYAAACOlZoZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOx92W9k53H96X1fuTSby+yrbMmWZDmxrBgxjNhBAghJgBgBEiAPechDkD8mQJC3AEmQvBkOLGSxYdiOI1mRJdsaSaNZOMMZLk32vu99u2//Hvg7xeo7Tc5wmZHNuQcgOMPebt97v/qqTp2qcozHY9iwYcPGaYbzsz4AGzZs2HjasA2dDRs2Tj1sQ2fDho1TD9vQ2bBh49TDNnQ2bNg49XA/5vHnPSXr+KwP4CnBvq6nF8e6tsPhEADgcrngcDx6mlqtFn784x9je3sbPp8PXq8Xo9EIhmHANE15vdvthtPpRL1eR61Ww8WLF/Enf/IniEajewc6HoOqD/52uVwTj087hsdg6gseZ+hs2LDxHMHhcGCa5Mw0TQwGA3S7XfR6PfT7fQC7xogGbjQaYTQaYTweYzgcwul0ot/vYzAYoNfrodPpwOPxwOfzwel0Hvh5Jw3b0NmwYUOgDZBGLpfD22+/jWKxiPfffx+FQgF+vx9erxeBQACRSASmaaLb7WI4HKJWq6HdbsM0TYxGI9y/fx/VahXz8/P45je/iZWVFfmMZ2HsbENnw4YNwX6hYr1ex0cffYRsNotPPvkEpVIJgUAAPp8PkUgECwsLGI/HaDQaMAwDmUwG9XodbrcbHo8H5XIZhmFgcXERX/7yl7GysvLYzz1C2LovbENnw4YNALv8XKPRQL/fRyaTQbVaRbvdRqPRQD6fx9raGprNJrxeL5LJpHh/fr8fkUgEwK5HOBgM0Gw2YZom/H6/GMRut4t8Po/vfve7eOedd5BKpTAzM4N4PI50Og2v14tIJDLB050UbENnw4YNALuGrlQqoV6v4+2338b9+/eRzWaxubkJ0zRhmiacTiei0SjC4TAMw4BhGAiFQojFYnA4HPB6vWLoRqMRotEootEoRqMRms2meIaGYeCVV17BCy+8gPPnz+PLX/4yIpEIAoHAr6+hO2x2ZDgcotPpwDRN+ZvX64XH45nIxPA9mdFpt9totVrweDyIRCJwu90IBoNwu217bcPGUdFut1Eul9FoNHD37l3U63VsbW2hVCqh0WhgNBoB2PXWHA6HGD3DMNDr9dBut1EqlQDsrtXhcIh+vw/DMCQ5AeyucQDw+XwYj8fodDrI5/NwuVwIBoOIRqNot9sIhUKYn58XL/Ek4HgMCfhYhtA0TYzHYzkJT4JGo4G1tTUMBgM4HA44HA5xYUejEYbDIRwOB1wul8T93W4Xa2truHPnDhKJBF544QVEIhFcuHBhImV9wjitMgRbXnJ6cehru7q6ip/+9KfI5/P42c9+hmq1isFggNFoJGva6XTC6/VOrHHtePAxPt7tdjEYDBCPx5FMJuF2u8UhabVa4ryMx2N4vV74fD5Eo1Fcu3YNMzMz+P3f/318/vOfP8r3f7bykvF4jH6/j9FohF6vh+FwKF+sXq9je3tbvix3Ccb8fD0zNvl8HvV6HZlMBjs7O+h2u4jH4+LVxWIx+Hw++Hw+eDweBIPBp/W1bNg4dSB3VigUUKlUUK/XxWi53W7R1FkdGTpJ9OKAPR0cnRUAso5p6OjA0OsbDocYDocYj8coFAoYjUbodrtiaLVdOCqObeicTufU0LXdbuP27duoVqv41a9+hc3NTXFz6fIOh0OJ5d944w288soriMVimJ+fR6/Xw9raGur1Ot577z08fPhQXGG/34+f//zncDqdMAwDAPDSSy/h+vXruHTpEr761a/C4/Ec96vZsPFcoFQq4Ze//CXq9ToAIBgMinGjw6ENHh0Ut9uNUCgkOrnRaCT6upmZGYRCIXg8HjFkfIzRn3ZOwuEwxuMxMpkMyuUystksqtUqAoEAQqHQsb/jiXh0NHLk10ajkcTfhUIBn376Ke7evYtms4lmsylW2jAMVKtVDIdDpFIpLCwsYDAYIBQKod1uY3t7G6VSCR9//DHu3LkjX9rlcqFQKMA0TRSLRXGzGev3er3dL+d2n2iK2sazg6ZU7Gv4dMD1So+u2+1OhKHEaDSC0+kUz4qvo8fHaE0bOqfTiUAgAGCP3iIn7/V65f2cTqdkZg3DQLlcRr/fR6vVkuM5CZxY6NpoNNBqtXD79m386Ec/EoKz2+1ifX0dlUpFuDz+uFwuxONxjMdjESSeP38eXq9XTn6lUkEgEEA6nZayEo1AIACv14tMJoNut4s7d+7g/fffRzqdxh/8wR9gfn4esVgMfr//pL6qjacM6rDa7TaSySRisRjcbjd8Pt9nfWinBuPxGDs7OygUClhfX0e/38dwOITb7RZnhdETkwJMQvDf5NE9Ho94fPT6wuGwXC+n04nRaCQGj6Bx1AaTEeLGxgZCoRAuXryIaDR67M3uxLKurVZLVNP/8A//gG63i1AoJF9gPB6Lq8o0NN3X8XiMUqmE7e1tDAYDnD17FoPBAOVyGfV6HT6fD6lUSlxglqPo1+fzeWxsbEg5yrVr13D58mW4XC74/X7b0H2GOKx3NhwOsb29jXK5jNFoBI/HIyp827s7GZAPu3PnjvDl5NkAyFoLhUKIRCISpenX07gNh0N4vV5Z4/TS+G+Hw/FIeRiNHL3Ffr8/ocLY3t6Gw+FANBo9as3rBE7M0D148AA3btzA/fv35Yb0+/1wu92yE+hCYcMwxLPj39xuNyqVCj788EMMh0Nks1n0+/2JVDV3BYa/brcbo9FI3OHhcIjBYIBOp4O3334bGxsb+Na3voVYLHYSX9XGEfCkN6mmPR4+fIitrS34fD7E4/ETIaRtTIJRV6vVEiNDKclwOJxIFHD9Mirjv7V8RCcsuAb5N4fDAY/HI2sWAHq9njgsGqZpotPpoF6vo9vtnsh3PRFDZ5om3n//ffzrv/6rcGzArmLa5XI9cvJo1a1f3uFwIJPJ4NNPPxW+jbsDDabmBgiXyyVucq/XQ7fbRbVaxT/+4z8iGo1iZWUFL7zwwkl8VRtPEaZpot/vo16v4/3338enn36KYDCIdDoNh8OBRCJhe3QnhPF4jFqtJno5Rl00XoZhoN/vSwE/jZvD4cBgMJDIiZ4ZQaPW6XTQ7XYnqifi8Tg8Ho/w7PV6XTw6gga3VqthPB6j2WyeSB3ssQydaZqo1+tot9uoVCpotVri0urUMkEvbJorqlPZurBYv8+0Xd36Pm63G16vF4ZhoNvtotPpoFAoIJPJIBKJ2J7drzF6vR52dnaQz+fRbrcxHA5Rr9eRy+XgcDiQSqXkHrFxfAyHQ/GqrHA6neKEAHtyLx1NMVxlVKbF/lzHfMx6zbi2+Th/+DwmNrQRPQ6OZegYHm5ubuLmzZuo1+vw+/0SV3e73UeqH0KhEMbjsXh2+oty1wiHwwD2uhowlifxSVExxYYOh0NOCqslGBq73W68++67qFQq+MpXvoKvf/3rdhh0QjjpzGg2m8V3vvMdFItF1Go1+P1+6Xrx0ksvIZVKIRgMIhQKTb2G0/qbHUbI/ryh2+2iVquh2+1OnCOXy4VIJDLBpXPN8XG3241AIAC/3z8hF2s0GjBNE7FYDIFAYKr2TnuBXKM0isyy0mtkFve4OJahG41GKBQK2NraQr1eF+PjdDofybAAEItN70x7drwhPR7PhBen09JaPMjQV7d64fuQr+N7lUolPHz4EFevXn0mva9sHA5cRM1mE9lsFqVSSTYt6i5XVlYwGAwk+UQ87nqeBJF9WkFtGw2YPk90OqweHbDXVJNSFGCP2yN3R6eEa5TODd/Let1oM7Rzw98ngSc2dNNumF6vhxs3buAXv/gF6vW6FOTyCzHTqclKK3nJk0ErPy1e5wnX7rF1R2cZCdvCkOMbjUZYXV3FgwcPcPHiRXS7XXi9XrlA+303G4/H487Zfh6ftZZ5fX0dt2/fRiaTQalUQrfbFc1ko9FApVJBuVxGr9ebMHTWzXTaxmdf1+lgrWm1WkWr1ZK/awPDRJ/OxpJicrvdUtTf7/eldp3PZVjMtaadG2ZvB4PBRJNOrm1WTQAQW3JcPJGhm1Zoz4PIZDJYXV2dSCfTMtOz4g3JHz6uY3g+h7qaaRZfGzfrDUzjprkFn8+Hfr+PUqmEZrOJfD6PwWAgu86z6m5q4+DNpFQq4datWyiXy+h0OhgOh4hEIvD5fKhWq5J906VCfE9NjVjvERsHYzAYiMdM6M2DSgdy7gwzqZfTBfydTkc8OR3qMmnITYg0FB0bGkBtI9gw4DPx6DQ6nQ5yuRy2t7fR7/fFhaWXpAlLfkEdfk5LVujXHAT9PoQ+UTR2PEEUmpqmiUwmg+9///tYWlrCl7/8ZeEQbGN38ph2Tq1i0VKpJCLzGzduYDQawefzIRgMIhAIwOPxIBaLYTweY2ZmBrFYDOFwWO4RK//Gf49GI1HY872YpLKxB91lRBs3YM9x0M6Hz+cT5QShkw7A3jXWxow0ky4WYAkZ1y03ME1XTRMZHxVH8uharRbu3LmDnZ0d9Ho9eDweMXba1eUOQDdUGz+6qrpLgrb+1s8HJpXZ1ptca31ovJjBYe3e+vo6vvOd7+Dll1/Giy++KCUqdnjz9GAtDwT26qOz2SwymQw++ugj/N///R8SiQReeuklBINBiQ6SySQCgQDm5+eRSCTkmvG9p1274XCInZ0d1Ot1zM/PY2ZmBn6/f4L/tbF7nlg8T+Oi+Tp6YDRKXJ98Prk6l8sFr9c74XFrz4zGkBsN16V+DutnadjoTT5Tj87Kd3Q6HTx48EA6ieibmV9E/00bNuuBWxMYwKT7rEMe/fdpve25W+gTzb9TclKtVlGtVtHpdKToWO9G9kJ4OuDmQzEoSwPv37+PWq2GWCwm3WVJZLtcLjSbTbRaLWxubuKdd95BIBBAPB6H3+/HzMwMwuGwiMq5UDqdDtbX16UofH5+3g5pLdBek3Zi9L/1WrJKvQBIaKplIVQ/aC6Va57P08ZQ3xfTPDd6nePx+Fh1r09s6LQBKBQK+K//+i/kcjk0m025iSgB4ZfXwmB+QVpqHjyfq3cLutIkK7kj6No4GlN6duQI9cXjiWNShItrdnYWxWIRbrcbiURCLormDm0cD9M2DJb6MOnw/e9/H++99x6SySSuXLkCv9+PYDAorbZcLhc2NjaQyWSwvr6Ot956C7FYDF/60pcwPz+P3/3d38XVq1dRKBSQzWZF5tBoNPDOO++gUCggEongxRdf3Hd83/MMJhK4uWjnQK9j8mi0A4ZhPCLaDwQCGAwGkjHnetQyEnrpnBimnSF6jtauKd1uF5VKBaFQ6FgVMofi6Gg82Cq52WxKxkTD6uFZH9OVDCQ39Qnm/3UIar0QB3FA1udpN7zf70vpi8/nmyg+tvH0wJuZzRqKxaIkGcbjsSwM6/1A40XNV6/XQy6Xk3rYYDCIUqmEQqEg5X/tdhvtdhu9Xk8Wqb15PQodYelwclqSR0NvGjy/dEZYCTVtU+H78kfz99ZITz/GpMdxuLpDGTr2nWKmhsW8OozU3Bk9q8FgAMMwEAwGEYvFEAwGkUqlJGx0OBzSqSQUCmF2dlY+D4DwK9xlWCbEUJSlKp1OR0hnh2OvVIU7Dy9iNpvFd7/7XSwuLuLP/uzPcOnSpUeO3cbJotPpoFKpYGNjA//yL/+CnZ0duN1uXLt2DaFQCMFgUATlAFCtVtHr9VAul9Fut+FwOGRHp1zo448/lmST7lJLbnhhYQGRSMTm5vZBv99Ho9GQ9aWTAjqcpOyLRi0cDsPj8aDdbqPb7coGBQDhcFhCVzooXI/sd9fr9SQUZdMPrYvVSQvWPvP4jopDGTp2C2YcTm9Jl3dogaAmG/lF6EWlUikxkuPxbhVFs9lEKBTCzMwMnE6nhLAMZ/jT7XbhdrsnBukOBoOJk2WN/bWX2W63sba2JsZRH7uNp4PBYIB6vY5SqYTV1VVkMhlcu3ZN7gOS3dRudTodWUiGYUgHk/F4t/7RMAzU63X0ej3EYjHMzs4iGAxiYWFBpknxvtkvafG8gzSR5r6sfNm0KInOBLVz5NgZqZG749/ooTNkZeKQtsP63sBkVHgSSYlDGbpsNovbt2/j7t27j2RSrTo5YDIzapomfD4fkskkEokE0um0nJTRaIRisSgWnhnc2dlZcYWZiWEvemCvmJ8iRK3F4eM8Pu4swG44dO/ePbTbbdRqNfT7fbuG0oJpusn9nsPnWUMhh8Mh8oWbN2/irbfekv6CZ8+elRb4LOsaDofioW9tbaHRaKDX64nHwUXA3d3r9aLf7yMcDiMcDiMSicgYvtFohHa7jWq1ikKhIEOWbYO3B5300aMOAEgpJ5vYMozkYCtmSoG9ZgzD4VCiPZ2l1UaM64zOByOuWCw20bqJx8HMcCAQeHYeXbFYxM2bN7GxsSFfkhabN/h+hm483u1VFYvFkEgkMD8/D4/Hg16vB8MwpEMJT7zf78fs7Cx8Ph+azaYsGKbD+f4ej2dCda11dtrI6R2n3W4jl8vBMAwZuMvHiec5A6s3C+Dxxk5fY62ZInHdbrdx//59fO973wMAXL16FTMzM4hEIjLpPRwOo91uo1AoSClYrVZDKBRCIBCYqIlkT0OPx4PBYCBVFOFwWMbulUolub6VSkU0eM/rNZ0GHVZq/RrF/qQRdNE/DY+O0kajEQaDAQaDwYSwG5jcDK0zI2hc3W43/H6/bE7ae2PChInJo+JQhq5arWJ1dRXlcvmRDKWWh1hvJnJrJKNbrRby+fyE9oZFwexjpTO4VMu3Wi05EfQEeRI06Wx1c3kBaQzJ6zgcDjx48ADxeBznz5/H0tKSvOZ5XhDTRLj7wXrz6e4ThmHgzp07WF1dxerqqhTjk5OjXs4wDBQKBbRaLeRyuUc4HH7OcDic2FQHgwH6/T5CoRBCoZB4fvQ8+v0+qtUqstksxuMxUqnUSZ6m31hwnfFHC/11UoIqCavzwMcPgrXSyVrbbpWrcA1rATE/v9vtikrjqDiUoctkMnj33XcfUU/rNsj8EhMfotLUjUZD+DStYavVamIIK5UKXC4XqtXqhGix2+2i3W7LZzBktYqF9QQifi6wV6jMYRxOpxPvvfcetre38Yd/+IcThu55x2EMvdZE0dB0u130ej385Cc/wXe/+1243W4kk0kEg0Ekk0nxwHw+H3Z2drCxsYFms4mtrS0Mh0P4/X6Ew+FHpEVcOA6HQ7Kxs7OziMfjCAaD8Pv9YuRarRYymQz8fj9M08SlS5eee3piPN6tI2ULM2a9ufHrzCnXKZtjaoOotXHW+nQrjTUYDCYSDLwGWq6iS764URmGgVarhVqthmAwOJEJPiyeyNDpmjZaVq/XO1EiwhOgf+uTC+x1HaVR1P3nGMI6nU60Wq2JOlieNGZXeZLI21Gbx8/S3qZVcMzX0vhWKhX5TBuHh5U0JoeazWbRaDRQKpWEA2UYSs+L167VaqHZbEo3WZ1Q4nvrvzMzyMXH0JfJLRpcJiJOUmH/mw6qIOg1kw7QGxvXm26HBuwZNSaPdEXDtMhOJyvJz+kwWduLacX7fPwkysAea+hM00S5XEaz2UStVpMvzDpRXcsG7NW4ab6Mv+v1Omq1mtyImnfhF+NkcH75/S6GPj6dFrcaM75OE64AEAqFYJomPvroIwDAV7/61WOdyN9E6JtNe8D7cXT8m/bc9TVptVp48OABSqUS3nrrLRm6EovFEI/HkU6nhXt1Op24d+8eisUiisUiCoWC9BKctuh0mVGr1cJoNJKhR8vLy7h06dIExxOPxxEIBI5NYp82jEYjVKtV6eDLrs00QPzp9XpizFjYT350YWEBgUAAuVxOhPdce5puoKSMkh8K+iuVigiV+RmNRkM6Dlk3OuDxofLj8FhDR+kHU/lMJdOA6KaYVlmJlqDorA0AcYd1byvuBvQamdnVjfms4k+rq2xdlNO8S+3ttVotyRbpk3/aYTVm+u/7PX/a33RI2Wq1UCqVkM/nsbm5ifX1dUQiEelEEggERF9F2qFWq6HT6QjZzPb5++3i+p6jl8iQle9BGoOyCe3xP++Y5tFZH9cenTW5yPWhpWF6rVk5cu1oWPlb2gzNzWl7oSOxp27ohsMhbt68idu3b+P+/fuP7PTawAGTlQ00SHoMGk+Itdmf5utYqbCfsQLwyMmkJ6mh9XRWBTgvMLsRb25u4qc//SkWFxdx/fr1U8/l6HMzzVO2Pmb9/3g8FjHvgwcPsLq6ikqlgtXVVcnKpdNpRCIRkX7EYjEYhoEHDx5IPWqhUIDH40E8Hp/QPgKY8PRHoxGazSYASHfb5eVlpFIphEIh8RIqlYrQLKPRCNvb29je3kY0GrWNHfb60DWbzakt1K18q+be6agwwuPwGz6mWzDxOvb7fXFodLMPr9cr0/l02EoOluExAJnx+lQ5OtM0kc1mcefOHRQKBQCPZuW01o3eEq09MJm0oBHkSdYG0rq76BM8zerzOVy0Wn9jhZVnYNhMA8tF6nQ6ceXKlVNv6IiDkg7Wx/T/TdOUWSFra2t477335N+maYpOLhKJTGRFqZms1+sol8toNBqIRqPSfp+cj7UUkDIDh8Mhow/j8Tjm5+fFm+z1ehLW8n5pt9vSYNIOYff4MN1Z2Po4MLlO9GOkB7iZWcNLvU4ByHOsvekYxbGqQm+gpCr4fErLjoMnMnT5fB5ra2toNptiHPSXm8bnaFhdUe1NaOs/rT26zppqWLkl3R3F+pg+DmtxN0/y1taW7DzPC1+nd1+9SenrRRkP6Ytut4utrS10Oh1kMhnUajUUCgUp71leXobT6UQsFpNdmdeFhohcLbN9erfXx6Z7mrlcLoRCIXi93om2S0x+aF0XQ1qXy4WtrS1pDFmr1TAYDBCPxz+L0/1rAW2MeD2oL9V0k4a1ukjr53SmVNNWNGL8TL6O0Ikk9h7UfDvfkyH2flTLk+Kxho7u/+3btxEIBBAMBie6k1gTABraYNHAWEMhfXL1YgMeJb2tWVirkbNmV60JjGnF3czMPXz4EGtra0gkEs9NiKNndpJq0G13HA6H6BTL5TI2NjZQLBbx9ttvo1wuS2aV90U4HMb58+dFM6lhGIaUdVUqFdTrdUlqkbPTN7LuYDMajRAMBhGPxxEKhXDu3DkEAgHx2JiN11nBZDIJv9+PQqEg5YXsYPw8GzoAExsPRyDwmmmnglGNlSPT4l29HnV2myJgfY/Ru6PH5vP5EIlE0O12ZegVbQK5c23ojoMDDV2j0UCj0UCn00G/3xdJyX4ZUOvBaKOib3ySlvzNx62JBKvYUL+Oz7MaWv1Dw6azrdYuDTrM5g+/62ntSMub6O7duygUCvD5fPD7/eINaUNHsWa9Xkc2m5X+cBxUE41GZVdmJp7nXvO0hNPplAXAMJW7uL6WwO61ot6RbXq4++v7T9MiXq9X6mKZ+JgmeH2eYQ0vgUfPDSsgxuOxeM96EI5eg9rhoAfPx6a9N8EuSFZjRkNI2uIkKIcDDd36+rpooZrNpgyk1qI/LSFhl4NpoafVIJGD4ftod1W7uAd5jIR+P02ac/GyNIXdafXCogfAzx2P9yQu8/PzRz6xv87Y3NxEu93G3//93+NHP/oRlpeXce7cuYlNgueSfAwzZQ6HQ8JNygx0XeO0ZAKwdy94vV6kUimEw2GUSiWZ30ovgdcuHA7LZ7DLMGtVdZIC2E1e+Xw+6WPH2knSLLrW8jjNG08DeO9zk7Feb66fVqsFwzAQDoeRSCTkGvP66vbrTFxYQ19rAtBKYdVqNRm3qMNfAOJocHbsU/fo2u22kMNaVqJxkAHS0AfL3V4bRWsIan2tlXuzEpg0quR0uCC1AWYSxBoOk+zkLmOa5qk1dAwhq9UqyuUyAoEAYrHYBFXAf7PCgWBIomUG1g4V+3GqXFjsQsLwcxp9EQgEJDNHI6YrXzQfa01+AZOyI72Yn5ck00HQ3LgVek3xOZq31c/h8/g37cnToGqboQ0psDf+YDwei0bSOpBHh8bHwYGG7vbt28J9LCwsIBQKyc49LWNDWC23Pik63NQ3n35f601r/bd1V9fv2ev1UKlUEI1GsbKyglgsJpnVTz/9FL/61a/g9/tl6jvfm4s/k8nggw8+gM/nw8WLFw9zLn9jkM1m0e12EQ6Hce7cOczNzQlvpVXtACZCWmqndFcYq0TBWgao6QC+9/z8PMbjMRYWFkRd3+v1JhowMJGhkyKVSmViAWpDpitsKItg70Ia53A4jGAw+EzO8a8zNG8G7HF2OmQkFcCMttfrnRgsT+fAMAzxvLTjwPXErtFc51aNpGmaiEQiOHPmDDqdDu7evSvRFzfEp954s1KpyI3MHdZqYR9nba0xttUzm+ZFWGP8aXyAXkj63wyDTNMUVTZnDKyvr0upFxeHXjTMLpZKpVPddbjVasn0tmg0KrMzCB1+UnhL7Zo+1/oG5HXQUgFgkshmUT5Fwfw7a1YpOeD7uFwu9Hq9iZpLeoB8b2Dv3qGwnA1htTfP73Faedcnhb7XrYaO0DWpTAjtF2VZs7R8nvbMtFzImjAcj8cy7U3TWNbPOI6GDniMoctkMhgMBqhUKmi1Wo+4sTQs+iTxoPTurE+C1sbxN7kfTRzz+fyy+osDeyfDmoDQO8+nn36KaDSKb3/723jllVdQKpXw85//HE6nE41GY8KtDoVCiMViuHTpEl566SWZM3Eakc/nZTemp8Y2WTQW+jpwcZBHs9Y268SP9Zppz55GqtFoCK+jW2+bpil8TbvdFgPHBhC8Jvrz9b3BqIBcHMuLeG/p8qTnGZTjWKkgbjQApGuzXsekd2jcNDfKHoHasaGh08ZVUwe6bZPVkGo6w2pHjoIDrzp78zcaDenqq5tjApC4mgejXVJrUoInU9+curcc/24tLZnmFVobPPLH4/EgEAhgNBrh/v37CIfDmJmZwWuvvYYPP/wQ0WhUmgvwJDocDsRiMczNzeHMmTO4evXqqTZ05XJZPCQaN96woVBoYkOisWE3Z25MwN7Or5MR+xk6eom6UJxRAq8llXirtdIAACAASURBVPRsCsDNdTweIxwOS42svsf4vnxvh8MhC0x7E7p86XmGTiboNcpzqmvQ+W8aJxpHXj9m64HJyhlt6LTKQf+2UiBW6ITHfrmBw+DAq/6FL3xh4qbkTcdOsC6XC9FoVOoYA4EAyuUyMpmM8CzWLzHNeFmJT2so/Ljkh84eWaH/dvnyZfzRH/0RCoUCPvroIwyHQylTYj+6S5cuSSeM0wr2++t0Omi1WiLuJCFMTovhI390Zk1D77jTKA0dpjDkZeLC5XI9ktnlvUA+zTRNMYjWhANDUy4cPWDH6u3vd488b9AcOQ2NNmYAJu4FrV8F9tYUOXG9gehrzOhOJxqtEZvL5YJhGMjn8yJn4fXT3U72S548KQ40dG+++Sb6/T6i0Sju37+PXC6H7e1t9Ho9ZLNZeDweXLx4EQsLCzJg+OOPP8atW7fgcOwOM+E8VetB8ovrzAu/pOaL9E6h/635A2uCQn+G3gneeOMNvPbaa7hx4wb+7u/+Dr1eD7/zO7+DxcVFvPjii7h8+bJosU4zOL2NWVdNKrMjyOzsrBThTzsf05ICOtyw1jxS+EuhKn8bhoFSqYRcLiev8Xq9uHLlitS/6my6zqBrQp33DXvYAXsboFWs/rxD85zW7KaeocrrqoX21rU3Go0kEgD2oi2WmXHEIT93Wmlos9mUGmVWVTBypIf+VDm6WCyGwWCAxcVFDIdDqVnUk4MuXLggE714Q+luJtbdwAo+xyoYnsbPHQTrTex0OqVzBg0nT+DMzAwuXryIfr+PxcVFpNNpJBKJ5yYjt7y8DMMwpO0Wzz9vUABS9G3lavh8YJJnpSGy/ltrI1lfyd3e6dxt3UOdFqkHn8+HCxcuCM3AEYbFYhEAZPFMS4TR25zmgWj++HmFDvX1JqX/zucBk+LiaQ4IvXKqJfTred01tWE9Fj5PZ+WfxoZ0oKFLp9MwTRPJZFIITJbyFAoFOBwOLC0tIRAI4Be/+AVu3rwpXSNIbDLk2M/11OVe1lCHmCZT0a8nD0NZgWnuDuI5c+aMdJ/VOHfuHP7mb/4GpmnK6LbTzMlZ8Vd/9VcwDAMfffQRtra2cPfuXdy4cQPD4VCMXzabBbAXluqh0qw40JUnVsNGT1sXj/O6kkNbWlpCPB4XwXIkEsHy8rJQIU6nE1tbW8jlcvjkk09w7949uR91GK2zdZ1OZ8Io602Tbbielw1tGuiJsUaYdavWJhtWL89au0ojp1ucc+Oit81EEDl8vq/W2dHIsemqbv+kPbnjGr8DDR1DFqsR6Pf7MnuVN92dO3ceeb2VF9EHa91t9Q48zU3d74taJSp8H6fTKe2BrGr4QCCAlZWVg776qcbS0tIEz1qtVhGJRCaMlR5NB+wR0VwUukeg9gTpAZBr06S39toobeFEuIsXL8rsDn2zc1Gsr68/Iiy28oFcPFp4zs+bxhE9r9ANEwh9bqatyf0Sg7zeVk+Qj1mdEius11Lbi+NwclYcaOisxohg/zD+GwAikQhSqRRisZi8VneU0MOq+bj1JOob+6Dj4THRoAGT8yC1bkp3MLa+xzQ8LzyOy+XC2bNnJdP8+uuvTxipQqEgQ6drtZrUunJoOL0Btr/nObcONJ+fn5cRlysrKwgGg9JpmDMjotGodDvRfQkdDgcSiQScTic2NzeRSCRES0cvQXtzVi4X2LsvWa72PHnu02Cau40Q2G1GJ3wAPCIKt76W1BQpAl4zrjNuRMyes809fzscDmmlxWtFiROwJ1DXhnjasRwWjzV00z7A6XRK3ShPgN/vRywWk1bImpwmgWntMjrNqFktPP/Gz9HHoGHNrGljZzWuh83qnkY4HA4kk0kkk0ksLy/L3xl2bm5uotFoYGtrC/l8Htvb26hWq9KNmcO/WXnAn0gkIufd5XIhEolgYWEBy8vL+PznP49YLIbLly8/cfjIcDkejyMSicgiYciq+UKGRQydAEhihRUytrxkb/YKJSJWLau1VE5nWfW55TrTVIGOCjQPS/kSn6sbdujX87NP2vs+8KoftOB5EPTSUqkUHA4H7t+/L+QkGyXSU3ic/OMgTEtQ6L9Z2woBwNzcHNLp9COL6qAM3PNg5DSsmxl3WCZn/H4/FhYWcP78eVy6dElqganD0/WMukyMP+RIY7EYFhYWJInFz97Pw7Z66hcvXsQf//EfS6YPmJS16GMH9sImznNdXFy061z/P/bb7PW5tCYUtYKB3hfvAXLc5OO0QST9QR7Omi3XcqVpshTdmeY4a/NIhk7H5DQazF5+8sknwoew/bE+eIay1qys5gX47/28NnIx+hi5W3NSGbCbTDlz5oykvq0L+nmHlRvhb7fbjbm5OYzHYywtLU2lGJ4EVm7WusEcRFPosMbtduP69eu4evXqEb7l/rXXzyusFJFeh8CkEFu3ZdOcp8Ox29mG3CzLA9lEleuUCUxgt/SQYSk/B5iM7uikaA3nSXjiR3r1fgkGh2O3lCqdTqPb7U5k6fQX0q+3tnCxfo713zyB1gXKUIkXgSR3Op2eCLNtPDmmXeOn8f5P8hg3RxvHA9coQ/n9aKLHeVPWMFdLj6Zxe1z7ViHwaDSStvhWmQmlQNZ260fBkQ3dfjfd/Pw8Xn/9ddTrdVQqFRiGIdUT+51U69+0ForgCdyvdpYXpN/vo91u49y5c/it3/otnDt37hHBq72z7+Kz9nKeZz3bZwW32410Oi2NV+lt6coITUPQeeC61N4dK2j4A+wZNT6HnC8dFIfDIfIkRl6hUAgrKysYDAbI5XLS5IG12ORnj3O/nDgzy4OOxWLw+XwYDoeIRCLSe4ywSgMIa4mRNmZ6t7BycyQ0Wce6sLAgn6thGzkbzzPIsemxk7qzCPWL5NusTTymOR8MUQE8IlvRz7d6h3xdJBLB/Pw8er0eqtXqRMv1k8KJG7qLFy/iz//8zyfa6lglHgfBavieNCPKk84TzWybDRs29qBDUk37cGLbtWvX4Ha78cEHH2B9fR1zc3OSyNGldVyjbrcbnU4HGxsbE8kgl2tvmBHpKzZ3ZXt+dhi+du0a/uIv/gKVSgX//M//jEwmI30wdZb/OIbvxA0dR9fZsGHj1xNWyoLhaSgUwvLyMvx+P27cuIFOpzOR9GO2nA4MYRiGZFQ544NGjx4cP8PpdMr7srwvGAziypUryOfzEz0Pgb0uJtPq5Q+D51tUZMPGc4bxeCwaSEpBOOwoFArh5ZdfxsLCAnq9Hs6cOYNcLoeNjQ0pEtBzI6hwIF1EPo1enM6qNptNGSlKo3XlyhUsLi7i1VdfhcfjQb/fx8bGBh48eCBUFCe4sbPJUWEbOhs2niNQwsHOMfSY6vU6FhcXce3aNVy5cgWtVgtzc3P4yU9+gvfff1+SDVQ3MAQdDAaikWOzBd1anYmFfr+PRqMx0Z3k7Nmz+NrXvoalpSVp15TNZrG5uYnZ2VmEQiEMBgMZTn4cAbFt6GzYeI7gdruxsrKCQCCARqMhoSZLAuPxOFwuF5aWlkSAz8YNutUWPUE25HU4HBNzOcjL93o9EYnH43H4fD7Mzc0hGAzii1/8IpaWlqTMLxaL4Rvf+AYuXbok7f0vXLiA69evS4eko8LxGHfw5NIev5k4rSla+7qeXjz22rJiYWdnB4VCAaFQCIlEAj6fT8JTVi8Ui0Xkcjlks1l88MEHaDabqNVq6PV6qNVq0jSV41DPnz+PYDAoxo4e3dzcHF555RUkk0l84QtfwOzsrHB4rLro9XrY3t4WaclwOMTc3BwWFhaE43sCTL22tkdnw8ZzBhqYQCCAUCiEcDiMaDQ6oY5g9pTF+PSwGLoyc6tLw/ijSwKZjKDmjp/JaiUNZmo9Ho8MRTqpRgyP8+hs2LBh4zcetjTdhg0bpx62obNhw8aph23obNiwcephGzobNmycetiGzoYNG6cetqGzYcPGqYdt6GzYsHHqYRs6GzZsnHrYhs6GDRunHrahs2HDxqmHbehs2LBx6mEbOhs2bJx6PK57ycE9nA6Y7XAQNjc38YMf/ADFYhE3b95ErVbDlStXcO7cOczOzuLChQsIBAKYm5uD0+nE1tYWqtUqGo2GTBe7e/cuer2edFP41re+ha9+9asIhUKIx+MnNQTntLbzeSadHMbjMXK5HIrFIhKJhMyIbTQa6Pf72N7eRrVaxdmzZ3Hp0qVnObjotF5XYJ9rq6frWf9O6BbrenbLeDx+pEvJsQ7Q8t7sWAzsPxnOOobxgGN49m2a+CXYsI8HxzFnejYkAGnq1+/34XA40Gw2JzqZso8Wh3PwxLNt82AwkB5YbCZoHc5r4+TAm08PKQYgI+2cTufEpPZ2uw3TNNFsNqUzrR60wmvPyVR67oCNpwNt2KY9Zp38pZ/LNupca/r99HUdj8dwu93w+XyPzGd+kmlf1hnOR8GxDN1BB2maJjqdDjqdDn7605/i3r178Pl8Mk7N5XIhFothYWEBoVBIdv9SqYQHDx5IE77BYIDZ2VmEw2F4vV74/X5ZMA6HA5FIBH6/H/l8Hu+99568t9/vx9LSEoLBINLpNGKx2HG+qg0LxuOxbEA3btzAe++9B9M0YZomYrEY3nzzTaysrCCXy+H27dti6NrtNtbX12EYBq5evYqFhQUkk0kAu57+f/zHf6Db7WJxcRGRSASf+9zncOnSpc/4254OHLRe+Ri9Pu0k8HHOaWWvuP/+7//G22+/jXg8jjNnzsDj8chwm1qtJnMpBoMBLly4gDfffBPRaPQRY8fmm/x87cTo49O/D4tje3T7ffBoNEKv10Or1cLHH3+Md999F+FwGJFIBLOzs/jc5z4Hv9+PaDQqQzAajYZMFKpWq3j//ffR6XTw0ksvYXl5GfF4HHNzc+IJsH0z20K3Wi3pgR8OhzEejxGPx5FIJGxD9xTAoShra2v4n//5Hxl6kkql8MYbb2B5eRmNRgM7Ozsol8tYX19HrVbDrVu3ZBiy3++XwSeVSgU/+9nP0Gg0cO3aNczOziKVStmG7hmBISQNjdVLI3jdP/zwQ/z7v/87FhcX8eKLL8p6djgcyGazqNfr0mH4S1/6Er75zW8iEonsa8A453WaF3lcnFjoyt08l8vhzp07aLfb2NnZQbPZxKeffopKpSJTg0zTxOzsLILBIBKJBGZnZ4WD6/V6AIBer4dgMCjhL1s3M4Rtt9vSxdTv96PT6aDX6wkX5HA4sLa2BpfLhTt37sDr9eLzn/88Xn31VTuMPQbG4zGGwyF6vR7eeecdrK6u4vbt26hUKrI71+t1PHjwAB6PB6Zp4uzZs+h2uygUCkJHOJ1OmSSVz+dx69YtbGxsyMK4c+eObGKDwUAMnh3GnixoYGhc9FxWYI+WaLfbyGaz6PV6yOfz4licPXsWPp8P+Xz+kZGIw+EQPp8PoVAIhmHgxz/+sXQz9vl8WFhYkJbqPp8PAGTKmB6OfRLNgY9s6KxxM7mYBw8e4K233kKpVML9+/dlgs9wOESn05HRaslkEvF4HC+99BKSyaT0r2+1WrKQwuEwAIi73Ol0UCwWZefhpHGPxyOvv379Oi5fvozhcIg7d+6g2WxiZ2cH9Xodf/mXf4kvfvGLcjFtHB7kXJvNJn74wx/iBz/4gVx7p9Mp1MTq6qrQDhcvXkQmk0E2m5X5n16vV67rzs6OUBW8zqQvDMNAsVjEyy+/jHPnztmG7gShN3xt6PTfDcNAo9FAPp/HL37xC9RqNaytraFer8PpdOLSpUuoVCpCM9FRicVi0oZ9cXERhmHgP//zP+FyubC4uIhYLIYvfelLQmdxaph1bWovk/8/Ck5sxddqNVQqFWSzWZRKJTSbTeHKuLNHIhGZBMQws16vw+12yzRukpvhcBhXr16FYRiIx+MIBAIyiWg4HKLb7cLpdCKZTMLn86HT6aDb7cLr9aLf70topPvgl8tl3L59G7FYDIuLi7bBOwJoeCqVioQm1mHFpmlia2sLg8EAhUIB4XAYmUxmYqcmj8NNqFwuo1KpYDAYiGfo9XrRbreRy+VQq9VOZGe3sQvrueQ1IUfWbDbR7/dRr9dRq9VQKpVQKpVk3Xo8Hrjdbng8HgyHQzSbTRiGAa/Xi/F4jFgshmAwKDMg6O1xsliz2UQ+nxfuPRgMwuv1IhaLwePxiN3gsfGYnzlHZ52mfffuXXz88ce4d+8e7t+/j/F4jJmZmYk5kAsLC1hZWUGpVMInn3wiyYRqtYparYZWqyUEaCqVwte//nXx6gCg3W6j1Wqh1Wphe3sbALCwsACfz4dgMIhAIIBoNIparSb8HQdu9Ho93L17F//0T/+Ea9eu4dvf/rbN2x0B7XYbH330EbLZLLa3t9FsNhGNRhGJRADs3oz9fh8/+9nPJgwbJ77z5h2Px1hdXcXa2hqA3XtIhzDRaBSmaaJUKqFcLmNhYWGqPMLG0aH5OLfbPZFouHXrljgt+Xwe7XYbxWIRpmkiFAqJIeOwG7/fj8FgIHxrMplEKBSC1+uVa0pnpd1ui8SI1x/YveavvPIKEomEcPI0wDqEPYqxO7ZLY5qmJB6YTGD4EovF4PV6ZXrQzMwM4vE4BoMBfD6fHDxlJcPhUMaaUXZCL4GSBY5hi0QiGI/HCAQC4v5GIhEEAgEJb0io8qfT6aBQKGB+ft5eNEfEaDRCo9FAtVrdd6gwOVXDMOSm1OQ2b1jyurymXq93wjN0uVyy8Pjb5/PZnvgJQ3tz9XodnU4HtVpNeLh2uy1RksPhkMlcXq8XLpdLHA1t1GjkuP4ByBhF3huDwQDtdhvAnrdGrjeRSCAQCEzcD8fx6I91x5imKSFnvV5Ho9FAKpXC1atXJzRyPGgaRRok0zTFdaWh9Hg8iEajGAwG+OEPf4jhcIhUKoVoNIpAIIBgMAin04mVlRU5hvF4jNnZWfj9foRCISSTSQwGA2QyGUlaOBwOERzPzs5OhLd2cuLJ0e/3sbGxgYcPH6LZbAKA3LwA5HyGw2EJb1wul+z2BBeMz+fDaDQSHR41l8Be4mMwGKBWq2F7exuJRALz8/PHGmb8vMLKc2knAgCq1SreeustFAoF2Zj0evX5fPB4PLh69SpisZjIwfx+P2ZnZ+H1epFKpeByuZDJZFCr1eDxeBAOh4WKGI1GsoF5PB4xlnzsgw8+gNPpRKPRkAKChYWFCVHxUUTLxzJ0JKaZTe31ekgmkzh//rzc3AAwNzeHcDiMVquFer0Oh8OBVColCQVgL9vCCzAajbC1tYVOpyMLicN16cEBu6HUcDiEx+NBJBJBKBRCNBpFt9t9hLimZ8DX8HW2oXty0KOr1Woi/KZHrnVR3N31LFDyb9wE/X4//H6/bIDc5enp09unsWu1WmIYbUN3NFgrIchfm6aJbreL9fV1bG9vy5olD8dMuc/nw8zMDJLJJBqNBoDdzc3r9SIcDiOVSsHj8aBcLqNarcLpdMqGR+eGXh8pLY/HA5/Ph263i3w+j9FohHPnziEajYrywnrsh8WxDN1oNJIvlMlkkMlkAOwaNmB3hzAMA6urq8LddLtdjEYjDAYDeL1eXLlyBZFIBP1+H5VKBcViEQ8fPhQidDQaTVRI8D1JTmsltmmaIkMYDAbI5/NoNpuo1+vyuQDQarVw584dVKtVnD9/XvglG4+HYRjI5/OSKWXygRsLhw2TkxsOh6KN4tBifc263a545fT6+H8tYG2325LgWFhYOJGhxs8bppV3AbtJuocPHyKXy4nXTUqBHrbP55PIzOl0wjCMiUolJjEKhQLcbre8Dz/L7XYL3cTMeqfTQbvdxmg0krCWjtPt27eRy+Xw27/92zh37tyxS8+OHbrWajUUCgXkcjnkcjn4fD5Uq1WYpilygnK5LF4Ud35mVs+fPw+fzwfDMFCv19FsNiVO507Qbrcl9HQ4HKhWq7h37x4MwxBugDh37hwikQgMw0CpVBI1PsvKHA4HOp0OHj58iG63i1QqZRu6Q4BZ13w+j16vJ+V3/X5fdmYAcq1dLpdk46iap+dH5TwAycb1er0Jj45GstPpIJ/Py/vZOBysdaz6d61WEy0kKQhuNjRKsVgMoVAIwWAQwN711SV+w+EQ5XJZQlOCCQ++NhQKyTrsdDpwOBwIBoPi1fd6PdHArqysnIiA+FiGzjAMbG1tYWNjA+VyGf1+H9VqFQ8fPgQAuZFrtRqazabwNVosmsvlRJQYi8Vk4XBHcTgcQlrSjXa73UgkElL5QA0OjSeTIjz5fr9/Qh8UDoeFc7B1WYfDaDRCt9tFp9OR3ZzXVMsT+Hd6dty4NEh58HEmJLS3wUig1+uhVCohEAjYiaQjQmctddjabDbx4MED4dkZbdGjZs0y5US8Tv1+H16vVx63Jv/o7bOSolQqAYAUBpAnpyfPe4H2gYaUx6zL0Q6LYxm6fr+PTz75BB9//DGKxSLa7TYGgwHK5TI8Ho/IN7LZLKrVKmKxGBKJxERd3erqKvx+P3w+H9LpNFqtFvx+vwgVaeFbrRbC4bDocpaXl+F2u5FOpyVB4XK50Gq1kM1mMRwORfPDhAdP0uzsLGKxGCKRiG3oDonRaCSaSWZA+UOvTDdS4OIaDoeyIdEYtlotCVXJu0WjUeGDAEhJYKPRwMbGBpxOp3C/Np4cevOwdv8oFov4+c9/LtpUCvE7nY5UpxiGgWw2C6fTiVKpJJxbJBKRggCXyyXODH9YKNDpdCRSoxaWG51uDsHjGwwGEh4T+3U2eRKcSDKi1+uJRSfvMhgMxPuiEp4nkClpSj56vZ4YO9M04ff7ZbGQrORvngiS3MFgUMJXxvkMecgvkFSlB9LpdLC9vY1+v4/z588f5xQ8V+ANqTvDAIDf70cikZCEge5Uo8NQeuj02JlFY8jCRBM9d4fDIRwOF8x+khYbRwcF+CyhpCxEe2XaUOo680gkIvw59ZJ8nOWZwWBQPDtuctrr5zGMRiNxSLrdrhg63jefmaHjl2YmRdek8gTRs5ubm5NwMhwO4+LFixiNRvj4449RKpVk8SwsLODy5cvi0bFWMplMolaroVwuw+v1YmZmBj6fT2pmo9EoQqEQnE6nJDNqtRpGoxFisRjcbrcossvlMm7cuIFUKoXz588jnU4f9zScerBZAjWMlACZpomVlRW8+uqryOfzePfddyUk4SbHBdDpdOS96MUBkJIyXtdgMCjXrNPpYGdnB61WC7lcDtFodGKXt/Hk2K/n22AwkAzp0tISIpGIGDd60x6PB6FQCC6XSyoeVlZWsLi4iHw+Ly2bGo0GxuMxvF4vIpEI0uk0VlZWpNa52+1KqZ+OplgRlUwmpTKj2+0Kx07P8plXRvBm1XE/9XDc0emK8iQx88mTYBiGiI21aNHv9080+mP7F+35+Xw+kTCwfVM4HJ54LT0BenJapFgsFif0XzYOhuZMrB5dMBhEKpXCYDCQa0gPms+j16ZV7lx4uj0PExr00hkFMNShsbVxfGhPm1IralG5NnVoqUNSVlNQOgTsZWp5HRmF+f3+iXZMXOv00rhOKTsimLFnf0lGekfBkQwdBZzFYhGGYchB8IZlJoXhJa1xLBaTbgazs7MwDAPpdFrKtAKBANLpNM6ePYtms4lMJiMJj52dHVy+fBnf+MY30Ov1UCgUAEAKhyORCCKRCObn53HlyhWUy2UpKyuVSsL30bUOh8PiNdh4PLrdLorFIorFonhy3DxSqRRee+01hMNhvP322/I4b24dngCTnoU2mlxYFJKy3pEGVoe7No4PVj/U63U551zD/D8ASfItLy8DAAqFAorFIprNJtbX19FoNFAulyWc9Xg86HQ6Uv9KzSXVGDoDD+wmQ1qtliSetEe3s7ODTz/9FHNzc7h+/bpk9Q+LI61yEv3tdltSx7TUjO95grQgMBqNIh6PS2zf7/cRj8cxHA4Rj8cRDocxPz+PZDIpolPKSXq9Hq5fv45r165JSyd6h/TsfD4fIpGI6Ph8Pp+4vo1GY6Ijsc/nk1pYG48HqQR2l9FdJSKRCM6ePYtarSYcGzPe5GK522toI8ebnh4brxEbMuofG0eDNZtNXWqn0xHPTG9QFPGTrpibmxMhf61Wk82PCSNy5kwYkWdjkrLVasHlcmFpaUloJiawGHnR0LJMjP0MuREeFUcydN1uVyQlAITsp2vK8JW95xiqxmIxJJNJseg+nw8vvvgier2etGpxu93iJV64cAHpdBrNZhO9Xg9ut1tmTNy+fRuDwQCbm5vw+/148cUXcfny5Qm1fr1eR7VaFYW+te+9aZqoVqsoFosiObExHbz5yL/RcHH3j8ViUvala1oPMkzWxhAul0v6lc3NzUnhOB9nJs42dkeDNeyr1+vIZrOo1Woi8eIcD7ZZImXRbrdRKpUk2WgYhmxi4/FYNiVGc8zEao6WhozGlU0B+v2+tG/TtsPpdArXHo/Hn31lRLvdxtraGqrVKsbjMaLRqBTvulwu0T01m005CfF4HDMzM5ifn58oC6FgmIuiUqlga2sLTqdTamY7nY60/Pnwww9RrValPbdpmvJ+qVRKFNms2iiVSlKHp9s28eSztVQ6nbYN3QGgfo43MG9cioGTySQikYhsKFYeDni0lbcWD5P7i0ajSCQSSKfTSCQS0imafCqvuY3jYTweo1arYXNzE8ViUTaw9fV1kW1Fo9EJT48dTuihkYsj18bHaBz1ddIVFNVqFQ6HA3NzczLjpdFooNvtolarYTgcTsiVKpUKksnks/fofD6fFFazTItWudlsyolgPG0YhljsSqUyEe+zH12z2RS9Tb1eBwAhH7kD1Go1VKtV1Ot14dqIRqOBbDaLZrOJQqGAUqkEn8+HcDiMeDw+YYyZ+k4kErIT2fWuB4M3qU7uAJNCTgAHPvY4kKuNRCLSeZqbD40mBabUbdnX7ehgyMkIiuvYMAx0Op2JeuRer4dKpQIAE9ISdiOipIzyIlJP5Od19QTpD6493eyB15jcrj6m4+BIhi4ej+O1116TIVDdEgAAIABJREFUGlIAuHfvHtbX18U6e71ezM/Pw+v1CqmYzWaxubmJCxcu4E//9E8RCoWwtbWFbreLu3fvYn19XRIVOsGxvr6Ocrksxk0LDcnRsQ6SzRzZdSEej2NlZQXJZFLS4uSG2Mpdh1s2poOhK70qZljpKZMK4OMApm4g+v86+0bPf2FhAcvLy7h+/Trm5+cxMzMjj7MOkrKDYDBoF/cfERQEVyoVMWrkxOh1t1otmblCrs3lckmvuDNnzmBxcVE6EFMC1Ov1MDc3h1AoJBsWnR0K+qvVKrrdrnD9AOQeoudGrq9er4uneFQcydBx5zVNE4lEAp1OB4lEAvV6Hf1+X4SfbIrZ7XbR7XbRbDalHIyJjGq1ina7jWq1imq1Kgp6urQ84a1Wa0Ixz+PgFDC25ta70eLiorRyZpdiGjrW3lHGcBwx4vMAho/06lioTdKaz7HeqAD2vUGtHh//r5NFJMT53nqjI/dq42jQXhZBGoGyDnrOWgjMhJ7eqKaBz9NzILRciI8zw8toQEvWeL2Py80e2dDRQHzta1+T1kdsZ85wdG5uDsPhEP/2b/+G999/H91uF36/H/1+Hzdv3oTb7cbW1hYajYZ8cbZy4hcFIFmgUCiEUCgkHoPf78cbb7yBdDotZKrX60Uul8Pi4iL++q//GmfOnJGUNzk6fRF0SGtjf1AM2mw2hVSemZmRsj4AQlp3Oh1pgGo1ZIR1Y2FWjVlyLj6GquyYwUyfbrlt48lgNUjUk05zIuhpcRIbkw8Ea48pBOfgKmbdqaNlAqnf70tlC0PixcVFXLx4UaIw/qbeksmISqUixQNHxZEMHTkukpYaJBRdLheSySS63S6CwaD0lfN4PBiPx2LMOFGIWVcKejWRzVbNXq9XPDLe5Ol0GmfOnBEvsVwuw+12IxQKSSbWxvHBnVU3xqSGkTIgLT4FHl1Y07xmranT4akWE2uPjuVKLA2z8eSwXg96bbp2mM9hsgHYvc4ej2diED2TUy6XayJJpWe06AiA4l86NF6vF9FoVCohSINZN0N+jhYuHwUnrpZlYbYu7KacZGZmRua6vvjii3Iz6w4mwWAQs7OzsnDYTZi1lMPhUPRcbrdbCviTySQWFxfRarVkjus03m2/k2WT2geDHh3JZqfTiXg8jqWlJWneoLV1rHM86LzyWrjdbgSDQQwGA3zyySeo1Wr45je/+cjz6d1R5GoX9z85rN0/NEfHygNtpEhB8DmhUAiXL1+Gw+FAqVSSKK5er0/IiJhE4OsZrXFWhGmamJ+fh8PhkEa6HInKJKYOh7nmO53Or5eho6dn/RsztSsrK1hYWMArr7wCwzCQyWQwGo1k7iu9NHIAHo8HL7zwAhYWFlAul5HP5+F0OlEoFGCaJorFonCEc3NzKJfLoumyehCH0XXZmARvVHrbAETvFg6H5dzR0DHjxjB3GvTi4HCVBw8eoN/vTxDUXJj06Dgkye5LdzhY72+OQLBWsACY8J7r9TqCwSDOnj0rnUV0p2lGV7rxKj05qin4f9azsxO4y+WSNlEsBSXlwWQEE2HPPHQ9DBwOB0KhkEz0qVar8Pv9MvHr7NmziEQi2NzcRDable6kLpdLpAU6fU1jxd29WCyi0Whgfn4ekUhEGgpo0eo0A3ZQNtDGo+Cuqjs105jV63UZQK1FooT1BuUGpLuhsHMNZ/+Wy2URpCcSCXkPwzBQrValssbG0UFtIqkgnfXkhsVO35FIRNaltekmgEfWmy7X01QGrzUHXdXrdWnXNRgMEAqFhOPTZYafibzkMGBHgqWlJdRqNZnvWSqVZLyZ2+3GjRs3cOvWLdRqNeRyuYnRdwxT2X1WN/PL5/MiZuTfmA3kc3U1BGAbtaOA0p1msyk3LuuX8/k8fvKTn+Du3buSKedmo294HRZpUTFLBNmc0ePxYHt7W8Tly8vL0nWG3S8AiNdn4/AgH9rpdKQxBq+JNnatVgvFYhF+vx+1Wk14dN0kgx7heDwWz0574GzZxqRgMBhEOBxGs9lEqVRCsVgUzp7JQXrxuoHur1XoOg168AkrJiqVCkzTlNpXt9stshKeIAoZa7WaaLjYBkp7eMzwkLTkSTkoZLKN3eGgKyN4XrmrM1NOb1obtCe9OfVGRPV8LpebGIfH92ToardrOh64xqYNiOL60UoFJoko7Nfdo8nb6sSRbsbAfoNMNnk8HpGNWJNKWm2hfx8HT93QmaaJer2OXC4nXQ76/T7ee+89afKXSqUmlO50ianEvnv37kRvKp5Yt9uN2dlZGbpCg9hut2WQrl5AvAi2kTs82BeuUChIBoz8TaFQQDablb5l1maKwJN50UxcjUYj/PKXv8TOzg7u3bsnXTC4oVGC0Gq1nup3Pu0gB8ckhJWjMwwDfr8f8/PzCAaDKJfLME0TDx8+FAkZvXY6HXooEr05hsc0dplMZkIWxHEHwKMDfGhsj7tmn4lHxxibnSmodmYDgGmzPIE9boelZXqYBvvOsWSI7Xx0sTkwfYHZxu7w0F1oYrGY9A1kbTM3MH1THsbIab4OACqViiyOcDiMwWAgQmJqIu1reDxor8vKq/LfzIgzZNV9AXk/cM3Rg9cendUbG4/HIkWxNtt4muvymRg6HjynCGmFND21ZrMpE+Cr1SoCgQDOnz+PQCAgejxCL7oLFy4gEolI66ZWq4V+vz/R5G+/47Hx5Lh+/Tr+9m//VnZoYJdP8fv9+N73voe33357YgMC8IhHTViz4ZrHY58yCkh/7/d+D6+//rosHFa0+Hw+XL9+/Rl889MHUkn0urSBoZFijWo6ncbVq1elTt0wDMzNzWF2dlZ+5/N5rK6uThTu85pS++r3+xGLxYSf73Q6WF5eRiqVQr1el2af5OX2M7xHxTPrOslFwB2A1p4Lp9fryXQpJhRisRji8bhUQ7BUhIJln8+HS5cuIRqN4sGDB8ID7leaYhu4oyOdTou+kf0Guan87//+70S7be7OxOPK6zSXx0429XodnU4HFy5cwJtvvvn0vthzCBoh7YFxvWgD5fV6EYvFkEql0Gg0kMvlMBwOEQ6H4fP5sLy8jHQ6jdFohLt378prdRLK7XYjHA4jGAxKP7tCoSBt19iKi4lHa8cb4HhDcYinbuhYBPzCCy9IJ4ROp4NCoQCn0ykzWzlPYHZ2VupXI5GINNUEIGlpilGt/e8cDgfC4TCWlpaQSqXEa7Q5uuODpLReEEwsWVXrVLQ/Drr6AZjUzDE8Yvugw3ZCsTEdvG46mQdMnnsAUm6pe00yk85u4Kxy0muKz9OeYSKRQCQSwcLCgnCs9M5Ztjk7OyvT/ugEMRw+SIv5pHgmhu7cuXMwTVO6h5TLZdy8eVNaO7E+EoCIih0Oh+ikWJDPNuxs9GiaJnK5nAgSaQBnZ2exsLAgGVxrCGsbu8ODXjRBZT1nfernWRfNYT9DGzhm0a11szaOBnJkbJs2TfoDQDqPsMSPCYvxeCy8OBNHml/VWVryuHNzc4hGo1haWsJgMMD6+rrwuZwhm06nZdC8pjLodR63B+FTN3Tk4dgDng32aLg4AKXb7U4Mw2C1BIXBdH+15MQ0TVQqFZGVsNVMq9WCx+OR7CvlKzwe28gdDXr3ByALhh1npskUjgJWxFCc2mq1ZJPTBtS+jocHPSVmQHXYCOyVcDGiYpKPGVRd1sVKpmazOZFQ0MaTRflsCsD1yXZe5OPYYJUNPK3vRe7uqH0In4m8JJ/PY21tTVzmWCyGS5cuIRAITNS7bWxsSIjSbrdx8+ZNdLtdnD17FolEAtFoFLFYTLJ8zOSOx2MsLi5idnYWlUoFd+7cQbFYxOuvvy4SFJ7Ik9DkPI/QrXXoKZfLZWQyGfR6PRk8zZtQ37BWb9oKPs6b2+l0IhKJwOHYbcmdyWSQSCQQDAYlbKZI1TZ2hwNpAToA8/PzE9IOOgTJZFKGw/d6PXQ6HTQaDYnCeK15na3DyYFdo1mtVmWWyPr6upRtcqIfk1cLCwvw+/1YW1vbt9UX5WWsnjgMnolHx5PDDKvD4ZDfvGGBvf5Y7D/Hti6cGM7eVp1ORxpxAhCOj33KmAbXfer18diL4/CwnkPusLpn2UmeV6tMxW6ffnKgR6drXK0iXfJyACZmdejEhR5hqTlUPodcLTO7TGLpNaj70unXa69d24ej9qV7Jh6d3vm73S5yuRzW1tYQDofxla98BXNzczLVq1wuY319XU5GIBAQ9T2banY6HelaQh0OZ0oAu7WR7Bw8Lftqe3WHh+beeD7Zh4z1r9aJXk8KXfVgbejIkFULTO2N6uhg6EnKR4tygb1uIePxbgeadruNnZ0dmRTm9XqxsrKCcDiMYrGIarU6UfPKdat5OiYc6Il5vV5p6cTJYNRjaiPJH9IYzWZTmuUetn/kM/PoSDSyR32v10MoFMLVq1cRCAQkA8SpP8DuYGT2jWdRL0tQ2JyRnl6j0ZBpYvF4XPrR2zg5WENQzdvo50yT9Rxlc+FuTh73JHVVzzMo6ZpWQqcTAaxEoSfFbsDxeByxWExmtwJ4pAMxsFfoz/tDN+WkyFiXa2qBOT16nfHVVNVh8UyK+tnOh1PBAoEAEokE/H4/qtWqGD6msmnxWQfHkJetXQBICyAWClOjxwnxXIQ6s6Rhh7BHg9XYHBSyHqbO1foa3uR+vx/hcHhqJ2H7+h0eulDeWl5F6QgVDMBeKZfb7RY+j625qtWqZF4Hg8FEa32WkNE4clAVm7W63W6USiXpTEzqidecxo/9LcPhsMhajjLf5Zm0aQqHw5idnRVJgtfrlbZNbKLILI/f70coFMJgMEC1WpU2MWzBTEKaU8WDwSDcbrdkcXXXBF12ZuP4sBoWhhzT2qVrWcCTeNbW5/B9GbrSE5h2HDaeHDR0jKCs55UTu7ShoxMyMzODUCgkg6ZYGqandDHU1NwdjV0wGEQkEsHi4qKsY3qWzMJy9gsjBa/Xi3A4LEZSV94cBs8kdKXFpqvMVufAbit19rlieQ+NIMGpYKyGoOXXHgMf00X99ArshXHyYGZ0bm4OkUhkQiiqz/e02RBP4ulxgdBDsGmIk4HV0OnzS4eBFQ3AnmfNlk0cDM/+hDRyutLCqs2j09Htdie6EZFuYjLL4/HA4/FMJBGnJSqOgmdi6Eha9/t98cZmZmYwHA5x69Yt5PN5ORlnz57F4uLixIk+c+aMhL7k73R3EgBSfsT5kyxFsk742q88zMbh4HQ6kU6n4fF4cOvWrYnGi8Q0Tm3ajcrwST9GI0cCXMO+dkcHBcNsa85B8tyoSA3xnGtHoVwuy/UIBoOSiKKom1lWcnWUnrBxLqcEUsNXKBRkPbPKgrXONJw8Phrbw7T+0ngmoSt3DQoRY7EYotEoDMOQuJvdDBiLu91use79fh/NZhOmaSIcDsvfGcN7PB4kEgnMzMxILV0gEJDPtL2Bk4fDsTfEmDfnfjjsjcnFwX/v9562wTs8NEenu5Zwo6KBmzaGgJQQK2G05ERLQnTmVFMZnObGWnZy8NZ5FdbP1Ymvo1JRz5Sj4zBbFvhS+BuPx2VH4Qi0druNSqWCWq2Ghw8fot1u44UXXsDLL78MwzCkzTbLw5aWljA/P4/19XW4XC7Mzc0hFotNkJe2N3d0WMNSp9OJ+fl5JJNJzM3NSXIIwITC/SBMew53bfaam9ZF2JYHHR2maaJWq6FYLEpHIO05M+nj8/nkmjOM5A8n7bFskwZQN3PQHjmL/FkR0Wg04HK5pEWbTiICmAhZWRnDXpYcysQxC0+KZ9K9hHoYn88n9a702jjdS6euyRMEAgF0u12RlACQRAUXALOtJDqj0ahkaWzl/MnCei7pTeubGXi0t5yG1Ujt520/rku0jaOBnLmWl2jBr3XsgO5wwmvBRIGWp+zXoEELiXlNnU6nZHP5/johon+YvWUxgB6FeRg8M8EwB1UXi0XpCuz1evHqq69OzH7UfcfOnDmDVCqFdDqNXq+H+fl5ERbmcjlp72SaJl566SVcvXoV/X4fy8vLiET+X3tf9hv3Wb3/zPKZfR8vsZM4dki6JDRV01JCFdpvi1SBQCx3XCGukCpu+Fu4QXDJBUj0BhBcIBCRChEUqjYlTZvVrWPH++z7/rvI7zk+83rGW+w0td9HsmzP8pmZz2fe857lOc+JolwuY319Xaa+Wxwc9JdPLxST5b4d+HjmhvZCJbAYjk6nIx4dq5wApCBIB0SrlWhPi2Ekb9PN/vo7YBpHAJK7M9vFdDdGOBzuG8BDalk0GsXy8jIAYGZmZtef+7EWI9gEDkAagqemphAMBqWCUygUsLS0BOBhv12320UqlUKn05FOh3a7jXw+j3K5LNLeiURCuHmcQ8F2MjsW7/FhL10oNIz6S697Zi32D1yPFGOgJ069R2AjAht27k1iL49rGrVBr83ncX6EuUGaRRBWa0ulEkqlEiKRyJ4Glz+W0JV5Fw5X8Xg8mJ2dFWVgv9+P1dVVGabLpmGqVZRKJdTrdSmLVyoVGXpN769YLGJ+fl52HFaPRkZGcOLECQDbz3W12Bu485sJ6Uc5nla3sdg/MOfGzZ8bjFYmYc6MnpcOK7XnpsNaXis+lqwJDq83DSL5lWRF6KliesAVj0tHJh6P77qhH9hHQzeMVsD7KPhHgxUKhaRdy+fz4fbt25ifn5ddggUGx3Gwuroqw3Ip3UQ3mAKAuVwOAFAqlbC8vCxSzwD69NKsodt/6BBnr+fX/M5Eo1EhpFrsH3QFk33iHBDNcLJWq8lQctPQ8Rg0TFyL7FBijo9sB1JR9AaoeXY0dJxd0Wg0RKat13s4PjEUCiGVSiGdTiOVSu26zxXYZ49uWMmfki40brFYTHIB+XwenU4HpVJJys+O46BeryOTyUgfK3k/7IjgjkC6ycTEBI4fP47V1VVUKhVEIhEb9uwzBuXaBtELdgIdstAbHPZ6FvsHj8eDWCyGkZGRvvGV9ODGx8elw2h9fb2v6sqQ0RxCxWliLApq2kqtVpPqLm9jFMZIT/MoaSwppmtKvu+1y2lfPbpBC8HleiiiSAOXSCQQCoUwPj4uYw+ZZAQ2YvNms4nl5eW+kxaJRDA+Pg4AUs5mlfaVV17BCy+8gNu3bwtfTwsKWjwaBhkyfvG4u9PL3g7ml9U8rm76tsZuf+E4DmZmZtDr9XDz5k2ZthYIBJBKpXD58mWEQiH87W9/wyeffCKCqoM2MxYPmW6iE+L3++U+emh0YMwCk/7+hEIhTE9Pw3EcZLNZEdNlS9kTzaMDNjw6NveyUZu8Hd2jSnIxCaPAQ06Px+NBJBKRUXts8eIQD7KneWzOl+AOYbH/2E0+Toc/WpRzK9iRhgcDXWhgXytbKFOplKwfANIWpq+Zed2oGkQpJopysIAYCATgcrmEm8f3QE+NTQHso6Vd4HeFxnaryX7bYd8M3aAeRu4AWo0UeJh/eeqpp8RLIyl4cXGxT110dHQUXq8Xx44dQyKREFJjoVDA7OxsX/Px/Py8xPlTU1MIh8OYmJiQkXz6fdrFs3cMyr/qYsRWrV7b0Uz0QmLrj92k9hfd7sOB8uvr6ygWi6hWq8JtjUQiePrpp5FOp3Hr1i3U63VMTExgampKmus51YtUEHJe6dk9ePBAKF+9Xk+OzShL2wm2g9VqNeTzeYTDYTzzzDNwu90ol8vI5XIYGxvDxMQETp48idHR0ScjRzfIiOh2EP5P74wubjKZRKVSkXwdB2ew8nbs2DFp7KdFdxynL1SqVCpYWVkRUQCSktkKpt+fNXR7w1bnTe/UQP8Iw62eo3d2M+k9jPBtr9/eoYsRWneOnhe7l0ZGRpBOpzE5OYmZmRmhbXEEYiAQEGI+11SpVML169dFjg0A4vE4ksmkRFuaRsQ+WXZBhUIhnDlzBgBEKSUSiYj+3RMr06TjbyY9qWRSKBQkVxcKhRCLxTA9PY3FxUXMzs6i1+vJpKFGo4GlpSUJe9fX13H37l20Wi0kk0npoMhmsyLUODIygqmpqT3Lulhsj0H9jLrCDUCksvh4YHPIy7CJ3xUtwc1JcBb7g2AwiK997Ws4e/YsVlZWpJXS5XLJtK5AIICXX34Zp06dktnKvEYej6fvt3Yc/H4/pqenJe3EfB3XoFa4ASCcuFarhbGxMdGe6/V6+OY3v4nz58/LxLFoNIrjx49LOmq3OFBDp5nU/KlWq1hbW8OtW7cQDofx6quvYnJyUmL7TCYjaibxeBx+vx/ValV0ySKRCDKZDO7fvy9VmXA4jHK5LNJNnU4HJ06ckCqt3gGsN7B/MD1kGjrtnbHqNqhbghthOByW2ziAnGkInau1eHQEAgE8//zzEsJyNgtlypk7f+655/Dcc8/t6tg+nw+Tk5P78j4vX768L8ch9jVHp38DGzyZCxcu9JH8Op2OCHA+9dRTSKVSItnc7XbF9Y3FYtKWwmSkx+ORAdUAZFIR7+cCSqfTOH78OOLx+KYdwBq73WOrc3bs2DG89NJLEoKwUg5AZnwA/Z4c83oul0vSDOyHZg90OBzG2bNnD/7DHRHoHmSXy9VXJAgEAn1Ogb5WO2nhG9YRw+frTXGrlMag1zBffy/r17VNHmVfavuUhCGazabILjHhTO8sl8thfn4eAKQxn0aMKgbMJQQCAYyPj0tVyDSyrLjq0HUY128IDqtF3FfOxuzsLG7evIlCoYCFhQUJP5m3oegqvTNeD4ZJVJUOhUIYGxtDJBLB2bNnZfbHXkKVbXBYrysw5NqaRF1tcAYZM/4/aPSg2RwwrHtCe+2UYiJ1aNBx9HvjbXqGBV9/G7GOgXc8FnqJyWfjUFzNh9HzIUOhEABIIYHGkNOESExkRYeyzDsxYNab23+wosYmcb25sOCkF5BWs6E3wb95XSmfbXFwGOQhmW182hiZf5vemfn/oL8H/ebzhnmF5mvuBdt5dBYWFhZfeNhypIWFxaGHNXQWFhaHHtbQWVhYHHpYQ2dhYXHoYQ2dhYXFoYc1dBYWFoce1tBZWFgcelhDZ2FhcehhDZ2FhcWhhzV0FhYWhx7W0FlYWBx6WENnYWFx6LGdeslj6fjvdDp4++238Ze//EUUEyi37nK5sLq6ilKpJDLPp0+fxre//W0kEglEo9GDkPEhDqvUyVFXcjis1xXYw7U1VUoGKQHl83ncuXMHDx48wM9//nN89NFHMr602WyiVquJFBPwUIqt1+vh0qVLeOONN3Dq1Cl84xvfQDgc3vK9aEmoPSqVfH4yTcPQ6/VQrVZRr9dRrVb7RplxVBpHH7bbbbRaLTQaDdRqNRSLRZEH0oN3LCws9h/dblfUorVwKkchttttAJCRhlSJ5myIer0uwrqfx1p9LMKbwGAtqUwmg1/96le4fv06FhYWsLy8LLuCHlrbaDTQ7XYRDAZFryydTmNkZAQ//vGP8cwzzyASiSAYDMprAfuiPXdYd37r0R1e7OraDhK/HITr16/jF7/4BZaXl3H37l2USiWcPn0aU1NTKJfLWFtbg9vtRjqdhtfrFcNWqVRQKpXw3HPP4a233sL4+DjGxsb6JvMNej+PsHY/P4/OFNkjqtUqrly5gitXrsguQEHGbreLSqXSp0LsOA4cx0G73Ua5XMbExARef/11nDx5En6/H8FgcMfSzxYWRx07NXLAw9D1/fffF2eEA6hOnTqFXC6HbrcLx3EwMTEBn8+HWq2GVquFa9eu4f3334fH48HKygp8Ph8SicRQQ3dQa/axGDpTQbRQKODOnTuYn59HoVAA8FBNmNOCqEicSqXQ6/XQarXQ6/VEbVi7we+//z6q1SouXbqECxcuWONmYbFD6NGDHGy0tLQkE/Wq1SoymYwMozIVpHV6KR6Pi/R5q9WC1+uVqV7xeBzVahV//etfkUgkMDo6ilAoJHMqfD4fgsGgSOhzUNZexhoOw2PL0WkDlM1m8c9//hPz8/PIZrMAIPNYacwcx0EwGITL5UKlUpFZr263W2L+TqeDq1ev4pNPPkE6ncaFCxc2vZaFhcVw0NgxSvr444+RyWRw+/ZtrKys4M6dO/joo4/g9/uRTCbFCeGcl3q9DrfbjUQiAQCSZ+fc5ng8jnQ6jVKphN///vdwu90IBAJwHAeJREJmw6ZSKUxOTiIajWJ8fFwGY+0XDtzQseDQbDaRz+eRzWaxsLCA+/fvY3V1VXYEjrbjPM92uy2Vl2azKWPwPB6P/A1ABuDOzs7iP//5DxKJBI4dOwbHceD3+22RwsJiCAqFAkqlEkqlEtbW1lAsFnHz5k3k83ksLi4il8uhUqlsqoDSGSmVSpibm5Ph18BG1bRcLsPtdqNYLG4aUMXHcAwm13e73ca1a9cwOjqKL3/5yzI6Uc8bOaiZEY+ctO50Ovj000+xvr6O//73v3jnnXdQLpexvLwsrjLntmqaiOM4iEQi8Hq9Eu/Lm/r/8z89Ho9Mikqn00gkErh48SJ+8IMfIB6PS77gEXBYXUNbjDi82NG1Zdrn448/xt27d3H16lXUajVUq1VxNhjStttteDweibQSiQQcx8H8/DyWlpYQiUQwPj4Ol8slhUSyKTjBD+gfnqPz6Bxi7TgOkskkkskkfvazn+GNN96QEad6itk2nt7nU4zo9XrI5/NYXl7G0tKS5ADo5QEbb5yVVj6PeTj+1sfkCeDzisUiarUalpeXZQD2yMjIoxo6C4tDi1KphJWVFaysrEh0RYeCnhMpJNqT4t+kezmO0xeZaUoJj8FCI7Dh0XHYfLvdRqPRkEiu2Wwim82iUCjIpL9HTUcduKFrNpu4evUq3nnnHaytrWFpaQlutxsejwc+n09i+WaziVar1UdW5MljyKrJxPQAQ6GQhLPVahUffvghyuUyZmZm8JOf/GRbgqKFxVFEt9vF7Ows3nnnHRQKBUkHRSIRuN3uvsHT/J9GrFqtwuPxIBgM4vjx45ImAiCPoXEkgVhz7fQsWNLJgsGgFETK5TLeffddVCoVXLhwAV/5ylem5UBbAAAcrElEQVQ2hb+7xYEaOn64xcVF3LlzRzw5x3HESnPINE8CsLFjdDodMYoej0d2Aq/XKxPd6VLXajU0m03kcjncvHlTdpVHiestLA4rer0eCoUCHjx4IAUEGh1WVAk9lBoA2u02Op2OpJoYntIYdrtd8eLMmbE8nh5YzTXebrdRq9XQbrexsrKCUCiEEydO9L2PveLADF2z2cTq6iqy2SxWV1dRKBTgcrkQCARkYrfb7RbuWyAQkBCVBg2A7Ao0iOyC4G9eGBYeOp0O8vk8VldXce/ePfR6PRw7dgyxWOygPqqFxRcGOqxk+oienA4lBw23No0WQ1e/349UKoVOp4NsNjvQaQHQ55HR6JkpKa7nSqWC1dVVlMvlTYOs94IDM3StVkti/2w2i2Kx2Dd9nZZc82VcLhdarZZ4YkyI+v1+4duYfa08CbyPVaRcLof5+Xl4vV5Eo1Fr6Cws8HC91Ot1VCoV1Ot1NJtNBAIBBAIB8fLokXk8nj5DZFZftVGMxWJotVrI5XJy/zAPTHt2NK4AhHRMSlkul0OtVtuXz32gHt3KygoWFxdRKpXkpHQ6nU2hqbbk7IDQCUvex/9N0CjSbWZVdnl5GT6fDzMzMwf1MS0svlBot9tYX19HLpdDqVSSKMqsiOocHdBP8dC5O6/Xi16vh2KxKOtPQxs1OjTM4+nj8nkMa2ngKpUKms3mIxOID8zQ1et13L59G3Nzc8hms2i1WlJwAPoTkuTl6JwdyYgsPgxSVAA2KrV0oxuNhiRMb926hWKxiPPnzx/Ux7Sw+EKh1Wphbm4OCwsLWF1dRafT6XM4gM2tYbzPNGI+nw9er1dyato704aR+T+z6sq1T0eF69/lcqFUKqFQKIhX1+v1pIFgLzgwQ9dut1EoFJDNZtFoNOR27h4ET0Sn05EKjflh9A6jLwKfSwoKW8VY5i4UClLRtbCweLhmyuUyCoVC37qkwQOGh5yD1iVhGkF9P50UMxpjKMz1T2PIFBZbzJinCwQCT56hq9VquHXrFm7duoVyuSzFglar1ceBI4UE2GA+69idhpFG0Exe8gLV63VpR/H5fOh2u7h79y7W19eRz+cP6mNaWHyh0Gq1sLCwgNu3b0s+rdlsolKpyGN0Lk57coMMHcnEJqmXRo2FQwCbiow0bI1GA6VSCT6fT/pcu92u8Olu3bqF0dFRoaLtBQdm6LrdLkqlEorFYl871zDPTHt0vI0nTru/g55Hg8iTTI2scrksu4OFhQVEFahYLIqTYdK7iEHek5mr49rUTApt0MzjDMuxc/3SaGoubaFQEHbGXvFYQlefzydVHRonnaNzuVxyosmLozurDZjO02l2dqvVkgotiYzNZhOFQkGY1hYWFg/Xy2effYYbN24AgDTjM91Tq9XQ6XQkAjMdCz4WgKxP9rpqg6Ufx7XN2+nlaRIyCxtkV9DglctlzM/PC89urziwjncqklarVaGI6O4G84eemTZummujTwrQ7/HxeTxhjuPA6/WKGvGjnCALi8OETqeDTCaD5eVlNBqNPnk0enaDHAvCjMiYbiJpmF6dTk8B2NTKaZKQ+Vw+jzzZer2ObDaLUqk0MA+4UxyIR0fjww+mDRZjeqC/8qpPnm77YpKSeTrtOrMZmB5du92WKpA2imwr4W5hYXFUwXVEx4O3+Xw+tNttOI4jRT1WQs3WK23k9DrjbWbPutmMb3qEAOD3+xEKhRCLxeA4DsrlMrrdLgqFAu7fv49YLLYpJN4N9t3QDauE8j5d2dE/wIbnpvvggA1Xl+6tlnLS8yR4obT73Ov1UKlUUCgUEI1GraGzONKgUdMRFqMgAH1FBSqKmB0NOq2kjd2g/DvtgHZU6L2R78qe91AohHg8Dp/Ph/X1dem0aDabSKfTjxSZ7buho64cpwBp8CQNkmvhc3Vi1DSQZkUWgPBwdO7OvDAsUVsj9/mj3W4jl8tJHshxHOtpPwawiknJM65DOg96HZlRk+mQ0GgxL86mfJ3jM6u1jMp0KKw9PzM3r40vJZ+eqGJEq9VCsVhEuVzexMvhyWb5WHc78KRxp+B95Nno5+uTxeZ+PpfeH3ePbreLTCaDhYUFeDwejIyM2Cb/A4L5RRx0niuVCj744AOUy2VMTk6KAu3Y2NjjeptHEs1mE5lMBuvr6yKAAUA2G/JNGRFxHdJxMfvNNZHY7/djZGREFIToXJBtYf4A/YwJt9uNUCgEx3FkTAL1KKvVqgiAPlE5OhojGi4TZlna3EH0cXgiTZ7ddkRFfUJZ0TXFOy0OHvrLzEXASny5XJb5H16vF8lkso9ztRM0Go2+PK1efJTaj8fjMh/4KG9wJN+yO0l3KOmU0KCWLz5fk/3N82l2U+jIyvx/kF3Q3D0aP9LNeI1pN/ZyHQ/Mo9NVEv3ByLNpNBpSTtbVFu1G82LoPlgWKFhwqNfrchF10pOadeyb288GYYuHMOkGgyp0q6urWFtbw+3bt/GPf/wD7XZbZLffffdd1Ot1fP3rX8ebb76JcDiMVCq1I2PXbrdx584dLC8v48GDB/jss8/g8XgQjUbRaDRw7do1FItF/PCHP8R3vvMd+Hw+hEKhfT4DXxyQ7pXL5ZDJZJDL5RCLxZBIJERFSEdeDE+1mhA3Lt3s7/F40Gq1sLa2Jk6Ofr7O2ekITxtBvqbmy+o+WrZ20lCbecOd4EBydHxDW1VJGK5SU05j0E6hdwVNP2HSVBcgAEjxgh5dvV7vaxGzeDSYlbZhHkCpVML6+jrm5uZw7do1uN1unDp1Cl6vF/Pz88jlcpiZmZFpcIlEou/7YEYARKvVQiaTweLiIu7du4dPPvkEjuMglUqhWq3ivffew9raGi5fviyy+0f52tMI1et1MRpcD8yHmRHPsHyavvZ0PNiPqrlyQH83hD7/W3Vb8HatIM6ihtlYsFPsu6FrNBrIZrPI5/ObwkptrMzysy4waIKvztEBkIuh8wNerxeVSmUTL49gyERpZ4vdYZCBGGQw6vU61tfXUa1WMTs7i0KhgNnZWczPzyMcDuNb3/oWQqEQJicn4XK58Pe//x137tzBwsIC/vCHP2BqagpvvPGGTIbyeDy4f/8+lpeXsbi4iBs3bvTNMshkMuKlRyIRJJNJnD9/Hl6vF88//zxarRZeeeUVmT1yVI0csGHoOp0OotEoksmk5MTYNklvjMR7YCMCG6Qlx+Pq23QH1KAcPbDhhGjDyvCU74cGWDcG5HI5BINBpNPpXSuZ7LuhY0cCixFmuVmfCLO6Q+/MpJ6YOwWfq0mGbFA2eTwApOpqOyR2B3MH385QNBoNrKysIJfL4V//+hcWFhbw6aefYmFhAZcvX8b3vvc9JBIJjI+Po91uY3Z2FsvLy1heXsann36KZ599VmbzksS6vLyM69ev48MPP8Sf/vSnvupbOByG3+/HqVOnMDMzg9HRUTz77LOIxWIYHR0VMqyt6ELWVrvdFhoH+0w5QpS5dYKV1WFe16D/tRI41ymNpRmdmesfgLwfRnq6c4qalvF4fNef/8CKEZo/xzif/3u9XpFSJwcO2MytG8Sn0/wbLgj2tnIOBSs+zP9RzFOrNVhsD70h6S8lPYNSqYR6vY5SqYR8Po98Po/PPvtMwpjR0VGk02m8+OKLeOqppzA2NoZwOIxAIIBut4tz587B7/fj1q1buHHjBnK5HN59911Eo1Gk02k4joMbN27g7t27mJ+fBwBEo1FMTk4iFArh5MmTSCaTUrVNpVIyHDkYDMqwZYuHa5BCm6xoBgIByWMzpNVOBZ0UU3BTg54yDdWwnlmTnmLSTbh+4/E4PB6PvB96eexy0rn43WDfDR0rnOTTAOiLr10uF/x+P0ZHRwFApoLpGRA8Afpv86TUajW43W6kUilEIhHpb63X65LvoTJxq9VCPp+XC2mxc5hf8E6ng3K5jHq9jtnZWaytrUmOrFAoYGFhAX6/H6+99hpmZmZw8eJFPPvss0JP0NfxzTffRLvdxttvv42PPvoIc3Nz+M1vfiNFBa/Xi8XFRayurgJ4uKjS6TRef/11TE5O4tKlSzh9+rQsHE19OOpVVhP0iMrlMoLBIJLJJILBIPx+P8rlMnK5nJDwzXz3II+OxQYAEoaaaSht0OjVmbfpSqvH48H4+DgCgQDm5uZQKpVQrVZRLpf7fvbSIXEgnRGm0ih3BvagMqQA+nNwWrVAV2DM3YC/9QXQ/2syJAnI9PIsdgd65/V6XRQvqDGYyWRQqVTgcrlkvi7nd4yPj2NsbAyJRELk802QKJxOpzE9PY1CoYDFxUW5Xh6PB4FAANPT09I4nk6ncfLkSYyNjSGZTA6d8vYoVITDCBb/tDHTbAeuN10kYBhqnsdh51TfrlVMBm08ZjqEoTUjNYbZAMQz53vfi7NyIKErq666rNxoNJBOp5FOp2VHoTYWTwhPuM4LUB0B2Dj5vV5PPrxOsvK5jPOZ56lUKshkMqhWq/v9cb/Q2C731uv1sLa2htXVVaGHlEolLC4uotPp4Pz585iYmMD09DRee+01OI6DYDAoHpnP50MwGNz0egRf96WXXsL4+Dj+97//4Ze//CXy+bwUGX70ox/hu9/9LoLBoGiVRaNRGXU56LNws2XYZVIZjiJIxapWq+Ilse2KFC3toNADBx5udjoFQKPF57CljGkNrsOt3guPpwdet9tt3L9/Hz6fT74DXq8XIyMjCIfDaDQaMmB7tzgQeskgjw6ASCiRja0JiBo6CT7sy2kqI+i2E51bADYG7VqPbgPD6CEmyuUyVldXsbKyggcPHqBcLmNlZQUApIodjUZx/PhxBINBSXLvBszLZDIZRCIRkdHudDoIhUI4fvw4IpHIjrpa9HfHpik2oMnbWvRCbwT6scDWG8NOqvBb3W5+/2j8WPnVIxgdx5E5MqaIwE5xIKGr6dGxxYRJz1arJaPW2Dis27t0uKrZ1IN2at06xvsYIjNH1+l0UK1WbTFCYSfeTafTwb///W/88Y9/RDqdxsWLF8XwhEIhUX1NJBJIJpN9qYfdvKbP50MsFsO5c+fw05/+FIuLi/jtb3+L2dlZvPfee6jVarh48SK+//3vD1WYNY89qHfzKKPT6aBSqaBSqcg60b2vPE+69cssIjKiMtNJLHTwb6C/O0mLdQAba1kPrddeN9MfnNdMo0cV8SeiGKHL2JpbwxI/24GoPKI5O7rHFeivzvB+uq2aDKwNII9H15uCfabGncX26PV6mJ2dxdWrV/HSSy/hlVdewcTEBC5durSnEv8wME907Ngx/N///R8ePHiAK1euYGFhAXNzc8hkMgiFQmi32zuW0rYGrh90JOgx8Tau1UFUL3OtmEOqdCFB/w9srE+zwZ+vq19fq5nwGFpOnY/V+cXd4sAUhgmXyyUKFe12G/l8fpNWnUnmNE86T5pZrNAGkDQVzeHRCWlr5DaQy+Wkcq17CB3HQTgcRq/XQz6fR7VaRavVwsTEBKampvD0008jkUhIm58Z4mxlXPRGYxYKdKqB3t2XvvQlVKtVrKysYGlpCR988AF+97vfYXR0FBcuXJAQlwTTYeEyjx0MBpFIJOByuYYWMA4ztEfEc8+OoW63Kx5wIBDoI+5vJYuu/+c65VrVxsw0hOY6dBxH0he6CKlFdPl+tKHeDQ7E0OkvM7ARupbLZVkgmmoyrKVDV111KGLuEL1eTyqDg4yZNXD9YF9iNpsVVYhut4tQKIRjx46h2+3i3r17yOfzaLfbmJqawpkzZ3DhwgV4vV6pturzSiOnVWM0dGM2vXAzqR2JRDA5OYlEIiGUlCtXrmBubg71eh2rq6s4ffo0IpEIJiYmsLCwgHw+v2nOgAaPPTo6ipmZGXg8niNp6NimxTXCqijFD7RXxYKiTvUM28A0GZjRlL6melPTbWHaPgQCAaRSKQAQD5N5fIbKTIk9MTw6YHA5mTCNoG7U14aM9/E52+0sw3YOM+lpAYRCIdnhtRSPy+WSLxKpHexiSCQSyGQycLvd4pXr3IvmRgGbzzW9bn0tTW4kK+zNZlOIwefPn5dqbjweRywWQz6fh9vtRqFQQLVa7TOwZljFxHsoFEKtVnukIchfZHCjYbrI9K54/agrZ2rWmddKR1ODoNe5TkmZdoHfC13ZZY7O7/eL7JM+5l6w74ZOJyxN6KooH6vL2Jp0qMmffI52jfXrAeg7WSxZEzqxagHx2gKBgFAN6NnR4w6FQgiFQhgbG8NXv/pVNBoNfPjhh30hKBeDng+w1W5rVtO1ceS1vn//Pjwej9BWXn75ZfR6Payvr2NhYQGtVguzs7O4d+/ewJyRuTD10HQWTGZmZg74DD956Ha7cp01I4EhJ2emkiZSqVTQaDS2bKHbieFhHk6TxfV3hST/YrEIj8cjfcmxWAzhcBiVSkW8PJPIvBsceI7OxLA4favH8m/t7ZkYViK32AymAZjwNUUWuRD4xff5fCgWi6jVan1fVGCD0b4TQ2fCNHQ8ntvtRjQalTYur9eLQCDQ1/lCcUYdsupIgt8Hj8cjZGNzYMtRgi4yAP30LJ4/tlDy+m9lyHa7vszHD3q+Gc1RjsmMAveCA6GXmLMi+EXmiSSfjVUZ/uZtZnFCa9QxxOUurUej8TF6qC77YK3h64fL5ZLWOQ4e0blPnn9dPZuenpbnm0UFfb12s4mZv3VRQlMZYrGYeKJaXmhYcpx/0wvw+/19mmtHDby2emPS5xd4eK1JwianjYKcWsVkkNNh0sC4Iepio8ljdblcQipPJpMANsRUdbhrsir2spYPbDjOoEQ1T6wW7jPzb2Z+T580XVEdJAFFKomZAD2qX+7twA3ki4BAIIBYLPZ5v40vNHTKaNg6Y8fRoIKCTisNWlNaWch8Hf0ahLYLDJmZNx6UW3+iQlftIptv0PT0zA9Nd5q8HhoqPhfYcLmZ19OGUnsfbAXj8fbKqLawOAzQDgi9ZTNt4ff7kUqlxNgxR8fN0OxkouPC55uimIOcHZfLJWu3XC6jVqshHo8jFAqh0+lIWoI5OeYP2VTwRPW60rAQPMlm07AGTxorPpqiwPCWYa0+rr6AmtPDk29y6ywsjio0b5UD3nVbWK/XQyKREMNCzhqjKR2FmekKrtlBGBTRMaylB+f3+zcpoNDQcTSjLkrsFgdSdR3m2uqQ02y01i1cWyVANcGVz9elbvO5Op9gQ1iLowodaekkP/DQSJVKJSlODaJuEcPWNX/rvwcZpEFhKAsPdGS0CC+dJu01PhEeHTCcIc+TbRpD9qya9A/T6NGl1a9BN5z3a/Y9YdUrLI46WKSjwjAr1j6fD9VqFevr6wD627m4rgbl9sxj00DSCzONI++jJ6fv08UnVn1JcNbtoiQMPzGGDtg4UXpkGW83K3SDCgsmqXCr8rTO0fFkWqNmYdEPXRQwc+hao86soGovTf/Wx93O0yNY9dXvg8UIsiXobQ4qSjwxVVfC7X44Qi0UCvXl28wcW6vV2qRWYlZqzJBXf+BGoyGP5VhEAEIr0SVtm6OzOKpgWKiT+gwJ6S21Wq2+EaT0ANlYz/VDr8tcsxp8LPN/OkenKWV8zWQyiXa7jWg0KoaQvbY8tikWshscSI7O/KHBGURE1EnHQSGmacXptQ3aafTkIs3RG8T7sbA4StAGiRGQKbQAQEQ0d8uL5GsMgpnDM9ctnSIqmXCN68Il7cYTk6NzHAfJZBLFYlHmRwCQJt1YLCYzHLrdLoLB4CZSrw5l+QH1DFh9Imj1STwkY77dbiObzaLXe9jORNfYwuIoQntUpF7R2+J8l0AgIKrRf/7zn6VowShM59q0E0FPy/TszCjONITseBkZGcHZs2dlTGatVpP3qG2ENsy7xYEYOm1YGo2GfFA2ZwMbCgb65GiLb54wGjfdvM3diSedhpA7FpOZukPCwuKoQovVst2P4SMdhMnJSUxNTSEajfb1IOvcHdDfAWHm2c1+9mHRFIsPkUgEY2NjKJVKUn3VXDry+oZVcneCfTd0qVQKzz//PI4fPw7HcVAoFETr//bt27hx4waA/vmPwEZC1EyGAugzhjyJDIUZrvJinT17Fq+++io8Ho80qodCIfh8Ply6dGmobpmFxWEG+WissmoSvzZKOmLS9A46GIPENgCIgTI1IwEIOVlHbFzDJPVHIhH0ej0REdBe4rBC5m6w74aOszzb7TYuXbokOmM+nw+//vWvcfPmzb4Tok+45vCYTceana0JjtylqLU1PT2Nt956C7FYbJPLvJVAo4XFYYaWPmIkZJL4AfQxJfT9dCq0oQM2qqh6jfE4/N+sonKta827eDwOl8slM2Xq9XqfUXvUdXsgVVfG9YFAQFpOONyiUqmIvrxOkJJfsxP+HZ+roYUdOUbvqCpVWFgMgpki4m28XRursbExTE9P9/HpGHHRITF5qzpE1beZa5XHTKVSiMViGB8fRzAY7BP61Ot5PyTWDpReQlluGqdyuYwHDx6IMdI7gW4LMUvI5o6iT6jeJbRaqjVyFhb9MLuIdHuVNkZerxcvvPACut0u5ubmcOfOHVEj1t7fIF6b9vTM21nc4LjKM2fOYHx8HC+++CLS6bSs3V5vY3APQadprzhQ6YphLGrtuQ0iEPP2nb4Gf1ulEguLwTAHx9Mr6/Ue9r5GIhER33S73TIovN1uy+yQWq3WJ7Chw1+9bgeFmSw8eL1eRKNR+P1+nDhxAseOHcPIyIgUEjlfhu+ReNRC4oHNjAA2G6tgMIjR0VEhJ2rok6X16LQGFgnG+ti8nW0tlAk39ayGudEWFkcB0WgU586dQzqdxtLSEtbW1sTrisVimJmZwZkzZxCJROA4Dl5++WWcO3dOBl43Gg1RFikUCmg2m6hUKjJgiemoUCgEr9eLcDgslDIOuOF9sVgMgUAAgUAAfr8fsVhM5sqcOnUKbrcbKysrKJfLEsXpkYx7WcOPVYyMuwqAvvCUhshMbBKDWkn0Y7RbzETqoNYR83kWFkcFjuNgZGRESLnMr5FWMjExgbGxMVlHY2NjGBsbk+c3m03k83k0Gg1kMhmRP6fkerValXQVp3qR7UA1FDoj8Xh8oDy7x+NBNBqViWA0xHo0whNTdQW2HlTMCUzUrtftJZoADGxUWsyQ1OPxSGsZDabeOczqqplstbA4amA/qd/v79OGpHQ+vSszjaRz6FSkDgQC0hqmuXgu14ZwJ6f7sYqrpdHNNlD9GrFYDNVqVbi4fDx5sE8MYXgrOI6DSCQycOg0jRtP2lZgrO9yuUQziz16PKmmx6d/W1gcNTDqoeglOWzskKARNDmsNER0LoCHYfB+wIy06NHVarU+Q8fcnX5fu8VjNXTT09N48803UalUkM1mJbbX49U0iZFJT3OGhN/vF+Y2bw+HwwgGg7h48aKcFA1r5CyOMvx+P8bGxuB2u3HhwgVEo1HU63U0m02cPHkSTz/9NMbHxyWkNLsZBv290zVlPn7Yb8dxhGpy+fJlTE1NAXjo6QWDQaTTacTjccTj8V1/ftc2FnJfe6ZarZYo/lJnKpfLoV6vo9Fo9IWx5Nz1ej3prCAY73MYMac8ka/n9/v36y0fVut41HvhDut1BYZcW66parWKDz74AGtra6jX62i32xgZGcH09DTC4TAmJyc3rR96XsyTaSWh7Yi8psAmgC1l1PTwq0GadjoEHoKBB37soStjbbZ4UKZFz3fVoWy325UKjrxpVcFhlYjtLRYWFpvB7iKulUAgIJO+uHbYxrUVTMdoN6GkJhUPex3yX/d7aNN2Hp2FhYXFFx628dPCwuLQwxo6CwuLQw9r6CwsLA49rKGzsLA49LCGzsLC4tDDGjoLC4tDj/8HH9ooW8oX+WsAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# normalising the values in the range 0 to 1.\n",
        "X_train_ae = X_train.astype('float32') / 255\n",
        "X_test_ae = X_test.astype('float32') / 255\n",
        "print(X_train_ae.shape)\n",
        "print(X_test_ae.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCF-SUsQY7V3",
        "outputId": "8ef38443-c879-44a0-8735-885ec637bb4b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 784)\n",
            "(10000, 784)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 2\n",
        "\n",
        "In order to keep a similar architecture in all three models, I have created layers in the following way:\n",
        "\n",
        "1. Input layer of size 784.\n",
        "\n",
        "2. Hidden layer of size 512 at both encoder and decoder.\n",
        "\n",
        "3. Another hidden layer of size 256 at both encoder and decoder.\n",
        "\n",
        "4. The latent space of size 100.\n",
        "\n",
        "5. Learning rate of 0.0001.\n",
        "\n",
        "6. Activation function is Leaky Relu."
      ],
      "metadata": {
        "id": "lxnf8_l6Ee-H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Auto encoder"
      ],
      "metadata": {
        "id": "DJGI9aUjkSRK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This code is referred from https://blog.keras.io/building-autoencoders-in-keras.html \n",
        "# and layers added and LeakyRelu activation function used.\n",
        "\n",
        "# compressing the image of size 784 to 100. \n",
        "encoding_dim = 100\n",
        "hidden_size1 = 512\n",
        "hidden_size2 = 256\n",
        "\n",
        "# Input image.\n",
        "input_img_ae = keras.Input(shape=(784,))\n",
        "\n",
        "# encoder layers\n",
        "# hidden layer 1\n",
        "hidden_1 = layers.Dense(hidden_size1)(input_img_ae)\n",
        "hidden_1 = layers.LeakyReLU(alpha=0.2)(hidden_1)\n",
        "# hidden layer 2\n",
        "hidden_2 = layers.Dense(hidden_size2)(hidden_1)\n",
        "hidden_2 = layers.LeakyReLU(alpha=0.2)(hidden_2)\n",
        "# encoded input image with l1 regularizer to avoid overfitting.\n",
        "encoded_ae = layers.Dense(encoding_dim,\n",
        "                           activity_regularizer=regularizers.l1(10e-5))(hidden_2)\n",
        "encoded_ae = layers.LeakyReLU(alpha=0.2)(encoded_ae)\n",
        "\n",
        "# decoded layers\n",
        "# hidden layer 1 \n",
        "hidden_3 = layers.Dense(hidden_size2)(encoded_ae)   \n",
        "hidden_3 = layers.LeakyReLU(alpha=0.2)(hidden_3)\n",
        "# hidden layer 2\n",
        "hidden_4 = layers.Dense(hidden_size1)(hidden_3)   \n",
        "hidden_4 = layers.LeakyReLU(alpha=0.2)(hidden_4)                  \n",
        "# reconstructing the image back to size 784.\n",
        "decoded_ae = layers.Dense(784, activation='sigmoid')(hidden_4)\n",
        "\n",
        "# A model to map reconstructed image to input image.\n",
        "autoencoder_ae = keras.Model(input_img_ae, decoded_ae)\n",
        "\n",
        "autoencoder_ae.compile(optimizer=tf.keras.optimizers.Adam(learning_rate = 0.0001),\n",
        "                       loss='binary_crossentropy')"
      ],
      "metadata": {
        "id": "1XB880jzkQ_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder_ae.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjNI0eF92Dnm",
        "outputId": "fbcd1488-26ed-498c-9890-fe69b9170ced"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 784)]             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               401920    \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 100)               25700     \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 100)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 256)               25856     \n",
            "                                                                 \n",
            " leaky_re_lu_3 (LeakyReLU)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 512)               131584    \n",
            "                                                                 \n",
            " leaky_re_lu_4 (LeakyReLU)   (None, 512)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 784)               402192    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,118,580\n",
            "Trainable params: 1,118,580\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training the model.\n",
        "autoencoder_history = autoencoder_ae.fit(X_train_ae, X_train_ae,\n",
        "                                         epochs=200,\n",
        "                                         batch_size=256,\n",
        "                                         shuffle=True,\n",
        "                                         validation_data=(X_test_ae, X_test_ae))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2msbwYTk_JS",
        "outputId": "99923248-ce95-4f12-8a89-56e47b3bd467"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "235/235 [==============================] - 11s 43ms/step - loss: 0.4465 - val_loss: 0.3582\n",
            "Epoch 2/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.3372 - val_loss: 0.3239\n",
            "Epoch 3/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.3192 - val_loss: 0.3135\n",
            "Epoch 4/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.3114 - val_loss: 0.3075\n",
            "Epoch 5/200\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 0.3064 - val_loss: 0.3032\n",
            "Epoch 6/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.3026 - val_loss: 0.2998\n",
            "Epoch 7/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2995 - val_loss: 0.2973\n",
            "Epoch 8/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2966 - val_loss: 0.2943\n",
            "Epoch 9/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2942 - val_loss: 0.2920\n",
            "Epoch 10/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2922 - val_loss: 0.2902\n",
            "Epoch 11/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2904 - val_loss: 0.2888\n",
            "Epoch 12/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2890 - val_loss: 0.2874\n",
            "Epoch 13/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2877 - val_loss: 0.2860\n",
            "Epoch 14/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2865 - val_loss: 0.2850\n",
            "Epoch 15/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2855 - val_loss: 0.2840\n",
            "Epoch 16/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2846 - val_loss: 0.2831\n",
            "Epoch 17/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2837 - val_loss: 0.2824\n",
            "Epoch 18/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2829 - val_loss: 0.2817\n",
            "Epoch 19/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2822 - val_loss: 0.2809\n",
            "Epoch 20/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2815 - val_loss: 0.2807\n",
            "Epoch 21/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2809 - val_loss: 0.2796\n",
            "Epoch 22/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2804 - val_loss: 0.2791\n",
            "Epoch 23/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2798 - val_loss: 0.2786\n",
            "Epoch 24/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2793 - val_loss: 0.2783\n",
            "Epoch 25/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2789 - val_loss: 0.2777\n",
            "Epoch 26/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2784 - val_loss: 0.2772\n",
            "Epoch 27/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2779 - val_loss: 0.2768\n",
            "Epoch 28/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2776 - val_loss: 0.2764\n",
            "Epoch 29/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2772 - val_loss: 0.2761\n",
            "Epoch 30/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2768 - val_loss: 0.2757\n",
            "Epoch 31/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2765 - val_loss: 0.2754\n",
            "Epoch 32/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2761 - val_loss: 0.2750\n",
            "Epoch 33/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2758 - val_loss: 0.2747\n",
            "Epoch 34/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2755 - val_loss: 0.2745\n",
            "Epoch 35/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2752 - val_loss: 0.2743\n",
            "Epoch 36/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2749 - val_loss: 0.2742\n",
            "Epoch 37/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2746 - val_loss: 0.2737\n",
            "Epoch 38/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2744 - val_loss: 0.2735\n",
            "Epoch 39/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2741 - val_loss: 0.2731\n",
            "Epoch 40/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2738 - val_loss: 0.2729\n",
            "Epoch 41/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2736 - val_loss: 0.2727\n",
            "Epoch 42/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2734 - val_loss: 0.2725\n",
            "Epoch 43/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2732 - val_loss: 0.2722\n",
            "Epoch 44/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2729 - val_loss: 0.2720\n",
            "Epoch 45/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2727 - val_loss: 0.2719\n",
            "Epoch 46/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2725 - val_loss: 0.2716\n",
            "Epoch 47/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2723 - val_loss: 0.2715\n",
            "Epoch 48/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2721 - val_loss: 0.2714\n",
            "Epoch 49/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2720 - val_loss: 0.2711\n",
            "Epoch 50/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2717 - val_loss: 0.2709\n",
            "Epoch 51/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2716 - val_loss: 0.2706\n",
            "Epoch 52/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2714 - val_loss: 0.2706\n",
            "Epoch 53/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2712 - val_loss: 0.2704\n",
            "Epoch 54/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2711 - val_loss: 0.2703\n",
            "Epoch 55/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2709 - val_loss: 0.2704\n",
            "Epoch 56/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2707 - val_loss: 0.2700\n",
            "Epoch 57/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2706 - val_loss: 0.2699\n",
            "Epoch 58/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2704 - val_loss: 0.2697\n",
            "Epoch 59/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2702 - val_loss: 0.2694\n",
            "Epoch 60/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2701 - val_loss: 0.2696\n",
            "Epoch 61/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2700 - val_loss: 0.2692\n",
            "Epoch 62/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2699 - val_loss: 0.2693\n",
            "Epoch 63/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2697 - val_loss: 0.2689\n",
            "Epoch 64/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2695 - val_loss: 0.2691\n",
            "Epoch 65/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2694 - val_loss: 0.2687\n",
            "Epoch 66/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2693 - val_loss: 0.2686\n",
            "Epoch 67/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2692 - val_loss: 0.2683\n",
            "Epoch 68/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2690 - val_loss: 0.2683\n",
            "Epoch 69/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2690 - val_loss: 0.2681\n",
            "Epoch 70/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2688 - val_loss: 0.2681\n",
            "Epoch 71/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2687 - val_loss: 0.2679\n",
            "Epoch 72/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2686 - val_loss: 0.2679\n",
            "Epoch 73/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2685 - val_loss: 0.2677\n",
            "Epoch 74/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2683 - val_loss: 0.2676\n",
            "Epoch 75/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2682 - val_loss: 0.2675\n",
            "Epoch 76/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2681 - val_loss: 0.2675\n",
            "Epoch 77/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2680 - val_loss: 0.2673\n",
            "Epoch 78/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2679 - val_loss: 0.2673\n",
            "Epoch 79/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2678 - val_loss: 0.2671\n",
            "Epoch 80/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2677 - val_loss: 0.2671\n",
            "Epoch 81/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2676 - val_loss: 0.2670\n",
            "Epoch 82/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2675 - val_loss: 0.2669\n",
            "Epoch 83/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2674 - val_loss: 0.2667\n",
            "Epoch 84/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2673 - val_loss: 0.2666\n",
            "Epoch 85/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2672 - val_loss: 0.2669\n",
            "Epoch 86/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2672 - val_loss: 0.2664\n",
            "Epoch 87/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2670 - val_loss: 0.2664\n",
            "Epoch 88/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2670 - val_loss: 0.2662\n",
            "Epoch 89/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2669 - val_loss: 0.2662\n",
            "Epoch 90/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2668 - val_loss: 0.2662\n",
            "Epoch 91/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2667 - val_loss: 0.2661\n",
            "Epoch 92/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2666 - val_loss: 0.2666\n",
            "Epoch 93/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2665 - val_loss: 0.2659\n",
            "Epoch 94/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2665 - val_loss: 0.2658\n",
            "Epoch 95/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2664 - val_loss: 0.2658\n",
            "Epoch 96/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2663 - val_loss: 0.2657\n",
            "Epoch 97/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2662 - val_loss: 0.2656\n",
            "Epoch 98/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2661 - val_loss: 0.2658\n",
            "Epoch 99/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2661 - val_loss: 0.2654\n",
            "Epoch 100/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2660 - val_loss: 0.2654\n",
            "Epoch 101/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2659 - val_loss: 0.2653\n",
            "Epoch 102/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2658 - val_loss: 0.2653\n",
            "Epoch 103/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2658 - val_loss: 0.2652\n",
            "Epoch 104/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2657 - val_loss: 0.2651\n",
            "Epoch 105/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2656 - val_loss: 0.2650\n",
            "Epoch 106/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2655 - val_loss: 0.2650\n",
            "Epoch 107/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2655 - val_loss: 0.2651\n",
            "Epoch 108/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2654 - val_loss: 0.2649\n",
            "Epoch 109/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2653 - val_loss: 0.2648\n",
            "Epoch 110/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2653 - val_loss: 0.2648\n",
            "Epoch 111/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2652 - val_loss: 0.2646\n",
            "Epoch 112/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2651 - val_loss: 0.2646\n",
            "Epoch 113/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2651 - val_loss: 0.2649\n",
            "Epoch 114/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2650 - val_loss: 0.2644\n",
            "Epoch 115/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2649 - val_loss: 0.2644\n",
            "Epoch 116/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2649 - val_loss: 0.2643\n",
            "Epoch 117/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2648 - val_loss: 0.2642\n",
            "Epoch 118/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2648 - val_loss: 0.2642\n",
            "Epoch 119/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2647 - val_loss: 0.2641\n",
            "Epoch 120/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2646 - val_loss: 0.2642\n",
            "Epoch 121/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2646 - val_loss: 0.2640\n",
            "Epoch 122/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2645 - val_loss: 0.2640\n",
            "Epoch 123/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2645 - val_loss: 0.2639\n",
            "Epoch 124/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2644 - val_loss: 0.2639\n",
            "Epoch 125/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2643 - val_loss: 0.2639\n",
            "Epoch 126/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2643 - val_loss: 0.2638\n",
            "Epoch 127/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2642 - val_loss: 0.2637\n",
            "Epoch 128/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2642 - val_loss: 0.2636\n",
            "Epoch 129/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2641 - val_loss: 0.2636\n",
            "Epoch 130/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2641 - val_loss: 0.2635\n",
            "Epoch 131/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2640 - val_loss: 0.2635\n",
            "Epoch 132/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2640 - val_loss: 0.2635\n",
            "Epoch 133/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2639 - val_loss: 0.2634\n",
            "Epoch 134/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2639 - val_loss: 0.2634\n",
            "Epoch 135/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2638 - val_loss: 0.2634\n",
            "Epoch 136/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2638 - val_loss: 0.2633\n",
            "Epoch 137/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2637 - val_loss: 0.2631\n",
            "Epoch 138/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2637 - val_loss: 0.2631\n",
            "Epoch 139/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2636 - val_loss: 0.2630\n",
            "Epoch 140/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2636 - val_loss: 0.2631\n",
            "Epoch 141/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2635 - val_loss: 0.2630\n",
            "Epoch 142/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2635 - val_loss: 0.2630\n",
            "Epoch 143/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2634 - val_loss: 0.2629\n",
            "Epoch 144/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2634 - val_loss: 0.2629\n",
            "Epoch 145/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2633 - val_loss: 0.2628\n",
            "Epoch 146/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2633 - val_loss: 0.2628\n",
            "Epoch 147/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2633 - val_loss: 0.2627\n",
            "Epoch 148/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2632 - val_loss: 0.2627\n",
            "Epoch 149/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2631 - val_loss: 0.2626\n",
            "Epoch 150/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2631 - val_loss: 0.2626\n",
            "Epoch 151/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2631 - val_loss: 0.2626\n",
            "Epoch 152/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2630 - val_loss: 0.2625\n",
            "Epoch 153/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2630 - val_loss: 0.2625\n",
            "Epoch 154/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2629 - val_loss: 0.2625\n",
            "Epoch 155/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2629 - val_loss: 0.2625\n",
            "Epoch 156/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2628 - val_loss: 0.2623\n",
            "Epoch 157/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2628 - val_loss: 0.2625\n",
            "Epoch 158/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2628 - val_loss: 0.2624\n",
            "Epoch 159/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2627 - val_loss: 0.2623\n",
            "Epoch 160/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2627 - val_loss: 0.2622\n",
            "Epoch 161/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2626 - val_loss: 0.2622\n",
            "Epoch 162/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2626 - val_loss: 0.2621\n",
            "Epoch 163/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2626 - val_loss: 0.2621\n",
            "Epoch 164/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2625 - val_loss: 0.2620\n",
            "Epoch 165/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2625 - val_loss: 0.2621\n",
            "Epoch 166/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2625 - val_loss: 0.2626\n",
            "Epoch 167/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2624 - val_loss: 0.2620\n",
            "Epoch 168/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2624 - val_loss: 0.2620\n",
            "Epoch 169/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2623 - val_loss: 0.2620\n",
            "Epoch 170/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2623 - val_loss: 0.2619\n",
            "Epoch 171/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2623 - val_loss: 0.2618\n",
            "Epoch 172/200\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2622 - val_loss: 0.2617\n",
            "Epoch 173/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2622 - val_loss: 0.2618\n",
            "Epoch 174/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2622 - val_loss: 0.2618\n",
            "Epoch 175/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2621 - val_loss: 0.2617\n",
            "Epoch 176/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2621 - val_loss: 0.2617\n",
            "Epoch 177/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2621 - val_loss: 0.2616\n",
            "Epoch 178/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2620 - val_loss: 0.2616\n",
            "Epoch 179/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2620 - val_loss: 0.2615\n",
            "Epoch 180/200\n",
            "235/235 [==============================] - 10s 40ms/step - loss: 0.2619 - val_loss: 0.2616\n",
            "Epoch 181/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2619 - val_loss: 0.2615\n",
            "Epoch 182/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2619 - val_loss: 0.2614\n",
            "Epoch 183/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2618 - val_loss: 0.2616\n",
            "Epoch 184/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2618 - val_loss: 0.2614\n",
            "Epoch 185/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2618 - val_loss: 0.2614\n",
            "Epoch 186/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2617 - val_loss: 0.2615\n",
            "Epoch 187/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2617 - val_loss: 0.2614\n",
            "Epoch 188/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2617 - val_loss: 0.2614\n",
            "Epoch 189/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2616 - val_loss: 0.2612\n",
            "Epoch 190/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2616 - val_loss: 0.2612\n",
            "Epoch 191/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2616 - val_loss: 0.2612\n",
            "Epoch 192/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2616 - val_loss: 0.2612\n",
            "Epoch 193/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2615 - val_loss: 0.2611\n",
            "Epoch 194/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2615 - val_loss: 0.2611\n",
            "Epoch 195/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2615 - val_loss: 0.2611\n",
            "Epoch 196/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2615 - val_loss: 0.2611\n",
            "Epoch 197/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2614 - val_loss: 0.2610\n",
            "Epoch 198/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2614 - val_loss: 0.2610\n",
            "Epoch 199/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2613 - val_loss: 0.2611\n",
            "Epoch 200/200\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.2613 - val_loss: 0.2609\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Variational Auto encoder"
      ],
      "metadata": {
        "id": "4by1XjrlyH-j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The code moving forward is referred from lecture notes and layers and LeakyRelu added.\n",
        "\n",
        "# defining the dimension of layers.\n",
        "original_dim = 784\n",
        "intermediate_dim1 = 512\n",
        "intermediate_dim2 = 256\n",
        "# keeping the latent space dimension as 100.\n",
        "# the more the dimension, the better the quality of images.\n",
        "latent_dim = 100\n",
        "\n",
        "class Sampling(layers.Layer):\n",
        "    \"\"\"This class uses mean and standard deviation to sample z value, which contains\n",
        "    the vector encoding the fashion dataset.\"\"\"\n",
        "    def call(self, inputs):\n",
        "        # overriding the call method.\n",
        "        z_mean, z_log_var = inputs\n",
        "        epsilon = tf.keras.backend.random_normal(shape=tf.shape(z_mean)) \n",
        "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon \n"
      ],
      "metadata": {
        "id": "V_rLYb9qyHDQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definining encoder model.\n",
        "# input -> hidden layer1 -> hidden layer2 -> (z_mean, z_log_var) -> (sampling) z\n",
        "original_inputs = tf.keras.Input(shape=(original_dim,), name=\"encoder_input\")\n",
        "\n",
        "# hidden layer 1\n",
        "hidden_vae_1 = layers.Dense(intermediate_dim1)(original_inputs)\n",
        "hidden_vae_1 = layers.LeakyReLU(alpha=0.2)(hidden_vae_1)\n",
        "\n",
        "# hidden layer 2\n",
        "hidden_vae_2 = layers.Dense(intermediate_dim2)(hidden_vae_1)\n",
        "hidden_vae_2 = layers.LeakyReLU(alpha=0.2)(hidden_vae_2)\n",
        "\n",
        "# calculating mean and variance.\n",
        "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(hidden_vae_2)\n",
        "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(hidden_vae_2)\n",
        "# sampling some images.\n",
        "z = Sampling()((z_mean, z_log_var))\n",
        "# creating an encoder with input image as input and z as output.\n",
        "encoder_vae = tf.keras.Model(inputs=original_inputs, outputs=z, name=\"encoder\")\n",
        "encoder_vae.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cS2soQDw_S_p",
        "outputId": "5cb99af9-0660-4ed1-d159-d2375d85bf48"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"encoder\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " encoder_input (InputLayer)     [(None, 784)]        0           []                               \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 512)          401920      ['encoder_input[0][0]']          \n",
            "                                                                                                  \n",
            " leaky_re_lu (LeakyReLU)        (None, 512)          0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 256)          131328      ['leaky_re_lu[0][0]']            \n",
            "                                                                                                  \n",
            " leaky_re_lu_1 (LeakyReLU)      (None, 256)          0           ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            " z_mean (Dense)                 (None, 100)          25700       ['leaky_re_lu_1[0][0]']          \n",
            "                                                                                                  \n",
            " z_log_var (Dense)              (None, 100)          25700       ['leaky_re_lu_1[0][0]']          \n",
            "                                                                                                  \n",
            " sampling (Sampling)            (None, 100)          0           ['z_mean[0][0]',                 \n",
            "                                                                  'z_log_var[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 584,648\n",
            "Trainable params: 584,648\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining decoder model.\n",
        "# z -> hidden layer2 -> hidden layer1 -> output\n",
        "latent_inputs = tf.keras.Input(shape=(latent_dim,), name=\"z_sampling\")\n",
        "\n",
        "# hidden layer 2\n",
        "hidden_vae_2 = layers.Dense(intermediate_dim2)(latent_inputs)\n",
        "hidden_vae_2 = layers.LeakyReLU(alpha=0.2)(hidden_vae_2)\n",
        "\n",
        "# hidden layer 1\n",
        "hidden_vae_1 = layers.Dense(intermediate_dim1)(hidden_vae_2)\n",
        "hidden_vae_1 = layers.LeakyReLU(alpha=0.2)(hidden_vae_1)\n",
        "\n",
        "# output layer having same dimension as input image.\n",
        "outputs = layers.Dense(original_dim, activation=\"sigmoid\")(hidden_vae_1)\n",
        "decoder_vae = tf.keras.Model(inputs=latent_inputs, outputs=outputs, name=\"decoder\")\n",
        "decoder_vae.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gyJY0ZDaAO-s",
        "outputId": "482e2a6b-674c-40c8-960d-f718f9deb66d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " z_sampling (InputLayer)     [(None, 100)]             0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 256)               25856     \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 512)               131584    \n",
            "                                                                 \n",
            " leaky_re_lu_3 (LeakyReLU)   (None, 512)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 784)               402192    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 559,632\n",
            "Trainable params: 559,632\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definining vae model having input of dimension 784.\n",
        "outputs = decoder_vae(z)\n",
        "vae = tf.keras.Model(inputs=original_inputs, outputs=outputs, name=\"vae\")\n",
        "vae.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70Y9Q1d9rEpZ",
        "outputId": "77eb0a8c-946e-4202-b863-4269f5ff8ac2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vae\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " encoder_input (InputLayer)     [(None, 784)]        0           []                               \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 512)          401920      ['encoder_input[0][0]']          \n",
            "                                                                                                  \n",
            " leaky_re_lu (LeakyReLU)        (None, 512)          0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 256)          131328      ['leaky_re_lu[0][0]']            \n",
            "                                                                                                  \n",
            " leaky_re_lu_1 (LeakyReLU)      (None, 256)          0           ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            " z_mean (Dense)                 (None, 100)          25700       ['leaky_re_lu_1[0][0]']          \n",
            "                                                                                                  \n",
            " z_log_var (Dense)              (None, 100)          25700       ['leaky_re_lu_1[0][0]']          \n",
            "                                                                                                  \n",
            " sampling (Sampling)            (None, 100)          0           ['z_mean[0][0]',                 \n",
            "                                                                  'z_log_var[0][0]']              \n",
            "                                                                                                  \n",
            " decoder (Functional)           (None, 784)          559632      ['sampling[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,144,280\n",
            "Trainable params: 1,144,280\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculating loss between original and output image.\n",
        "reconstruction_loss = mse(original_inputs, outputs) \n",
        "reconstruction_loss = original_dim * K.mean(reconstruction_loss)\n",
        "kl_loss = -0.5 * tf.reduce_mean(z_log_var - tf.square(z_mean) - tf.exp(z_log_var) + 1)\n",
        "\n",
        "# setting the loss and kl divergence in the model.\n",
        "vae.add_loss(kl_loss)\n",
        "vae.add_metric(kl_loss, name='kl_loss', aggregation='mean')\n",
        "vae.add_loss(reconstruction_loss)\n",
        "vae.add_metric(reconstruction_loss, name='mse_loss', aggregation='mean')\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)"
      ],
      "metadata": {
        "id": "ayGpnJMkA9d3"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vae.compile(optimizer)"
      ],
      "metadata": {
        "id": "Vf3t5oMYBEm3"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training on the dataset.\n",
        "vae_history = vae.fit(X_train_ae, X_train_ae, epochs=200, batch_size = 256, validation_data = (X_test_ae, X_test_ae))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZCfCyuX3e9l",
        "outputId": "ccadd011-07d7-4caf-fddc-b549fd48927d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "235/235 [==============================] - 13s 49ms/step - loss: 26.0601 - kl_loss: 1.0806 - mse_loss: 24.9795 - val_loss: 15.9880 - val_kl_loss: 1.2482 - val_mse_loss: 14.7398\n",
            "Epoch 2/200\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 14.1363 - kl_loss: 1.3093 - mse_loss: 12.8269 - val_loss: 12.7587 - val_kl_loss: 1.3771 - val_mse_loss: 11.3815\n",
            "Epoch 3/200\n",
            "235/235 [==============================] - 11s 47ms/step - loss: 11.8443 - kl_loss: 1.3829 - mse_loss: 10.4614 - val_loss: 11.1341 - val_kl_loss: 1.4091 - val_mse_loss: 9.7250\n",
            "Epoch 4/200\n",
            "235/235 [==============================] - 11s 47ms/step - loss: 10.5713 - kl_loss: 1.4170 - mse_loss: 9.1543 - val_loss: 10.4052 - val_kl_loss: 1.4560 - val_mse_loss: 8.9492\n",
            "Epoch 5/200\n",
            "235/235 [==============================] - 11s 47ms/step - loss: 9.7968 - kl_loss: 1.4269 - mse_loss: 8.3698 - val_loss: 9.5597 - val_kl_loss: 1.4476 - val_mse_loss: 8.1121\n",
            "Epoch 6/200\n",
            "235/235 [==============================] - 12s 51ms/step - loss: 9.2674 - kl_loss: 1.4271 - mse_loss: 7.8403 - val_loss: 9.0950 - val_kl_loss: 1.3816 - val_mse_loss: 7.7134\n",
            "Epoch 7/200\n",
            "235/235 [==============================] - 11s 47ms/step - loss: 8.7669 - kl_loss: 1.4314 - mse_loss: 7.3354 - val_loss: 8.7282 - val_kl_loss: 1.4359 - val_mse_loss: 7.2922\n",
            "Epoch 8/200\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 8.4261 - kl_loss: 1.4265 - mse_loss: 6.9995 - val_loss: 8.3960 - val_kl_loss: 1.4311 - val_mse_loss: 6.9648\n",
            "Epoch 9/200\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 8.1347 - kl_loss: 1.4216 - mse_loss: 6.7131 - val_loss: 8.2843 - val_kl_loss: 1.4611 - val_mse_loss: 6.8232\n",
            "Epoch 10/200\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 7.9182 - kl_loss: 1.4157 - mse_loss: 6.5024 - val_loss: 8.0302 - val_kl_loss: 1.3839 - val_mse_loss: 6.6463\n",
            "Epoch 11/200\n",
            "235/235 [==============================] - 11s 47ms/step - loss: 7.6809 - kl_loss: 1.4108 - mse_loss: 6.2701 - val_loss: 7.7947 - val_kl_loss: 1.3671 - val_mse_loss: 6.4276\n",
            "Epoch 12/200\n",
            "235/235 [==============================] - 11s 47ms/step - loss: 7.4893 - kl_loss: 1.4042 - mse_loss: 6.0851 - val_loss: 7.6453 - val_kl_loss: 1.3935 - val_mse_loss: 6.2518\n",
            "Epoch 13/200\n",
            "235/235 [==============================] - 11s 47ms/step - loss: 7.3296 - kl_loss: 1.3995 - mse_loss: 5.9301 - val_loss: 7.4877 - val_kl_loss: 1.3914 - val_mse_loss: 6.0962\n",
            "Epoch 14/200\n",
            "235/235 [==============================] - 11s 47ms/step - loss: 7.2053 - kl_loss: 1.3946 - mse_loss: 5.8107 - val_loss: 7.4411 - val_kl_loss: 1.3990 - val_mse_loss: 6.0421\n",
            "Epoch 15/200\n",
            "235/235 [==============================] - 11s 47ms/step - loss: 7.0608 - kl_loss: 1.3923 - mse_loss: 5.6685 - val_loss: 7.2016 - val_kl_loss: 1.3809 - val_mse_loss: 5.8207\n",
            "Epoch 16/200\n",
            "235/235 [==============================] - 11s 47ms/step - loss: 6.9345 - kl_loss: 1.3896 - mse_loss: 5.5449 - val_loss: 7.1903 - val_kl_loss: 1.3534 - val_mse_loss: 5.8369\n",
            "Epoch 17/200\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 6.8463 - kl_loss: 1.3853 - mse_loss: 5.4610 - val_loss: 7.0438 - val_kl_loss: 1.3955 - val_mse_loss: 5.6483\n",
            "Epoch 18/200\n",
            "235/235 [==============================] - 11s 47ms/step - loss: 6.7335 - kl_loss: 1.3826 - mse_loss: 5.3510 - val_loss: 6.9325 - val_kl_loss: 1.4128 - val_mse_loss: 5.5196\n",
            "Epoch 19/200\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 6.6611 - kl_loss: 1.3795 - mse_loss: 5.2817 - val_loss: 6.9443 - val_kl_loss: 1.3139 - val_mse_loss: 5.6304\n",
            "Epoch 20/200\n",
            "235/235 [==============================] - 12s 51ms/step - loss: 6.5602 - kl_loss: 1.3782 - mse_loss: 5.1820 - val_loss: 6.8160 - val_kl_loss: 1.3885 - val_mse_loss: 5.4275\n",
            "Epoch 21/200\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 6.4891 - kl_loss: 1.3759 - mse_loss: 5.1133 - val_loss: 6.7100 - val_kl_loss: 1.3816 - val_mse_loss: 5.3284\n",
            "Epoch 22/200\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 6.4294 - kl_loss: 1.3742 - mse_loss: 5.0552 - val_loss: 6.6651 - val_kl_loss: 1.3881 - val_mse_loss: 5.2770\n",
            "Epoch 23/200\n",
            "235/235 [==============================] - 11s 47ms/step - loss: 6.3698 - kl_loss: 1.3726 - mse_loss: 4.9972 - val_loss: 6.6007 - val_kl_loss: 1.3748 - val_mse_loss: 5.2259\n",
            "Epoch 24/200\n",
            "235/235 [==============================] - 11s 47ms/step - loss: 6.3088 - kl_loss: 1.3720 - mse_loss: 4.9368 - val_loss: 6.7370 - val_kl_loss: 1.3496 - val_mse_loss: 5.3874\n",
            "Epoch 25/200\n",
            "235/235 [==============================] - 11s 47ms/step - loss: 6.2711 - kl_loss: 1.3699 - mse_loss: 4.9011 - val_loss: 6.5149 - val_kl_loss: 1.3408 - val_mse_loss: 5.1741\n",
            "Epoch 26/200\n",
            "235/235 [==============================] - 11s 47ms/step - loss: 6.2136 - kl_loss: 1.3718 - mse_loss: 4.8418 - val_loss: 6.5073 - val_kl_loss: 1.3758 - val_mse_loss: 5.1315\n",
            "Epoch 27/200\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 6.1725 - kl_loss: 1.3705 - mse_loss: 4.8021 - val_loss: 6.4609 - val_kl_loss: 1.3718 - val_mse_loss: 5.0891\n",
            "Epoch 28/200\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 6.1146 - kl_loss: 1.3684 - mse_loss: 4.7462 - val_loss: 6.3790 - val_kl_loss: 1.4018 - val_mse_loss: 4.9771\n",
            "Epoch 29/200\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 6.0918 - kl_loss: 1.3686 - mse_loss: 4.7232 - val_loss: 6.4309 - val_kl_loss: 1.3179 - val_mse_loss: 5.1130\n",
            "Epoch 30/200\n",
            "235/235 [==============================] - 11s 47ms/step - loss: 6.0577 - kl_loss: 1.3686 - mse_loss: 4.6892 - val_loss: 6.3845 - val_kl_loss: 1.3673 - val_mse_loss: 5.0172\n",
            "Epoch 31/200\n",
            "235/235 [==============================] - 11s 47ms/step - loss: 6.0309 - kl_loss: 1.3678 - mse_loss: 4.6631 - val_loss: 6.2961 - val_kl_loss: 1.3778 - val_mse_loss: 4.9183\n",
            "Epoch 32/200\n",
            "235/235 [==============================] - 11s 47ms/step - loss: 5.9977 - kl_loss: 1.3672 - mse_loss: 4.6305 - val_loss: 6.2993 - val_kl_loss: 1.3776 - val_mse_loss: 4.9218\n",
            "Epoch 33/200\n",
            "235/235 [==============================] - 11s 47ms/step - loss: 5.9484 - kl_loss: 1.3670 - mse_loss: 4.5814 - val_loss: 6.4048 - val_kl_loss: 1.3434 - val_mse_loss: 5.0614\n",
            "Epoch 34/200\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 5.9370 - kl_loss: 1.3665 - mse_loss: 4.5705 - val_loss: 6.2604 - val_kl_loss: 1.3921 - val_mse_loss: 4.8683\n",
            "Epoch 35/200\n",
            "235/235 [==============================] - 11s 49ms/step - loss: 5.8977 - kl_loss: 1.3657 - mse_loss: 4.5320 - val_loss: 6.2178 - val_kl_loss: 1.3635 - val_mse_loss: 4.8543\n",
            "Epoch 36/200\n",
            "235/235 [==============================] - 11s 49ms/step - loss: 5.8842 - kl_loss: 1.3651 - mse_loss: 4.5190 - val_loss: 6.2438 - val_kl_loss: 1.3930 - val_mse_loss: 4.8508\n",
            "Epoch 37/200\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 5.8492 - kl_loss: 1.3660 - mse_loss: 4.4831 - val_loss: 6.1867 - val_kl_loss: 1.3702 - val_mse_loss: 4.8165\n",
            "Epoch 38/200\n",
            "235/235 [==============================] - 12s 49ms/step - loss: 5.8391 - kl_loss: 1.3649 - mse_loss: 4.4741 - val_loss: 6.2049 - val_kl_loss: 1.3271 - val_mse_loss: 4.8778\n",
            "Epoch 39/200\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 5.8022 - kl_loss: 1.3652 - mse_loss: 4.4370 - val_loss: 6.1504 - val_kl_loss: 1.3407 - val_mse_loss: 4.8097\n",
            "Epoch 40/200\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 5.7862 - kl_loss: 1.3648 - mse_loss: 4.4214 - val_loss: 6.1219 - val_kl_loss: 1.3693 - val_mse_loss: 4.7526\n",
            "Epoch 41/200\n",
            "235/235 [==============================] - 11s 47ms/step - loss: 5.7658 - kl_loss: 1.3634 - mse_loss: 4.4023 - val_loss: 6.2107 - val_kl_loss: 1.3369 - val_mse_loss: 4.8738\n",
            "Epoch 42/200\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 5.7616 - kl_loss: 1.3635 - mse_loss: 4.3981 - val_loss: 6.0676 - val_kl_loss: 1.3351 - val_mse_loss: 4.7325\n",
            "Epoch 43/200\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 5.7219 - kl_loss: 1.3634 - mse_loss: 4.3584 - val_loss: 6.0580 - val_kl_loss: 1.3741 - val_mse_loss: 4.6839\n",
            "Epoch 44/200\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 5.7058 - kl_loss: 1.3634 - mse_loss: 4.3424 - val_loss: 6.0372 - val_kl_loss: 1.3590 - val_mse_loss: 4.6782\n",
            "Epoch 45/200\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 5.6993 - kl_loss: 1.3618 - mse_loss: 4.3375 - val_loss: 6.0665 - val_kl_loss: 1.3561 - val_mse_loss: 4.7104\n",
            "Epoch 46/200\n",
            "235/235 [==============================] - 11s 49ms/step - loss: 5.6688 - kl_loss: 1.3623 - mse_loss: 4.3065 - val_loss: 6.1333 - val_kl_loss: 1.3242 - val_mse_loss: 4.8091\n",
            "Epoch 47/200\n",
            "235/235 [==============================] - 12s 51ms/step - loss: 5.6790 - kl_loss: 1.3613 - mse_loss: 4.3177 - val_loss: 6.0428 - val_kl_loss: 1.3378 - val_mse_loss: 4.7050\n",
            "Epoch 48/200\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 5.6586 - kl_loss: 1.3611 - mse_loss: 4.2975 - val_loss: 6.0348 - val_kl_loss: 1.3736 - val_mse_loss: 4.6613\n",
            "Epoch 49/200\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 5.6342 - kl_loss: 1.3605 - mse_loss: 4.2738 - val_loss: 6.0389 - val_kl_loss: 1.3558 - val_mse_loss: 4.6832\n",
            "Epoch 50/200\n",
            "235/235 [==============================] - 15s 63ms/step - loss: 5.6317 - kl_loss: 1.3600 - mse_loss: 4.2717 - val_loss: 5.9552 - val_kl_loss: 1.3499 - val_mse_loss: 4.6053\n",
            "Epoch 51/200\n",
            "235/235 [==============================] - 17s 72ms/step - loss: 5.6069 - kl_loss: 1.3599 - mse_loss: 4.2470 - val_loss: 6.0118 - val_kl_loss: 1.3660 - val_mse_loss: 4.6459\n",
            "Epoch 52/200\n",
            "235/235 [==============================] - 18s 78ms/step - loss: 5.5958 - kl_loss: 1.3593 - mse_loss: 4.2365 - val_loss: 5.9623 - val_kl_loss: 1.3633 - val_mse_loss: 4.5991\n",
            "Epoch 53/200\n",
            "235/235 [==============================] - 17s 73ms/step - loss: 5.5704 - kl_loss: 1.3586 - mse_loss: 4.2118 - val_loss: 5.9366 - val_kl_loss: 1.3730 - val_mse_loss: 4.5636\n",
            "Epoch 54/200\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 5.5710 - kl_loss: 1.3576 - mse_loss: 4.2134 - val_loss: 5.9252 - val_kl_loss: 1.3380 - val_mse_loss: 4.5872\n",
            "Epoch 55/200\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 5.5521 - kl_loss: 1.3574 - mse_loss: 4.1947 - val_loss: 5.9572 - val_kl_loss: 1.3768 - val_mse_loss: 4.5804\n",
            "Epoch 56/200\n",
            "235/235 [==============================] - 11s 47ms/step - loss: 5.5517 - kl_loss: 1.3560 - mse_loss: 4.1957 - val_loss: 5.9704 - val_kl_loss: 1.3324 - val_mse_loss: 4.6380\n",
            "Epoch 57/200\n",
            "235/235 [==============================] - 11s 47ms/step - loss: 5.5410 - kl_loss: 1.3578 - mse_loss: 4.1831 - val_loss: 6.0503 - val_kl_loss: 1.3644 - val_mse_loss: 4.6858\n",
            "Epoch 58/200\n",
            "235/235 [==============================] - 18s 77ms/step - loss: 5.5253 - kl_loss: 1.3568 - mse_loss: 4.1685 - val_loss: 5.9731 - val_kl_loss: 1.3836 - val_mse_loss: 4.5895\n",
            "Epoch 59/200\n",
            "235/235 [==============================] - 12s 52ms/step - loss: 5.5185 - kl_loss: 1.3563 - mse_loss: 4.1622 - val_loss: 5.9231 - val_kl_loss: 1.3419 - val_mse_loss: 4.5812\n",
            "Epoch 60/200\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 5.4988 - kl_loss: 1.3551 - mse_loss: 4.1438 - val_loss: 5.9069 - val_kl_loss: 1.3384 - val_mse_loss: 4.5685\n",
            "Epoch 61/200\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 5.5029 - kl_loss: 1.3543 - mse_loss: 4.1486 - val_loss: 5.9264 - val_kl_loss: 1.3355 - val_mse_loss: 4.5908\n",
            "Epoch 62/200\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 5.4779 - kl_loss: 1.3555 - mse_loss: 4.1224 - val_loss: 5.8547 - val_kl_loss: 1.3219 - val_mse_loss: 4.5328\n",
            "Epoch 63/200\n",
            "235/235 [==============================] - 11s 47ms/step - loss: 5.4667 - kl_loss: 1.3531 - mse_loss: 4.1136 - val_loss: 5.9259 - val_kl_loss: 1.3401 - val_mse_loss: 4.5858\n",
            "Epoch 64/200\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 5.4679 - kl_loss: 1.3534 - mse_loss: 4.1145 - val_loss: 5.8560 - val_kl_loss: 1.3756 - val_mse_loss: 4.4804\n",
            "Epoch 65/200\n",
            "235/235 [==============================] - 11s 47ms/step - loss: 5.4484 - kl_loss: 1.3535 - mse_loss: 4.0948 - val_loss: 5.8496 - val_kl_loss: 1.3457 - val_mse_loss: 4.5039\n",
            "Epoch 66/200\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 5.4470 - kl_loss: 1.3525 - mse_loss: 4.0944 - val_loss: 5.8206 - val_kl_loss: 1.3442 - val_mse_loss: 4.4764\n",
            "Epoch 67/200\n",
            "235/235 [==============================] - 11s 47ms/step - loss: 5.4299 - kl_loss: 1.3516 - mse_loss: 4.0783 - val_loss: 5.8450 - val_kl_loss: 1.3173 - val_mse_loss: 4.5277\n",
            "Epoch 68/200\n",
            "235/235 [==============================] - 11s 47ms/step - loss: 5.4334 - kl_loss: 1.3523 - mse_loss: 4.0811 - val_loss: 5.8239 - val_kl_loss: 1.3419 - val_mse_loss: 4.4820\n",
            "Epoch 69/200\n",
            "235/235 [==============================] - 11s 47ms/step - loss: 5.4155 - kl_loss: 1.3519 - mse_loss: 4.0636 - val_loss: 5.8352 - val_kl_loss: 1.3449 - val_mse_loss: 4.4903\n",
            "Epoch 70/200\n",
            "235/235 [==============================] - 11s 47ms/step - loss: 5.4098 - kl_loss: 1.3512 - mse_loss: 4.0586 - val_loss: 5.8352 - val_kl_loss: 1.3453 - val_mse_loss: 4.4899\n",
            "Epoch 71/200\n",
            "235/235 [==============================] - 11s 47ms/step - loss: 5.4007 - kl_loss: 1.3500 - mse_loss: 4.0507 - val_loss: 5.8146 - val_kl_loss: 1.3387 - val_mse_loss: 4.4759\n",
            "Epoch 72/200\n",
            "235/235 [==============================] - 11s 47ms/step - loss: 5.3899 - kl_loss: 1.3503 - mse_loss: 4.0396 - val_loss: 5.8252 - val_kl_loss: 1.3176 - val_mse_loss: 4.5077\n",
            "Epoch 73/200\n",
            "235/235 [==============================] - 11s 45ms/step - loss: 5.3927 - kl_loss: 1.3497 - mse_loss: 4.0430 - val_loss: 5.7818 - val_kl_loss: 1.3574 - val_mse_loss: 4.4243\n",
            "Epoch 74/200\n",
            "235/235 [==============================] - 11s 45ms/step - loss: 5.3834 - kl_loss: 1.3490 - mse_loss: 4.0344 - val_loss: 5.8065 - val_kl_loss: 1.3181 - val_mse_loss: 4.4884\n",
            "Epoch 75/200\n",
            "235/235 [==============================] - 11s 45ms/step - loss: 5.3787 - kl_loss: 1.3493 - mse_loss: 4.0294 - val_loss: 5.7836 - val_kl_loss: 1.3542 - val_mse_loss: 4.4295\n",
            "Epoch 76/200\n",
            "235/235 [==============================] - 11s 47ms/step - loss: 5.3709 - kl_loss: 1.3485 - mse_loss: 4.0224 - val_loss: 5.8083 - val_kl_loss: 1.3613 - val_mse_loss: 4.4470\n",
            "Epoch 77/200\n",
            "235/235 [==============================] - 11s 47ms/step - loss: 5.3734 - kl_loss: 1.3483 - mse_loss: 4.0250 - val_loss: 5.7759 - val_kl_loss: 1.3369 - val_mse_loss: 4.4391\n",
            "Epoch 78/200\n",
            "235/235 [==============================] - 11s 47ms/step - loss: 5.3419 - kl_loss: 1.3481 - mse_loss: 3.9938 - val_loss: 5.7772 - val_kl_loss: 1.3219 - val_mse_loss: 4.4553\n",
            "Epoch 79/200\n",
            "235/235 [==============================] - 11s 47ms/step - loss: 5.3465 - kl_loss: 1.3476 - mse_loss: 3.9989 - val_loss: 5.7746 - val_kl_loss: 1.3451 - val_mse_loss: 4.4295\n",
            "Epoch 80/200\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 5.3314 - kl_loss: 1.3479 - mse_loss: 3.9835 - val_loss: 5.8075 - val_kl_loss: 1.3327 - val_mse_loss: 4.4748\n",
            "Epoch 81/200\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 5.3321 - kl_loss: 1.3466 - mse_loss: 3.9854 - val_loss: 5.7747 - val_kl_loss: 1.3733 - val_mse_loss: 4.4014\n",
            "Epoch 82/200\n",
            "235/235 [==============================] - 11s 47ms/step - loss: 5.3375 - kl_loss: 1.3470 - mse_loss: 3.9905 - val_loss: 5.7591 - val_kl_loss: 1.3378 - val_mse_loss: 4.4213\n",
            "Epoch 83/200\n",
            "235/235 [==============================] - 11s 47ms/step - loss: 5.3125 - kl_loss: 1.3476 - mse_loss: 3.9649 - val_loss: 5.7253 - val_kl_loss: 1.3331 - val_mse_loss: 4.3922\n",
            "Epoch 84/200\n",
            "235/235 [==============================] - 11s 47ms/step - loss: 5.3135 - kl_loss: 1.3454 - mse_loss: 3.9681 - val_loss: 5.7634 - val_kl_loss: 1.3742 - val_mse_loss: 4.3892\n",
            "Epoch 85/200\n",
            "235/235 [==============================] - 11s 47ms/step - loss: 5.3051 - kl_loss: 1.3453 - mse_loss: 3.9598 - val_loss: 5.7344 - val_kl_loss: 1.3471 - val_mse_loss: 4.3874\n",
            "Epoch 86/200\n",
            "235/235 [==============================] - 11s 47ms/step - loss: 5.3018 - kl_loss: 1.3454 - mse_loss: 3.9564 - val_loss: 5.8301 - val_kl_loss: 1.3440 - val_mse_loss: 4.4861\n",
            "Epoch 87/200\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 5.2939 - kl_loss: 1.3449 - mse_loss: 3.9490 - val_loss: 5.7629 - val_kl_loss: 1.3781 - val_mse_loss: 4.3849\n",
            "Epoch 88/200\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 5.2932 - kl_loss: 1.3455 - mse_loss: 3.9477 - val_loss: 5.7600 - val_kl_loss: 1.3285 - val_mse_loss: 4.4315\n",
            "Epoch 89/200\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 5.2788 - kl_loss: 1.3442 - mse_loss: 3.9346 - val_loss: 5.8193 - val_kl_loss: 1.2905 - val_mse_loss: 4.5287\n",
            "Epoch 90/200\n",
            "235/235 [==============================] - 11s 49ms/step - loss: 5.2782 - kl_loss: 1.3433 - mse_loss: 3.9348 - val_loss: 5.7360 - val_kl_loss: 1.3553 - val_mse_loss: 4.3808\n",
            "Epoch 91/200\n",
            "235/235 [==============================] - 11s 49ms/step - loss: 5.2704 - kl_loss: 1.3437 - mse_loss: 3.9267 - val_loss: 5.7306 - val_kl_loss: 1.3498 - val_mse_loss: 4.3808\n",
            "Epoch 92/200\n",
            "235/235 [==============================] - 12s 49ms/step - loss: 5.2654 - kl_loss: 1.3442 - mse_loss: 3.9212 - val_loss: 5.8092 - val_kl_loss: 1.3345 - val_mse_loss: 4.4747\n",
            "Epoch 93/200\n",
            "235/235 [==============================] - 12s 49ms/step - loss: 5.2634 - kl_loss: 1.3431 - mse_loss: 3.9203 - val_loss: 5.6826 - val_kl_loss: 1.3237 - val_mse_loss: 4.3589\n",
            "Epoch 94/200\n",
            "235/235 [==============================] - 12s 49ms/step - loss: 5.2625 - kl_loss: 1.3429 - mse_loss: 3.9196 - val_loss: 5.8001 - val_kl_loss: 1.3470 - val_mse_loss: 4.4531\n",
            "Epoch 95/200\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 5.2560 - kl_loss: 1.3433 - mse_loss: 3.9128 - val_loss: 5.7270 - val_kl_loss: 1.3247 - val_mse_loss: 4.4023\n",
            "Epoch 96/200\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 5.2431 - kl_loss: 1.3424 - mse_loss: 3.9007 - val_loss: 5.6618 - val_kl_loss: 1.3508 - val_mse_loss: 4.3110\n",
            "Epoch 97/200\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 5.2529 - kl_loss: 1.3431 - mse_loss: 3.9098 - val_loss: 5.6948 - val_kl_loss: 1.3336 - val_mse_loss: 4.3612\n",
            "Epoch 98/200\n",
            "235/235 [==============================] - 11s 47ms/step - loss: 5.2309 - kl_loss: 1.3429 - mse_loss: 3.8880 - val_loss: 5.6885 - val_kl_loss: 1.3374 - val_mse_loss: 4.3511\n",
            "Epoch 99/200\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 5.2312 - kl_loss: 1.3414 - mse_loss: 3.8898 - val_loss: 5.7182 - val_kl_loss: 1.3315 - val_mse_loss: 4.3867\n",
            "Epoch 100/200\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 5.2377 - kl_loss: 1.3418 - mse_loss: 3.8959 - val_loss: 5.7111 - val_kl_loss: 1.3083 - val_mse_loss: 4.4028\n",
            "Epoch 101/200\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 5.2235 - kl_loss: 1.3405 - mse_loss: 3.8830 - val_loss: 5.6576 - val_kl_loss: 1.3643 - val_mse_loss: 4.2933\n",
            "Epoch 102/200\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 5.2267 - kl_loss: 1.3400 - mse_loss: 3.8867 - val_loss: 5.6668 - val_kl_loss: 1.3403 - val_mse_loss: 4.3265\n",
            "Epoch 103/200\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 5.2200 - kl_loss: 1.3409 - mse_loss: 3.8792 - val_loss: 5.6706 - val_kl_loss: 1.3374 - val_mse_loss: 4.3332\n",
            "Epoch 104/200\n",
            "235/235 [==============================] - 11s 49ms/step - loss: 5.2233 - kl_loss: 1.3408 - mse_loss: 3.8825 - val_loss: 5.6924 - val_kl_loss: 1.3314 - val_mse_loss: 4.3610\n",
            "Epoch 105/200\n",
            "235/235 [==============================] - 12s 52ms/step - loss: 5.2068 - kl_loss: 1.3409 - mse_loss: 3.8659 - val_loss: 5.6748 - val_kl_loss: 1.3334 - val_mse_loss: 4.3413\n",
            "Epoch 106/200\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 5.2023 - kl_loss: 1.3401 - mse_loss: 3.8622 - val_loss: 5.6695 - val_kl_loss: 1.3441 - val_mse_loss: 4.3254\n",
            "Epoch 107/200\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 5.1954 - kl_loss: 1.3414 - mse_loss: 3.8541 - val_loss: 5.6603 - val_kl_loss: 1.3500 - val_mse_loss: 4.3103\n",
            "Epoch 108/200\n",
            "235/235 [==============================] - 15s 62ms/step - loss: 5.2035 - kl_loss: 1.3395 - mse_loss: 3.8640 - val_loss: 5.6643 - val_kl_loss: 1.3026 - val_mse_loss: 4.3617\n",
            "Epoch 109/200\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 5.1931 - kl_loss: 1.3396 - mse_loss: 3.8534 - val_loss: 5.6457 - val_kl_loss: 1.3231 - val_mse_loss: 4.3226\n",
            "Epoch 110/200\n",
            "235/235 [==============================] - 12s 49ms/step - loss: 5.1873 - kl_loss: 1.3384 - mse_loss: 3.8488 - val_loss: 5.6596 - val_kl_loss: 1.3472 - val_mse_loss: 4.3124\n",
            "Epoch 111/200\n",
            "235/235 [==============================] - 12s 49ms/step - loss: 5.1815 - kl_loss: 1.3395 - mse_loss: 3.8420 - val_loss: 5.6547 - val_kl_loss: 1.3471 - val_mse_loss: 4.3076\n",
            "Epoch 112/200\n",
            "235/235 [==============================] - 12s 49ms/step - loss: 5.1846 - kl_loss: 1.3390 - mse_loss: 3.8456 - val_loss: 5.7257 - val_kl_loss: 1.3071 - val_mse_loss: 4.4185\n",
            "Epoch 113/200\n",
            "235/235 [==============================] - 12s 49ms/step - loss: 5.1735 - kl_loss: 1.3378 - mse_loss: 3.8358 - val_loss: 5.6224 - val_kl_loss: 1.3403 - val_mse_loss: 4.2822\n",
            "Epoch 114/200\n",
            "235/235 [==============================] - 12s 49ms/step - loss: 5.1775 - kl_loss: 1.3379 - mse_loss: 3.8396 - val_loss: 5.6844 - val_kl_loss: 1.3326 - val_mse_loss: 4.3518\n",
            "Epoch 115/200\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 5.1634 - kl_loss: 1.3390 - mse_loss: 3.8244 - val_loss: 5.6295 - val_kl_loss: 1.3468 - val_mse_loss: 4.2827\n",
            "Epoch 116/200\n",
            "235/235 [==============================] - 11s 49ms/step - loss: 5.1630 - kl_loss: 1.3380 - mse_loss: 3.8250 - val_loss: 5.6350 - val_kl_loss: 1.3300 - val_mse_loss: 4.3049\n",
            "Epoch 117/200\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 5.1660 - kl_loss: 1.3373 - mse_loss: 3.8287 - val_loss: 5.6100 - val_kl_loss: 1.3168 - val_mse_loss: 4.2932\n",
            "Epoch 118/200\n",
            "235/235 [==============================] - 13s 53ms/step - loss: 5.1555 - kl_loss: 1.3378 - mse_loss: 3.8177 - val_loss: 5.6673 - val_kl_loss: 1.3630 - val_mse_loss: 4.3043\n",
            "Epoch 119/200\n",
            "235/235 [==============================] - 13s 55ms/step - loss: 5.1580 - kl_loss: 1.3375 - mse_loss: 3.8205 - val_loss: 5.6172 - val_kl_loss: 1.3287 - val_mse_loss: 4.2885\n",
            "Epoch 120/200\n",
            "235/235 [==============================] - 12s 49ms/step - loss: 5.1513 - kl_loss: 1.3374 - mse_loss: 3.8139 - val_loss: 5.6673 - val_kl_loss: 1.3096 - val_mse_loss: 4.3576\n",
            "Epoch 121/200\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 5.1461 - kl_loss: 1.3372 - mse_loss: 3.8090 - val_loss: 5.6419 - val_kl_loss: 1.3194 - val_mse_loss: 4.3225\n",
            "Epoch 122/200\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 5.1396 - kl_loss: 1.3372 - mse_loss: 3.8024 - val_loss: 5.6667 - val_kl_loss: 1.3251 - val_mse_loss: 4.3416\n",
            "Epoch 123/200\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 5.1495 - kl_loss: 1.3373 - mse_loss: 3.8122 - val_loss: 5.6154 - val_kl_loss: 1.3462 - val_mse_loss: 4.2692\n",
            "Epoch 124/200\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 5.1444 - kl_loss: 1.3367 - mse_loss: 3.8077 - val_loss: 5.6575 - val_kl_loss: 1.2998 - val_mse_loss: 4.3577\n",
            "Epoch 125/200\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 5.1288 - kl_loss: 1.3363 - mse_loss: 3.7926 - val_loss: 5.6669 - val_kl_loss: 1.3570 - val_mse_loss: 4.3098\n",
            "Epoch 126/200\n",
            "235/235 [==============================] - 11s 47ms/step - loss: 5.1281 - kl_loss: 1.3366 - mse_loss: 3.7915 - val_loss: 5.6105 - val_kl_loss: 1.3325 - val_mse_loss: 4.2779\n",
            "Epoch 127/200\n",
            "235/235 [==============================] - 11s 47ms/step - loss: 5.1209 - kl_loss: 1.3366 - mse_loss: 3.7843 - val_loss: 5.5921 - val_kl_loss: 1.3300 - val_mse_loss: 4.2622\n",
            "Epoch 128/200\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 5.1288 - kl_loss: 1.3367 - mse_loss: 3.7920 - val_loss: 5.6493 - val_kl_loss: 1.3173 - val_mse_loss: 4.3320\n",
            "Epoch 129/200\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 5.1221 - kl_loss: 1.3364 - mse_loss: 3.7857 - val_loss: 5.6664 - val_kl_loss: 1.3058 - val_mse_loss: 4.3606\n",
            "Epoch 130/200\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 5.1183 - kl_loss: 1.3352 - mse_loss: 3.7831 - val_loss: 5.6108 - val_kl_loss: 1.3559 - val_mse_loss: 4.2549\n",
            "Epoch 131/200\n",
            "235/235 [==============================] - 11s 49ms/step - loss: 5.1178 - kl_loss: 1.3361 - mse_loss: 3.7817 - val_loss: 5.6601 - val_kl_loss: 1.3474 - val_mse_loss: 4.3127\n",
            "Epoch 132/200\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 5.1171 - kl_loss: 1.3359 - mse_loss: 3.7813 - val_loss: 5.6290 - val_kl_loss: 1.3182 - val_mse_loss: 4.3108\n",
            "Epoch 133/200\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 5.1102 - kl_loss: 1.3355 - mse_loss: 3.7747 - val_loss: 5.6093 - val_kl_loss: 1.3208 - val_mse_loss: 4.2886\n",
            "Epoch 134/200\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 5.1073 - kl_loss: 1.3360 - mse_loss: 3.7713 - val_loss: 5.6019 - val_kl_loss: 1.3209 - val_mse_loss: 4.2810\n",
            "Epoch 135/200\n",
            "235/235 [==============================] - 11s 49ms/step - loss: 5.1038 - kl_loss: 1.3361 - mse_loss: 3.7678 - val_loss: 5.6098 - val_kl_loss: 1.3291 - val_mse_loss: 4.2807\n",
            "Epoch 136/200\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 5.0959 - kl_loss: 1.3356 - mse_loss: 3.7602 - val_loss: 5.6090 - val_kl_loss: 1.3254 - val_mse_loss: 4.2836\n",
            "Epoch 137/200\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 5.0921 - kl_loss: 1.3339 - mse_loss: 3.7582 - val_loss: 5.5867 - val_kl_loss: 1.3130 - val_mse_loss: 4.2738\n",
            "Epoch 138/200\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 5.1061 - kl_loss: 1.3337 - mse_loss: 3.7725 - val_loss: 5.6857 - val_kl_loss: 1.3222 - val_mse_loss: 4.3635\n",
            "Epoch 139/200\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 5.0969 - kl_loss: 1.3346 - mse_loss: 3.7623 - val_loss: 5.5773 - val_kl_loss: 1.3438 - val_mse_loss: 4.2336\n",
            "Epoch 140/200\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 5.0765 - kl_loss: 1.3352 - mse_loss: 3.7413 - val_loss: 5.6591 - val_kl_loss: 1.3129 - val_mse_loss: 4.3462\n",
            "Epoch 141/200\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 5.0938 - kl_loss: 1.3342 - mse_loss: 3.7596 - val_loss: 5.5646 - val_kl_loss: 1.3207 - val_mse_loss: 4.2440\n",
            "Epoch 142/200\n",
            "235/235 [==============================] - 11s 49ms/step - loss: 5.0738 - kl_loss: 1.3347 - mse_loss: 3.7391 - val_loss: 5.5594 - val_kl_loss: 1.3278 - val_mse_loss: 4.2316\n",
            "Epoch 143/200\n",
            "235/235 [==============================] - 12s 49ms/step - loss: 5.0878 - kl_loss: 1.3348 - mse_loss: 3.7530 - val_loss: 5.5921 - val_kl_loss: 1.3429 - val_mse_loss: 4.2492\n",
            "Epoch 144/200\n",
            "235/235 [==============================] - 12s 49ms/step - loss: 5.0811 - kl_loss: 1.3342 - mse_loss: 3.7469 - val_loss: 5.6064 - val_kl_loss: 1.3204 - val_mse_loss: 4.2860\n",
            "Epoch 145/200\n",
            "235/235 [==============================] - 12s 49ms/step - loss: 5.0742 - kl_loss: 1.3345 - mse_loss: 3.7396 - val_loss: 5.6015 - val_kl_loss: 1.3240 - val_mse_loss: 4.2775\n",
            "Epoch 146/200\n",
            "235/235 [==============================] - 12s 49ms/step - loss: 5.0788 - kl_loss: 1.3337 - mse_loss: 3.7451 - val_loss: 5.5723 - val_kl_loss: 1.3231 - val_mse_loss: 4.2492\n",
            "Epoch 147/200\n",
            "235/235 [==============================] - 12s 49ms/step - loss: 5.0691 - kl_loss: 1.3340 - mse_loss: 3.7351 - val_loss: 5.6040 - val_kl_loss: 1.3103 - val_mse_loss: 4.2937\n",
            "Epoch 148/200\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 5.0682 - kl_loss: 1.3341 - mse_loss: 3.7340 - val_loss: 5.5595 - val_kl_loss: 1.3206 - val_mse_loss: 4.2389\n",
            "Epoch 149/200\n",
            "235/235 [==============================] - 12s 50ms/step - loss: 5.0695 - kl_loss: 1.3336 - mse_loss: 3.7359 - val_loss: 5.5942 - val_kl_loss: 1.3381 - val_mse_loss: 4.2562\n",
            "Epoch 150/200\n",
            "235/235 [==============================] - 12s 50ms/step - loss: 5.0652 - kl_loss: 1.3325 - mse_loss: 3.7327 - val_loss: 5.5748 - val_kl_loss: 1.3456 - val_mse_loss: 4.2292\n",
            "Epoch 151/200\n",
            "235/235 [==============================] - 12s 49ms/step - loss: 5.0675 - kl_loss: 1.3343 - mse_loss: 3.7332 - val_loss: 5.5840 - val_kl_loss: 1.3485 - val_mse_loss: 4.2355\n",
            "Epoch 152/200\n",
            "235/235 [==============================] - 12s 49ms/step - loss: 5.0669 - kl_loss: 1.3336 - mse_loss: 3.7333 - val_loss: 5.6067 - val_kl_loss: 1.3283 - val_mse_loss: 4.2784\n",
            "Epoch 153/200\n",
            "235/235 [==============================] - 12s 49ms/step - loss: 5.0519 - kl_loss: 1.3334 - mse_loss: 3.7185 - val_loss: 5.6158 - val_kl_loss: 1.3245 - val_mse_loss: 4.2913\n",
            "Epoch 154/200\n",
            "235/235 [==============================] - 11s 49ms/step - loss: 5.0558 - kl_loss: 1.3330 - mse_loss: 3.7228 - val_loss: 5.5783 - val_kl_loss: 1.3275 - val_mse_loss: 4.2509\n",
            "Epoch 155/200\n",
            "235/235 [==============================] - 12s 49ms/step - loss: 5.0478 - kl_loss: 1.3330 - mse_loss: 3.7148 - val_loss: 5.5696 - val_kl_loss: 1.3387 - val_mse_loss: 4.2309\n",
            "Epoch 156/200\n",
            "235/235 [==============================] - 11s 49ms/step - loss: 5.0478 - kl_loss: 1.3331 - mse_loss: 3.7148 - val_loss: 5.5964 - val_kl_loss: 1.3162 - val_mse_loss: 4.2801\n",
            "Epoch 157/200\n",
            "235/235 [==============================] - 12s 52ms/step - loss: 5.0538 - kl_loss: 1.3326 - mse_loss: 3.7211 - val_loss: 5.5565 - val_kl_loss: 1.3679 - val_mse_loss: 4.1887\n",
            "Epoch 158/200\n",
            "235/235 [==============================] - 12s 50ms/step - loss: 5.0505 - kl_loss: 1.3327 - mse_loss: 3.7178 - val_loss: 5.5344 - val_kl_loss: 1.3436 - val_mse_loss: 4.1909\n",
            "Epoch 159/200\n",
            "235/235 [==============================] - 12s 50ms/step - loss: 5.0312 - kl_loss: 1.3315 - mse_loss: 3.6997 - val_loss: 5.5805 - val_kl_loss: 1.3337 - val_mse_loss: 4.2468\n",
            "Epoch 160/200\n",
            "235/235 [==============================] - 12s 49ms/step - loss: 5.0474 - kl_loss: 1.3318 - mse_loss: 3.7156 - val_loss: 5.5802 - val_kl_loss: 1.3265 - val_mse_loss: 4.2537\n",
            "Epoch 161/200\n",
            "235/235 [==============================] - 11s 49ms/step - loss: 5.0441 - kl_loss: 1.3332 - mse_loss: 3.7109 - val_loss: 5.5711 - val_kl_loss: 1.3129 - val_mse_loss: 4.2581\n",
            "Epoch 162/200\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 5.0408 - kl_loss: 1.3317 - mse_loss: 3.7090 - val_loss: 5.5613 - val_kl_loss: 1.3278 - val_mse_loss: 4.2336\n",
            "Epoch 163/200\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 5.0295 - kl_loss: 1.3322 - mse_loss: 3.6973 - val_loss: 5.5445 - val_kl_loss: 1.3080 - val_mse_loss: 4.2365\n",
            "Epoch 164/200\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 5.0294 - kl_loss: 1.3328 - mse_loss: 3.6966 - val_loss: 5.5572 - val_kl_loss: 1.3383 - val_mse_loss: 4.2188\n",
            "Epoch 165/200\n",
            "235/235 [==============================] - 11s 49ms/step - loss: 5.0244 - kl_loss: 1.3323 - mse_loss: 3.6921 - val_loss: 5.5829 - val_kl_loss: 1.3202 - val_mse_loss: 4.2627\n",
            "Epoch 166/200\n",
            "235/235 [==============================] - 12s 51ms/step - loss: 5.0319 - kl_loss: 1.3319 - mse_loss: 3.7000 - val_loss: 5.5377 - val_kl_loss: 1.3280 - val_mse_loss: 4.2098\n",
            "Epoch 167/200\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 5.0306 - kl_loss: 1.3326 - mse_loss: 3.6980 - val_loss: 5.5400 - val_kl_loss: 1.3355 - val_mse_loss: 4.2045\n",
            "Epoch 168/200\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 5.0134 - kl_loss: 1.3325 - mse_loss: 3.6809 - val_loss: 5.5320 - val_kl_loss: 1.3749 - val_mse_loss: 4.1571\n",
            "Epoch 169/200\n",
            "235/235 [==============================] - 11s 49ms/step - loss: 5.0272 - kl_loss: 1.3315 - mse_loss: 3.6957 - val_loss: 5.5404 - val_kl_loss: 1.3250 - val_mse_loss: 4.2153\n",
            "Epoch 170/200\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 5.0180 - kl_loss: 1.3319 - mse_loss: 3.6861 - val_loss: 5.5558 - val_kl_loss: 1.3441 - val_mse_loss: 4.2117\n",
            "Epoch 171/200\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 5.0216 - kl_loss: 1.3322 - mse_loss: 3.6894 - val_loss: 5.5740 - val_kl_loss: 1.3289 - val_mse_loss: 4.2451\n",
            "Epoch 172/200\n",
            "235/235 [==============================] - 11s 49ms/step - loss: 5.0209 - kl_loss: 1.3317 - mse_loss: 3.6892 - val_loss: 5.5651 - val_kl_loss: 1.3038 - val_mse_loss: 4.2613\n",
            "Epoch 173/200\n",
            "235/235 [==============================] - 11s 49ms/step - loss: 5.0123 - kl_loss: 1.3322 - mse_loss: 3.6801 - val_loss: 5.5379 - val_kl_loss: 1.3209 - val_mse_loss: 4.2170\n",
            "Epoch 174/200\n",
            "235/235 [==============================] - 11s 49ms/step - loss: 5.0152 - kl_loss: 1.3309 - mse_loss: 3.6844 - val_loss: 5.5775 - val_kl_loss: 1.3275 - val_mse_loss: 4.2500\n",
            "Epoch 175/200\n",
            "235/235 [==============================] - 12s 50ms/step - loss: 5.0110 - kl_loss: 1.3314 - mse_loss: 3.6796 - val_loss: 5.5699 - val_kl_loss: 1.3181 - val_mse_loss: 4.2519\n",
            "Epoch 176/200\n",
            "235/235 [==============================] - 12s 50ms/step - loss: 5.0177 - kl_loss: 1.3305 - mse_loss: 3.6872 - val_loss: 5.5604 - val_kl_loss: 1.3168 - val_mse_loss: 4.2436\n",
            "Epoch 177/200\n",
            "235/235 [==============================] - 12s 49ms/step - loss: 5.0056 - kl_loss: 1.3322 - mse_loss: 3.6734 - val_loss: 5.5346 - val_kl_loss: 1.3306 - val_mse_loss: 4.2041\n",
            "Epoch 178/200\n",
            "235/235 [==============================] - 12s 50ms/step - loss: 5.0050 - kl_loss: 1.3315 - mse_loss: 3.6735 - val_loss: 5.5341 - val_kl_loss: 1.3424 - val_mse_loss: 4.1917\n",
            "Epoch 179/200\n",
            "235/235 [==============================] - 12s 50ms/step - loss: 5.0020 - kl_loss: 1.3312 - mse_loss: 3.6708 - val_loss: 5.5230 - val_kl_loss: 1.3464 - val_mse_loss: 4.1766\n",
            "Epoch 180/200\n",
            "235/235 [==============================] - 12s 50ms/step - loss: 4.9991 - kl_loss: 1.3316 - mse_loss: 3.6675 - val_loss: 5.5121 - val_kl_loss: 1.3436 - val_mse_loss: 4.1685\n",
            "Epoch 181/200\n",
            "235/235 [==============================] - 11s 49ms/step - loss: 4.9916 - kl_loss: 1.3314 - mse_loss: 3.6602 - val_loss: 5.5426 - val_kl_loss: 1.3408 - val_mse_loss: 4.2018\n",
            "Epoch 182/200\n",
            "235/235 [==============================] - 12s 49ms/step - loss: 4.9973 - kl_loss: 1.3310 - mse_loss: 3.6664 - val_loss: 5.5797 - val_kl_loss: 1.3107 - val_mse_loss: 4.2690\n",
            "Epoch 183/200\n",
            "235/235 [==============================] - 12s 49ms/step - loss: 4.9942 - kl_loss: 1.3307 - mse_loss: 3.6635 - val_loss: 5.5119 - val_kl_loss: 1.3073 - val_mse_loss: 4.2046\n",
            "Epoch 184/200\n",
            "235/235 [==============================] - 12s 49ms/step - loss: 5.0044 - kl_loss: 1.3315 - mse_loss: 3.6729 - val_loss: 5.5337 - val_kl_loss: 1.3228 - val_mse_loss: 4.2109\n",
            "Epoch 185/200\n",
            "235/235 [==============================] - 11s 49ms/step - loss: 4.9974 - kl_loss: 1.3301 - mse_loss: 3.6673 - val_loss: 5.5408 - val_kl_loss: 1.3044 - val_mse_loss: 4.2364\n",
            "Epoch 186/200\n",
            "235/235 [==============================] - 11s 49ms/step - loss: 4.9857 - kl_loss: 1.3304 - mse_loss: 3.6553 - val_loss: 5.5357 - val_kl_loss: 1.3593 - val_mse_loss: 4.1764\n",
            "Epoch 187/200\n",
            "235/235 [==============================] - 11s 49ms/step - loss: 4.9888 - kl_loss: 1.3306 - mse_loss: 3.6582 - val_loss: 5.5485 - val_kl_loss: 1.3312 - val_mse_loss: 4.2174\n",
            "Epoch 188/200\n",
            "235/235 [==============================] - 12s 49ms/step - loss: 4.9916 - kl_loss: 1.3306 - mse_loss: 3.6609 - val_loss: 5.5053 - val_kl_loss: 1.3076 - val_mse_loss: 4.1977\n",
            "Epoch 189/200\n",
            "235/235 [==============================] - 12s 49ms/step - loss: 4.9825 - kl_loss: 1.3302 - mse_loss: 3.6524 - val_loss: 5.5382 - val_kl_loss: 1.3247 - val_mse_loss: 4.2135\n",
            "Epoch 190/200\n",
            "235/235 [==============================] - 12s 49ms/step - loss: 4.9895 - kl_loss: 1.3302 - mse_loss: 3.6593 - val_loss: 5.5180 - val_kl_loss: 1.3548 - val_mse_loss: 4.1633\n",
            "Epoch 191/200\n",
            "235/235 [==============================] - 11s 49ms/step - loss: 4.9762 - kl_loss: 1.3304 - mse_loss: 3.6459 - val_loss: 5.5040 - val_kl_loss: 1.3300 - val_mse_loss: 4.1740\n",
            "Epoch 192/200\n",
            "235/235 [==============================] - 12s 49ms/step - loss: 4.9781 - kl_loss: 1.3295 - mse_loss: 3.6486 - val_loss: 5.5114 - val_kl_loss: 1.3395 - val_mse_loss: 4.1719\n",
            "Epoch 193/200\n",
            "235/235 [==============================] - 12s 49ms/step - loss: 4.9714 - kl_loss: 1.3299 - mse_loss: 3.6415 - val_loss: 5.5016 - val_kl_loss: 1.3317 - val_mse_loss: 4.1700\n",
            "Epoch 194/200\n",
            "235/235 [==============================] - 12s 49ms/step - loss: 4.9836 - kl_loss: 1.3295 - mse_loss: 3.6541 - val_loss: 5.5533 - val_kl_loss: 1.3642 - val_mse_loss: 4.1892\n",
            "Epoch 195/200\n",
            "235/235 [==============================] - 12s 50ms/step - loss: 4.9730 - kl_loss: 1.3300 - mse_loss: 3.6430 - val_loss: 5.5394 - val_kl_loss: 1.3534 - val_mse_loss: 4.1859\n",
            "Epoch 196/200\n",
            "235/235 [==============================] - 12s 50ms/step - loss: 4.9785 - kl_loss: 1.3301 - mse_loss: 3.6485 - val_loss: 5.5130 - val_kl_loss: 1.3363 - val_mse_loss: 4.1767\n",
            "Epoch 197/200\n",
            "235/235 [==============================] - 11s 49ms/step - loss: 4.9741 - kl_loss: 1.3300 - mse_loss: 3.6441 - val_loss: 5.5315 - val_kl_loss: 1.3219 - val_mse_loss: 4.2095\n",
            "Epoch 198/200\n",
            "235/235 [==============================] - 12s 49ms/step - loss: 4.9688 - kl_loss: 1.3305 - mse_loss: 3.6383 - val_loss: 5.5564 - val_kl_loss: 1.3173 - val_mse_loss: 4.2391\n",
            "Epoch 199/200\n",
            "235/235 [==============================] - 12s 49ms/step - loss: 4.9710 - kl_loss: 1.3291 - mse_loss: 3.6419 - val_loss: 5.5404 - val_kl_loss: 1.3209 - val_mse_loss: 4.2195\n",
            "Epoch 200/200\n",
            "235/235 [==============================] - 17s 71ms/step - loss: 4.9662 - kl_loss: 1.3292 - mse_loss: 3.6370 - val_loss: 5.5500 - val_kl_loss: 1.3248 - val_mse_loss: 4.2251\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generative Adversarial Model"
      ],
      "metadata": {
        "id": "G82S6z111cm-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The code moving forward is referred from lecture notes with changes in layers.\n",
        "\n",
        "# Defining the dimension of input image and latent layer.\n",
        "img_shape = (28 * 28,)\n",
        "# the more the intermediate dimension, the more clear the image is.\n",
        "z_dim = 100\n",
        "\n",
        "# Defining generator model (like AE decoder)\n",
        "# z -> hidden layer -> image\n",
        "Generator = Sequential()\n",
        "Generator.add(Input(shape=(z_dim,)))\n",
        "# Layer 1\n",
        "Generator.add(Dense(256))\n",
        "Generator.add(LeakyReLU(alpha=0.2))\n",
        "Generator.add(BatchNormalization(momentum=0.8))\n",
        "# Layer 2\n",
        "Generator.add(Dense(512))\n",
        "Generator.add(LeakyReLU(alpha=0.2))\n",
        "Generator.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "# output image layer.\n",
        "Generator.add(Dense(np.prod(img_shape), activation=\"tanh\"))\n",
        "Generator.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "riOCgH0p1fzg",
        "outputId": "99196c97-4df4-4ab6-d65b-e69649a5a41f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_11 (Dense)            (None, 256)               25856     \n",
            "                                                                 \n",
            " leaky_re_lu_9 (LeakyReLU)   (None, 256)               0         \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 256)              1024      \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 512)               131584    \n",
            "                                                                 \n",
            " leaky_re_lu_10 (LeakyReLU)  (None, 512)               0         \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 512)              2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 784)               402192    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 562,704\n",
            "Trainable params: 561,168\n",
            "Non-trainable params: 1,536\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definining discriminator model\n",
        "# image -> hidden layer -> class 0 or 1 (real or fake)\n",
        "Discriminator = Sequential()\n",
        "Discriminator.add(Input(shape=(img_shape)))\n",
        "# Layer 1\n",
        "Discriminator.add(Dense(512))\n",
        "Discriminator.add(LeakyReLU(alpha=0.2))\n",
        "# Layer 2\n",
        "Discriminator.add(Dense(256))\n",
        "Discriminator.add(LeakyReLU(alpha=0.2))\n",
        "# classifying image as real or fake using this layer.\n",
        "Discriminator.add(Dense(1, activation='sigmoid')) # binary classification\n",
        "Discriminator.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUouCqb0TblN",
        "outputId": "7d8f8ba4-72f6-4f14-9ed5-b323829230ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_14 (Dense)            (None, 512)               401920    \n",
            "                                                                 \n",
            " leaky_re_lu_11 (LeakyReLU)  (None, 512)               0         \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 256)               131328    \n",
            "                                                                 \n",
            " leaky_re_lu_12 (LeakyReLU)  (None, 256)               0         \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 533,505\n",
            "Trainable params: 533,505\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# using adam optimizer with 0.0001 learning rate.\n",
        "Discriminator.compile(loss='mse', optimizer=adam_v2.Adam(0.0001, 0.5),\n",
        "          metrics=['accuracy'])\n",
        "\n",
        "# making the discriminator not trainable.\n",
        "Discriminator.trainable = False\n",
        "z = Input(shape=(z_dim,))\n",
        "# creating a GAN model using generator and discriminator.\n",
        "# the images generated from generator are classified using discriminator.\n",
        "GAN = Model(z, Discriminator(Generator(z)))\n",
        "GAN.compile(loss='mse', optimizer=adam_v2.Adam(0.0001, 0.5),\n",
        "          metrics=['accuracy'])\n",
        "GAN.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FQmAeZvX_rr",
        "outputId": "f29c490f-2539-43eb-8c7c-679426660e89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 100)]             0         \n",
            "                                                                 \n",
            " sequential (Sequential)     (None, 784)               562704    \n",
            "                                                                 \n",
            " sequential_1 (Sequential)   (None, 1)                 533505    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,096,209\n",
            "Trainable params: 561,168\n",
            "Non-trainable params: 535,041\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# since we are using tanh, thus the range of values should be between -1 to 1. \n",
        "X_train_gan = X_train / 127.5 - 1\n",
        "# calculating the number of iterations.\n",
        "batch_size=100\n",
        "epochs = 100\n",
        "steps = epochs * X_train_gan.shape[0] // batch_size\n",
        "sample_interval=100\n",
        "# fake -> 1, real -> 0\n",
        "y_fake = np.ones((batch_size, 1))\n",
        "y_real = np.zeros((batch_size, 1))\n",
        "\n",
        "def sample_images():\n",
        "    # saving image to see some images generated\n",
        "    r, c = 3, 3\n",
        "    z = np.random.normal(0, 1, (r * c, z_dim))\n",
        "    x_fake = Generator.predict(z)\n",
        "\n",
        "    # creating a 3*3 grid.\n",
        "    fig, axs = plt.subplots(r, c)\n",
        "    for i in range(r):\n",
        "        for j in range(c):\n",
        "          # setting an image in the grid.\n",
        "            axs[i, j].imshow(x_fake[i*r+j].reshape((28, 28)), cmap='gray_r')\n",
        "            axs[i, j].axis('off')\n",
        "    plt.savefig(\"gan_mnist.png\")\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "nGv7tmZn3K9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for each step generating images.\n",
        "for step in range(steps):\n",
        "\n",
        "    # choose real images to generate fake images.\n",
        "    idx = np.random.randint(0, X_train_gan.shape[0], batch_size)\n",
        "    x_real = X_train_gan[idx]\n",
        "    z = np.random.normal(0, 1, (batch_size, z_dim))\n",
        "    x_fake = Generator.predict(z)\n",
        "\n",
        "    # train Discriminator on real and fake images.\n",
        "    loss_d_real = Discriminator.train_on_batch(x_real, y_real)\n",
        "    loss_d_fake = Discriminator.train_on_batch(x_fake, y_fake)\n",
        "    loss_d = 0.5 * np.add(loss_d_real, loss_d_fake)\n",
        "\n",
        "    # train generator.\n",
        "    loss_g = GAN.train_on_batch(z, y_real)\n",
        "\n",
        "    # loss_g and loss_d are loss and accuracy.\n",
        "    print(f\"{step:4d}/{steps} [D {loss_d[0]:.2f}, acc. (on x_real and x_fake) {100 * loss_d[1]:3.0f}] [G {loss_g[0]:.2f}, acc. (on x_fake) {100 * loss_g[1]:3.0f}]\")\n",
        "    if step % sample_interval == 0 or step == steps - 1:\n",
        "      # storing every 100th image.\n",
        "      sample_images()\n",
        "     \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRCZrm9M3EXA",
        "outputId": "963e18c6-9149-432e-9876-1c07a9daaf60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "55000/60000 [D 0.16, acc. (on x_real and x_fake)  79] [G 0.50, acc. (on x_fake)   6]\n",
            "55001/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.47, acc. (on x_fake)   9]\n",
            "55002/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.46, acc. (on x_fake)  12]\n",
            "55003/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.48, acc. (on x_fake)   8]\n",
            "55004/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)  10]\n",
            "55005/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.47, acc. (on x_fake)   7]\n",
            "55006/60000 [D 0.19, acc. (on x_real and x_fake)  76] [G 0.48, acc. (on x_fake)   8]\n",
            "55007/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)  14]\n",
            "55008/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.49, acc. (on x_fake)   8]\n",
            "55009/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.47, acc. (on x_fake)   6]\n",
            "55010/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.46, acc. (on x_fake)   9]\n",
            "55011/60000 [D 0.21, acc. (on x_real and x_fake)  70] [G 0.45, acc. (on x_fake)  15]\n",
            "55012/60000 [D 0.19, acc. (on x_real and x_fake)  68] [G 0.47, acc. (on x_fake)  19]\n",
            "55013/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)  13]\n",
            "55014/60000 [D 0.15, acc. (on x_real and x_fake)  80] [G 0.48, acc. (on x_fake)  17]\n",
            "55015/60000 [D 0.20, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)   9]\n",
            "55016/60000 [D 0.19, acc. (on x_real and x_fake)  67] [G 0.48, acc. (on x_fake)  10]\n",
            "55017/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.45, acc. (on x_fake)  16]\n",
            "55018/60000 [D 0.21, acc. (on x_real and x_fake)  71] [G 0.44, acc. (on x_fake)  19]\n",
            "55019/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)   8]\n",
            "55020/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.50, acc. (on x_fake)   4]\n",
            "55021/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)  10]\n",
            "55022/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.46, acc. (on x_fake)   8]\n",
            "55023/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.47, acc. (on x_fake)  13]\n",
            "55024/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.46, acc. (on x_fake)  15]\n",
            "55025/60000 [D 0.20, acc. (on x_real and x_fake)  63] [G 0.46, acc. (on x_fake)  12]\n",
            "55026/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.47, acc. (on x_fake)  12]\n",
            "55027/60000 [D 0.17, acc. (on x_real and x_fake)  80] [G 0.49, acc. (on x_fake)   8]\n",
            "55028/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.47, acc. (on x_fake)  11]\n",
            "55029/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)   9]\n",
            "55030/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.48, acc. (on x_fake)   6]\n",
            "55031/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.46, acc. (on x_fake)  10]\n",
            "55032/60000 [D 0.18, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)  11]\n",
            "55033/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.46, acc. (on x_fake)  14]\n",
            "55034/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.46, acc. (on x_fake)   8]\n",
            "55035/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)  10]\n",
            "55036/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.47, acc. (on x_fake)  12]\n",
            "55037/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)  12]\n",
            "55038/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.50, acc. (on x_fake)  12]\n",
            "55039/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)   9]\n",
            "55040/60000 [D 0.16, acc. (on x_real and x_fake)  79] [G 0.50, acc. (on x_fake)   6]\n",
            "55041/60000 [D 0.20, acc. (on x_real and x_fake)  68] [G 0.48, acc. (on x_fake)   8]\n",
            "55042/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)   9]\n",
            "55043/60000 [D 0.21, acc. (on x_real and x_fake)  70] [G 0.43, acc. (on x_fake)  15]\n",
            "55044/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.46, acc. (on x_fake)   8]\n",
            "55045/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.47, acc. (on x_fake)  12]\n",
            "55046/60000 [D 0.20, acc. (on x_real and x_fake)  70] [G 0.50, acc. (on x_fake)   7]\n",
            "55047/60000 [D 0.17, acc. (on x_real and x_fake)  73] [G 0.46, acc. (on x_fake)  11]\n",
            "55048/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)  10]\n",
            "55049/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.50, acc. (on x_fake)   7]\n",
            "55050/60000 [D 0.18, acc. (on x_real and x_fake)  78] [G 0.50, acc. (on x_fake)   5]\n",
            "55051/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  14]\n",
            "55052/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.52, acc. (on x_fake)   3]\n",
            "55053/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)   8]\n",
            "55054/60000 [D 0.16, acc. (on x_real and x_fake)  78] [G 0.51, acc. (on x_fake)   6]\n",
            "55055/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)   9]\n",
            "55056/60000 [D 0.18, acc. (on x_real and x_fake)  77] [G 0.47, acc. (on x_fake)  12]\n",
            "55057/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)   7]\n",
            "55058/60000 [D 0.16, acc. (on x_real and x_fake)  78] [G 0.47, acc. (on x_fake)   8]\n",
            "55059/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.45, acc. (on x_fake)  12]\n",
            "55060/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)   7]\n",
            "55061/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)   8]\n",
            "55062/60000 [D 0.16, acc. (on x_real and x_fake)  78] [G 0.47, acc. (on x_fake)   9]\n",
            "55063/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.49, acc. (on x_fake)   9]\n",
            "55064/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)   9]\n",
            "55065/60000 [D 0.19, acc. (on x_real and x_fake)  77] [G 0.49, acc. (on x_fake)  11]\n",
            "55066/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  12]\n",
            "55067/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)   9]\n",
            "55068/60000 [D 0.20, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)  14]\n",
            "55069/60000 [D 0.20, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)  11]\n",
            "55070/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.46, acc. (on x_fake)  15]\n",
            "55071/60000 [D 0.18, acc. (on x_real and x_fake)  69] [G 0.46, acc. (on x_fake)  16]\n",
            "55072/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)   9]\n",
            "55073/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)  11]\n",
            "55074/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)  10]\n",
            "55075/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.48, acc. (on x_fake)   9]\n",
            "55076/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.46, acc. (on x_fake)   6]\n",
            "55077/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.46, acc. (on x_fake)  16]\n",
            "55078/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   7]\n",
            "55079/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.46, acc. (on x_fake)  11]\n",
            "55080/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)   6]\n",
            "55081/60000 [D 0.21, acc. (on x_real and x_fake)  69] [G 0.45, acc. (on x_fake)  11]\n",
            "55082/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)  10]\n",
            "55083/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  14]\n",
            "55084/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)  13]\n",
            "55085/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  10]\n",
            "55086/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)   8]\n",
            "55087/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)  11]\n",
            "55088/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  12]\n",
            "55089/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)   8]\n",
            "55090/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.44, acc. (on x_fake)  11]\n",
            "55091/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  13]\n",
            "55092/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)  13]\n",
            "55093/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  12]\n",
            "55094/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)  12]\n",
            "55095/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.48, acc. (on x_fake)  10]\n",
            "55096/60000 [D 0.18, acc. (on x_real and x_fake)  70] [G 0.49, acc. (on x_fake)   7]\n",
            "55097/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.44, acc. (on x_fake)  18]\n",
            "55098/60000 [D 0.19, acc. (on x_real and x_fake)  76] [G 0.48, acc. (on x_fake)  13]\n",
            "55099/60000 [D 0.19, acc. (on x_real and x_fake)  77] [G 0.47, acc. (on x_fake)  10]\n",
            "55100/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.45, acc. (on x_fake)  17]\n",
            "55101/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)  11]\n",
            "55102/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  11]\n",
            "55103/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.46, acc. (on x_fake)  13]\n",
            "55104/60000 [D 0.17, acc. (on x_real and x_fake)  73] [G 0.46, acc. (on x_fake)  12]\n",
            "55105/60000 [D 0.21, acc. (on x_real and x_fake)  64] [G 0.46, acc. (on x_fake)   7]\n",
            "55106/60000 [D 0.18, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)  10]\n",
            "55107/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.51, acc. (on x_fake)   4]\n",
            "55108/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)   7]\n",
            "55109/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.45, acc. (on x_fake)  17]\n",
            "55110/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.45, acc. (on x_fake)   8]\n",
            "55111/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  19]\n",
            "55112/60000 [D 0.16, acc. (on x_real and x_fake)  78] [G 0.48, acc. (on x_fake)   7]\n",
            "55113/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  11]\n",
            "55114/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)  10]\n",
            "55115/60000 [D 0.20, acc. (on x_real and x_fake)  70] [G 0.43, acc. (on x_fake)  16]\n",
            "55116/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.45, acc. (on x_fake)  13]\n",
            "55117/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.49, acc. (on x_fake)  10]\n",
            "55118/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.51, acc. (on x_fake)   8]\n",
            "55119/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.48, acc. (on x_fake)  10]\n",
            "55120/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.48, acc. (on x_fake)  11]\n",
            "55121/60000 [D 0.19, acc. (on x_real and x_fake)  68] [G 0.44, acc. (on x_fake)  12]\n",
            "55122/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.45, acc. (on x_fake)  12]\n",
            "55123/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.42, acc. (on x_fake)  19]\n",
            "55124/60000 [D 0.18, acc. (on x_real and x_fake)  77] [G 0.48, acc. (on x_fake)   9]\n",
            "55125/60000 [D 0.19, acc. (on x_real and x_fake)  68] [G 0.45, acc. (on x_fake)   8]\n",
            "55126/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.46, acc. (on x_fake)  13]\n",
            "55127/60000 [D 0.16, acc. (on x_real and x_fake)  80] [G 0.50, acc. (on x_fake)   7]\n",
            "55128/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.50, acc. (on x_fake)   7]\n",
            "55129/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.48, acc. (on x_fake)   7]\n",
            "55130/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.45, acc. (on x_fake)  11]\n",
            "55131/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.44, acc. (on x_fake)  12]\n",
            "55132/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)  11]\n",
            "55133/60000 [D 0.19, acc. (on x_real and x_fake)  66] [G 0.49, acc. (on x_fake)   5]\n",
            "55134/60000 [D 0.17, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)  13]\n",
            "55135/60000 [D 0.16, acc. (on x_real and x_fake)  77] [G 0.49, acc. (on x_fake)   6]\n",
            "55136/60000 [D 0.19, acc. (on x_real and x_fake)  66] [G 0.46, acc. (on x_fake)  11]\n",
            "55137/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.46, acc. (on x_fake)  11]\n",
            "55138/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.45, acc. (on x_fake)   7]\n",
            "55139/60000 [D 0.20, acc. (on x_real and x_fake)  66] [G 0.44, acc. (on x_fake)  19]\n",
            "55140/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.46, acc. (on x_fake)  12]\n",
            "55141/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  11]\n",
            "55142/60000 [D 0.20, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  13]\n",
            "55143/60000 [D 0.20, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  12]\n",
            "55144/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)  16]\n",
            "55145/60000 [D 0.18, acc. (on x_real and x_fake)  78] [G 0.48, acc. (on x_fake)  13]\n",
            "55146/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.49, acc. (on x_fake)   7]\n",
            "55147/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.50, acc. (on x_fake)   7]\n",
            "55148/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.50, acc. (on x_fake)  14]\n",
            "55149/60000 [D 0.17, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)  11]\n",
            "55150/60000 [D 0.16, acc. (on x_real and x_fake)  78] [G 0.47, acc. (on x_fake)  14]\n",
            "55151/60000 [D 0.19, acc. (on x_real and x_fake)  68] [G 0.49, acc. (on x_fake)   8]\n",
            "55152/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)  14]\n",
            "55153/60000 [D 0.20, acc. (on x_real and x_fake)  66] [G 0.47, acc. (on x_fake)  17]\n",
            "55154/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)  11]\n",
            "55155/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)   7]\n",
            "55156/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.45, acc. (on x_fake)  15]\n",
            "55157/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   5]\n",
            "55158/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  13]\n",
            "55159/60000 [D 0.20, acc. (on x_real and x_fake)  67] [G 0.44, acc. (on x_fake)  13]\n",
            "55160/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)   8]\n",
            "55161/60000 [D 0.20, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)   8]\n",
            "55162/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.48, acc. (on x_fake)   5]\n",
            "55163/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)   9]\n",
            "55164/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.46, acc. (on x_fake)   7]\n",
            "55165/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)   7]\n",
            "55166/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.46, acc. (on x_fake)  15]\n",
            "55167/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.47, acc. (on x_fake)   7]\n",
            "55168/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   6]\n",
            "55169/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)   7]\n",
            "55170/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.51, acc. (on x_fake)   6]\n",
            "55171/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.46, acc. (on x_fake)  13]\n",
            "55172/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.46, acc. (on x_fake)  15]\n",
            "55173/60000 [D 0.19, acc. (on x_real and x_fake)  75] [G 0.46, acc. (on x_fake)  12]\n",
            "55174/60000 [D 0.20, acc. (on x_real and x_fake)  68] [G 0.46, acc. (on x_fake)  15]\n",
            "55175/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.50, acc. (on x_fake)  10]\n",
            "55176/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.49, acc. (on x_fake)  11]\n",
            "55177/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)   8]\n",
            "55178/60000 [D 0.17, acc. (on x_real and x_fake)  79] [G 0.50, acc. (on x_fake)  10]\n",
            "55179/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.47, acc. (on x_fake)  12]\n",
            "55180/60000 [D 0.16, acc. (on x_real and x_fake)  75] [G 0.51, acc. (on x_fake)   7]\n",
            "55181/60000 [D 0.17, acc. (on x_real and x_fake)  73] [G 0.51, acc. (on x_fake)   8]\n",
            "55182/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  13]\n",
            "55183/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.46, acc. (on x_fake)  11]\n",
            "55184/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.47, acc. (on x_fake)   8]\n",
            "55185/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.46, acc. (on x_fake)  11]\n",
            "55186/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.45, acc. (on x_fake)  12]\n",
            "55187/60000 [D 0.20, acc. (on x_real and x_fake)  68] [G 0.44, acc. (on x_fake)  16]\n",
            "55188/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  10]\n",
            "55189/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   6]\n",
            "55190/60000 [D 0.21, acc. (on x_real and x_fake)  66] [G 0.46, acc. (on x_fake)  14]\n",
            "55191/60000 [D 0.17, acc. (on x_real and x_fake)  79] [G 0.48, acc. (on x_fake)   8]\n",
            "55192/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.49, acc. (on x_fake)   6]\n",
            "55193/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.45, acc. (on x_fake)  13]\n",
            "55194/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.46, acc. (on x_fake)   9]\n",
            "55195/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)  10]\n",
            "55196/60000 [D 0.17, acc. (on x_real and x_fake)  72] [G 0.45, acc. (on x_fake)  15]\n",
            "55197/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  14]\n",
            "55198/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)  11]\n",
            "55199/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.46, acc. (on x_fake)  19]\n",
            "55200/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.49, acc. (on x_fake)   8]\n",
            "55201/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.42, acc. (on x_fake)  17]\n",
            "55202/60000 [D 0.18, acc. (on x_real and x_fake)  70] [G 0.46, acc. (on x_fake)  13]\n",
            "55203/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.46, acc. (on x_fake)   9]\n",
            "55204/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.47, acc. (on x_fake)  15]\n",
            "55205/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.47, acc. (on x_fake)  18]\n",
            "55206/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.47, acc. (on x_fake)  14]\n",
            "55207/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.51, acc. (on x_fake)   5]\n",
            "55208/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.50, acc. (on x_fake)   9]\n",
            "55209/60000 [D 0.18, acc. (on x_real and x_fake)  78] [G 0.49, acc. (on x_fake)   6]\n",
            "55210/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.48, acc. (on x_fake)   8]\n",
            "55211/60000 [D 0.17, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)   4]\n",
            "55212/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.50, acc. (on x_fake)  10]\n",
            "55213/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.50, acc. (on x_fake)   5]\n",
            "55214/60000 [D 0.16, acc. (on x_real and x_fake)  81] [G 0.51, acc. (on x_fake)   4]\n",
            "55215/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.46, acc. (on x_fake)  12]\n",
            "55216/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.45, acc. (on x_fake)   9]\n",
            "55217/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.46, acc. (on x_fake)  15]\n",
            "55218/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)   8]\n",
            "55219/60000 [D 0.20, acc. (on x_real and x_fake)  67] [G 0.47, acc. (on x_fake)  12]\n",
            "55220/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.47, acc. (on x_fake)   7]\n",
            "55221/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)  10]\n",
            "55222/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)  10]\n",
            "55223/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.46, acc. (on x_fake)  13]\n",
            "55224/60000 [D 0.18, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)  10]\n",
            "55225/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.50, acc. (on x_fake)  11]\n",
            "55226/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.47, acc. (on x_fake)   8]\n",
            "55227/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.46, acc. (on x_fake)   9]\n",
            "55228/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  13]\n",
            "55229/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.50, acc. (on x_fake)   9]\n",
            "55230/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.48, acc. (on x_fake)   7]\n",
            "55231/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)   5]\n",
            "55232/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  11]\n",
            "55233/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.46, acc. (on x_fake)  14]\n",
            "55234/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.47, acc. (on x_fake)  12]\n",
            "55235/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.48, acc. (on x_fake)  10]\n",
            "55236/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)   8]\n",
            "55237/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)   6]\n",
            "55238/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)   9]\n",
            "55239/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)   6]\n",
            "55240/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.51, acc. (on x_fake)   6]\n",
            "55241/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)   7]\n",
            "55242/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   8]\n",
            "55243/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)  17]\n",
            "55244/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.45, acc. (on x_fake)  15]\n",
            "55245/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.46, acc. (on x_fake)  10]\n",
            "55246/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)   6]\n",
            "55247/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.44, acc. (on x_fake)  13]\n",
            "55248/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)  13]\n",
            "55249/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  13]\n",
            "55250/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)   9]\n",
            "55251/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.50, acc. (on x_fake)  10]\n",
            "55252/60000 [D 0.20, acc. (on x_real and x_fake)  66] [G 0.45, acc. (on x_fake)  12]\n",
            "55253/60000 [D 0.18, acc. (on x_real and x_fake)  78] [G 0.43, acc. (on x_fake)  12]\n",
            "55254/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.46, acc. (on x_fake)  11]\n",
            "55255/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)  11]\n",
            "55256/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.49, acc. (on x_fake)  10]\n",
            "55257/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)  10]\n",
            "55258/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)  12]\n",
            "55259/60000 [D 0.19, acc. (on x_real and x_fake)  68] [G 0.46, acc. (on x_fake)  10]\n",
            "55260/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)  10]\n",
            "55261/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  10]\n",
            "55262/60000 [D 0.18, acc. (on x_real and x_fake)  70] [G 0.48, acc. (on x_fake)  11]\n",
            "55263/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)  12]\n",
            "55264/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)   9]\n",
            "55265/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)  16]\n",
            "55266/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.50, acc. (on x_fake)   8]\n",
            "55267/60000 [D 0.21, acc. (on x_real and x_fake)  69] [G 0.46, acc. (on x_fake)  15]\n",
            "55268/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.46, acc. (on x_fake)  12]\n",
            "55269/60000 [D 0.16, acc. (on x_real and x_fake)  80] [G 0.51, acc. (on x_fake)   9]\n",
            "55270/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.46, acc. (on x_fake)  10]\n",
            "55271/60000 [D 0.19, acc. (on x_real and x_fake)  75] [G 0.46, acc. (on x_fake)  10]\n",
            "55272/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)   9]\n",
            "55273/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  11]\n",
            "55274/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.46, acc. (on x_fake)  11]\n",
            "55275/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.46, acc. (on x_fake)  14]\n",
            "55276/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)   7]\n",
            "55277/60000 [D 0.16, acc. (on x_real and x_fake)  78] [G 0.53, acc. (on x_fake)   4]\n",
            "55278/60000 [D 0.18, acc. (on x_real and x_fake)  78] [G 0.51, acc. (on x_fake)   8]\n",
            "55279/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)   6]\n",
            "55280/60000 [D 0.17, acc. (on x_real and x_fake)  72] [G 0.50, acc. (on x_fake)   6]\n",
            "55281/60000 [D 0.17, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)   9]\n",
            "55282/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)  10]\n",
            "55283/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.45, acc. (on x_fake)  16]\n",
            "55284/60000 [D 0.17, acc. (on x_real and x_fake)  72] [G 0.45, acc. (on x_fake)  16]\n",
            "55285/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)  11]\n",
            "55286/60000 [D 0.20, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  11]\n",
            "55287/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  11]\n",
            "55288/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)  10]\n",
            "55289/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)  13]\n",
            "55290/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)   7]\n",
            "55291/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.46, acc. (on x_fake)  10]\n",
            "55292/60000 [D 0.20, acc. (on x_real and x_fake)  68] [G 0.50, acc. (on x_fake)   9]\n",
            "55293/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.45, acc. (on x_fake)  14]\n",
            "55294/60000 [D 0.19, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)  12]\n",
            "55295/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.45, acc. (on x_fake)  18]\n",
            "55296/60000 [D 0.20, acc. (on x_real and x_fake)  67] [G 0.49, acc. (on x_fake)   9]\n",
            "55297/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)   9]\n",
            "55298/60000 [D 0.20, acc. (on x_real and x_fake)  67] [G 0.47, acc. (on x_fake)   7]\n",
            "55299/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)  13]\n",
            "55300/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)  13]\n",
            "55301/60000 [D 0.20, acc. (on x_real and x_fake)  72] [G 0.44, acc. (on x_fake)  13]\n",
            "55302/60000 [D 0.21, acc. (on x_real and x_fake)  65] [G 0.48, acc. (on x_fake)   7]\n",
            "55303/60000 [D 0.21, acc. (on x_real and x_fake)  66] [G 0.48, acc. (on x_fake)  10]\n",
            "55304/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)   9]\n",
            "55305/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.45, acc. (on x_fake)  11]\n",
            "55306/60000 [D 0.20, acc. (on x_real and x_fake)  68] [G 0.45, acc. (on x_fake)  12]\n",
            "55307/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  11]\n",
            "55308/60000 [D 0.20, acc. (on x_real and x_fake)  71] [G 0.42, acc. (on x_fake)  18]\n",
            "55309/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.49, acc. (on x_fake)   4]\n",
            "55310/60000 [D 0.20, acc. (on x_real and x_fake)  68] [G 0.47, acc. (on x_fake)  14]\n",
            "55311/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.45, acc. (on x_fake)  11]\n",
            "55312/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)  10]\n",
            "55313/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   9]\n",
            "55314/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  11]\n",
            "55315/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  17]\n",
            "55316/60000 [D 0.22, acc. (on x_real and x_fake)  63] [G 0.50, acc. (on x_fake)  12]\n",
            "55317/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)  16]\n",
            "55318/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)  13]\n",
            "55319/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  12]\n",
            "55320/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)   9]\n",
            "55321/60000 [D 0.19, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)   8]\n",
            "55322/60000 [D 0.21, acc. (on x_real and x_fake)  67] [G 0.45, acc. (on x_fake)   9]\n",
            "55323/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)  10]\n",
            "55324/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  16]\n",
            "55325/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)   9]\n",
            "55326/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  10]\n",
            "55327/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)   7]\n",
            "55328/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)  10]\n",
            "55329/60000 [D 0.18, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)  15]\n",
            "55330/60000 [D 0.18, acc. (on x_real and x_fake)  78] [G 0.49, acc. (on x_fake)  10]\n",
            "55331/60000 [D 0.21, acc. (on x_real and x_fake)  64] [G 0.43, acc. (on x_fake)  22]\n",
            "55332/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.46, acc. (on x_fake)  12]\n",
            "55333/60000 [D 0.16, acc. (on x_real and x_fake)  80] [G 0.49, acc. (on x_fake)   7]\n",
            "55334/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.49, acc. (on x_fake)   9]\n",
            "55335/60000 [D 0.20, acc. (on x_real and x_fake)  67] [G 0.48, acc. (on x_fake)  11]\n",
            "55336/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)   7]\n",
            "55337/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  11]\n",
            "55338/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.45, acc. (on x_fake)  14]\n",
            "55339/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.46, acc. (on x_fake)  13]\n",
            "55340/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.50, acc. (on x_fake)   9]\n",
            "55341/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)   7]\n",
            "55342/60000 [D 0.19, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  10]\n",
            "55343/60000 [D 0.16, acc. (on x_real and x_fake)  78] [G 0.51, acc. (on x_fake)   8]\n",
            "55344/60000 [D 0.19, acc. (on x_real and x_fake)  68] [G 0.45, acc. (on x_fake)  15]\n",
            "55345/60000 [D 0.18, acc. (on x_real and x_fake)  77] [G 0.49, acc. (on x_fake)  12]\n",
            "55346/60000 [D 0.17, acc. (on x_real and x_fake)  71] [G 0.50, acc. (on x_fake)   9]\n",
            "55347/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  12]\n",
            "55348/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.46, acc. (on x_fake)  13]\n",
            "55349/60000 [D 0.18, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)   9]\n",
            "55350/60000 [D 0.20, acc. (on x_real and x_fake)  66] [G 0.48, acc. (on x_fake)  11]\n",
            "55351/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.48, acc. (on x_fake)   7]\n",
            "55352/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)  10]\n",
            "55353/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.44, acc. (on x_fake)  13]\n",
            "55354/60000 [D 0.17, acc. (on x_real and x_fake)  70] [G 0.46, acc. (on x_fake)  21]\n",
            "55355/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  10]\n",
            "55356/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.46, acc. (on x_fake)  13]\n",
            "55357/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.49, acc. (on x_fake)   9]\n",
            "55358/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   6]\n",
            "55359/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)  13]\n",
            "55360/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.46, acc. (on x_fake)  10]\n",
            "55361/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)   9]\n",
            "55362/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)   9]\n",
            "55363/60000 [D 0.18, acc. (on x_real and x_fake)  70] [G 0.49, acc. (on x_fake)  12]\n",
            "55364/60000 [D 0.18, acc. (on x_real and x_fake)  77] [G 0.48, acc. (on x_fake)  12]\n",
            "55365/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.47, acc. (on x_fake)  11]\n",
            "55366/60000 [D 0.16, acc. (on x_real and x_fake)  78] [G 0.52, acc. (on x_fake)   6]\n",
            "55367/60000 [D 0.18, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)  10]\n",
            "55368/60000 [D 0.19, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)  10]\n",
            "55369/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.50, acc. (on x_fake)   6]\n",
            "55370/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.45, acc. (on x_fake)  11]\n",
            "55371/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)  10]\n",
            "55372/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.49, acc. (on x_fake)  13]\n",
            "55373/60000 [D 0.22, acc. (on x_real and x_fake)  67] [G 0.46, acc. (on x_fake)  10]\n",
            "55374/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.49, acc. (on x_fake)  13]\n",
            "55375/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)   6]\n",
            "55376/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.47, acc. (on x_fake)   6]\n",
            "55377/60000 [D 0.17, acc. (on x_real and x_fake)  72] [G 0.51, acc. (on x_fake)   8]\n",
            "55378/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.46, acc. (on x_fake)  14]\n",
            "55379/60000 [D 0.20, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)  12]\n",
            "55380/60000 [D 0.20, acc. (on x_real and x_fake)  67] [G 0.48, acc. (on x_fake)   6]\n",
            "55381/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.50, acc. (on x_fake)   8]\n",
            "55382/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)   9]\n",
            "55383/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.47, acc. (on x_fake)  12]\n",
            "55384/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.47, acc. (on x_fake)  13]\n",
            "55385/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.46, acc. (on x_fake)  13]\n",
            "55386/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.46, acc. (on x_fake)  15]\n",
            "55387/60000 [D 0.16, acc. (on x_real and x_fake)  77] [G 0.49, acc. (on x_fake)  11]\n",
            "55388/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)   7]\n",
            "55389/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.47, acc. (on x_fake)  15]\n",
            "55390/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.46, acc. (on x_fake)  15]\n",
            "55391/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)   9]\n",
            "55392/60000 [D 0.16, acc. (on x_real and x_fake)  78] [G 0.51, acc. (on x_fake)   8]\n",
            "55393/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.51, acc. (on x_fake)   8]\n",
            "55394/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  11]\n",
            "55395/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.48, acc. (on x_fake)  10]\n",
            "55396/60000 [D 0.20, acc. (on x_real and x_fake)  68] [G 0.47, acc. (on x_fake)   7]\n",
            "55397/60000 [D 0.20, acc. (on x_real and x_fake)  64] [G 0.46, acc. (on x_fake)  10]\n",
            "55398/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.46, acc. (on x_fake)  12]\n",
            "55399/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.46, acc. (on x_fake)  12]\n",
            "55400/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)   9]\n",
            "55401/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)   9]\n",
            "55402/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)   6]\n",
            "55403/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.51, acc. (on x_fake)  10]\n",
            "55404/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.53, acc. (on x_fake)   8]\n",
            "55405/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  14]\n",
            "55406/60000 [D 0.16, acc. (on x_real and x_fake)  78] [G 0.52, acc. (on x_fake)   8]\n",
            "55407/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)   8]\n",
            "55408/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)   8]\n",
            "55409/60000 [D 0.18, acc. (on x_real and x_fake)  77] [G 0.49, acc. (on x_fake)  10]\n",
            "55410/60000 [D 0.16, acc. (on x_real and x_fake)  80] [G 0.50, acc. (on x_fake)   7]\n",
            "55411/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)  11]\n",
            "55412/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.50, acc. (on x_fake)   7]\n",
            "55413/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.48, acc. (on x_fake)  13]\n",
            "55414/60000 [D 0.20, acc. (on x_real and x_fake)  67] [G 0.46, acc. (on x_fake)   8]\n",
            "55415/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  13]\n",
            "55416/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.50, acc. (on x_fake)   4]\n",
            "55417/60000 [D 0.19, acc. (on x_real and x_fake)  76] [G 0.48, acc. (on x_fake)   8]\n",
            "55418/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)   9]\n",
            "55419/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)  11]\n",
            "55420/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.45, acc. (on x_fake)  12]\n",
            "55421/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.46, acc. (on x_fake)  18]\n",
            "55422/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.45, acc. (on x_fake)  16]\n",
            "55423/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.44, acc. (on x_fake)  16]\n",
            "55424/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  11]\n",
            "55425/60000 [D 0.19, acc. (on x_real and x_fake)  68] [G 0.44, acc. (on x_fake)  17]\n",
            "55426/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)  13]\n",
            "55427/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)  10]\n",
            "55428/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.47, acc. (on x_fake)  16]\n",
            "55429/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  11]\n",
            "55430/60000 [D 0.20, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  12]\n",
            "55431/60000 [D 0.19, acc. (on x_real and x_fake)  76] [G 0.48, acc. (on x_fake)   5]\n",
            "55432/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)  12]\n",
            "55433/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  15]\n",
            "55434/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.50, acc. (on x_fake)  10]\n",
            "55435/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.46, acc. (on x_fake)  10]\n",
            "55436/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.45, acc. (on x_fake)  17]\n",
            "55437/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.45, acc. (on x_fake)  19]\n",
            "55438/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.46, acc. (on x_fake)   8]\n",
            "55439/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.49, acc. (on x_fake)   7]\n",
            "55440/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)  14]\n",
            "55441/60000 [D 0.17, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)   6]\n",
            "55442/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)   5]\n",
            "55443/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  12]\n",
            "55444/60000 [D 0.16, acc. (on x_real and x_fake)  78] [G 0.49, acc. (on x_fake)  12]\n",
            "55445/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   7]\n",
            "55446/60000 [D 0.16, acc. (on x_real and x_fake)  77] [G 0.49, acc. (on x_fake)  14]\n",
            "55447/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.51, acc. (on x_fake)   8]\n",
            "55448/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)  14]\n",
            "55449/60000 [D 0.18, acc. (on x_real and x_fake)  77] [G 0.49, acc. (on x_fake)  11]\n",
            "55450/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.50, acc. (on x_fake)   6]\n",
            "55451/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  11]\n",
            "55452/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.50, acc. (on x_fake)   9]\n",
            "55453/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  16]\n",
            "55454/60000 [D 0.21, acc. (on x_real and x_fake)  68] [G 0.46, acc. (on x_fake)  13]\n",
            "55455/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)  11]\n",
            "55456/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.45, acc. (on x_fake)  18]\n",
            "55457/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)  14]\n",
            "55458/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.49, acc. (on x_fake)  14]\n",
            "55459/60000 [D 0.19, acc. (on x_real and x_fake)  67] [G 0.49, acc. (on x_fake)  11]\n",
            "55460/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)  13]\n",
            "55461/60000 [D 0.18, acc. (on x_real and x_fake)  77] [G 0.48, acc. (on x_fake)  12]\n",
            "55462/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.50, acc. (on x_fake)  11]\n",
            "55463/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  11]\n",
            "55464/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  11]\n",
            "55465/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)   6]\n",
            "55466/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)   9]\n",
            "55467/60000 [D 0.16, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)   8]\n",
            "55468/60000 [D 0.21, acc. (on x_real and x_fake)  64] [G 0.44, acc. (on x_fake)  13]\n",
            "55469/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)   8]\n",
            "55470/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.46, acc. (on x_fake)   7]\n",
            "55471/60000 [D 0.18, acc. (on x_real and x_fake)  77] [G 0.48, acc. (on x_fake)   5]\n",
            "55472/60000 [D 0.20, acc. (on x_real and x_fake)  72] [G 0.45, acc. (on x_fake)  15]\n",
            "55473/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)  10]\n",
            "55474/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.49, acc. (on x_fake)  12]\n",
            "55475/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)   9]\n",
            "55476/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.46, acc. (on x_fake)  12]\n",
            "55477/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.48, acc. (on x_fake)  13]\n",
            "55478/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.49, acc. (on x_fake)  10]\n",
            "55479/60000 [D 0.20, acc. (on x_real and x_fake)  71] [G 0.46, acc. (on x_fake)  14]\n",
            "55480/60000 [D 0.21, acc. (on x_real and x_fake)  66] [G 0.47, acc. (on x_fake)  12]\n",
            "55481/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.52, acc. (on x_fake)  11]\n",
            "55482/60000 [D 0.19, acc. (on x_real and x_fake)  75] [G 0.46, acc. (on x_fake)  15]\n",
            "55483/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  12]\n",
            "55484/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.50, acc. (on x_fake)   4]\n",
            "55485/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)  11]\n",
            "55486/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)  11]\n",
            "55487/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)  10]\n",
            "55488/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.50, acc. (on x_fake)   8]\n",
            "55489/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.46, acc. (on x_fake)  10]\n",
            "55490/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.49, acc. (on x_fake)  11]\n",
            "55491/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)  11]\n",
            "55492/60000 [D 0.20, acc. (on x_real and x_fake)  71] [G 0.45, acc. (on x_fake)  11]\n",
            "55493/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)  16]\n",
            "55494/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)   9]\n",
            "55495/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)  11]\n",
            "55496/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)   8]\n",
            "55497/60000 [D 0.20, acc. (on x_real and x_fake)  70] [G 0.48, acc. (on x_fake)  10]\n",
            "55498/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.47, acc. (on x_fake)  13]\n",
            "55499/60000 [D 0.21, acc. (on x_real and x_fake)  63] [G 0.47, acc. (on x_fake)  13]\n",
            "55500/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  10]\n",
            "55501/60000 [D 0.16, acc. (on x_real and x_fake)  77] [G 0.49, acc. (on x_fake)   9]\n",
            "55502/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.47, acc. (on x_fake)  10]\n",
            "55503/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.45, acc. (on x_fake)  18]\n",
            "55504/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)  12]\n",
            "55505/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)   9]\n",
            "55506/60000 [D 0.16, acc. (on x_real and x_fake)  79] [G 0.47, acc. (on x_fake)   6]\n",
            "55507/60000 [D 0.21, acc. (on x_real and x_fake)  68] [G 0.51, acc. (on x_fake)   7]\n",
            "55508/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  11]\n",
            "55509/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.46, acc. (on x_fake)  11]\n",
            "55510/60000 [D 0.16, acc. (on x_real and x_fake)  79] [G 0.49, acc. (on x_fake)   8]\n",
            "55511/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)  10]\n",
            "55512/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.46, acc. (on x_fake)  11]\n",
            "55513/60000 [D 0.19, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)   9]\n",
            "55514/60000 [D 0.18, acc. (on x_real and x_fake)  80] [G 0.48, acc. (on x_fake)   7]\n",
            "55515/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  13]\n",
            "55516/60000 [D 0.20, acc. (on x_real and x_fake)  68] [G 0.47, acc. (on x_fake)   9]\n",
            "55517/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.49, acc. (on x_fake)   7]\n",
            "55518/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)  12]\n",
            "55519/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.51, acc. (on x_fake)   9]\n",
            "55520/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)  11]\n",
            "55521/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)  10]\n",
            "55522/60000 [D 0.17, acc. (on x_real and x_fake)  80] [G 0.46, acc. (on x_fake)  10]\n",
            "55523/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.46, acc. (on x_fake)  17]\n",
            "55524/60000 [D 0.20, acc. (on x_real and x_fake)  70] [G 0.45, acc. (on x_fake)  13]\n",
            "55525/60000 [D 0.17, acc. (on x_real and x_fake)  79] [G 0.48, acc. (on x_fake)   7]\n",
            "55526/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)   9]\n",
            "55527/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.51, acc. (on x_fake)   4]\n",
            "55528/60000 [D 0.15, acc. (on x_real and x_fake)  80] [G 0.47, acc. (on x_fake)   7]\n",
            "55529/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.50, acc. (on x_fake)   4]\n",
            "55530/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.46, acc. (on x_fake)  14]\n",
            "55531/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.46, acc. (on x_fake)  15]\n",
            "55532/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  11]\n",
            "55533/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.46, acc. (on x_fake)  12]\n",
            "55534/60000 [D 0.20, acc. (on x_real and x_fake)  70] [G 0.46, acc. (on x_fake)  16]\n",
            "55535/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.45, acc. (on x_fake)  16]\n",
            "55536/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.44, acc. (on x_fake)  16]\n",
            "55537/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.45, acc. (on x_fake)  15]\n",
            "55538/60000 [D 0.16, acc. (on x_real and x_fake)  75] [G 0.46, acc. (on x_fake)  13]\n",
            "55539/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.45, acc. (on x_fake)  17]\n",
            "55540/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)  12]\n",
            "55541/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.49, acc. (on x_fake)  10]\n",
            "55542/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)  10]\n",
            "55543/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)   8]\n",
            "55544/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.47, acc. (on x_fake)  10]\n",
            "55545/60000 [D 0.17, acc. (on x_real and x_fake)  73] [G 0.50, acc. (on x_fake)   5]\n",
            "55546/60000 [D 0.20, acc. (on x_real and x_fake)  67] [G 0.47, acc. (on x_fake)   7]\n",
            "55547/60000 [D 0.18, acc. (on x_real and x_fake)  77] [G 0.50, acc. (on x_fake)   8]\n",
            "55548/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.47, acc. (on x_fake)  15]\n",
            "55549/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.46, acc. (on x_fake)  12]\n",
            "55550/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.45, acc. (on x_fake)  15]\n",
            "55551/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  10]\n",
            "55552/60000 [D 0.16, acc. (on x_real and x_fake)  79] [G 0.48, acc. (on x_fake)   6]\n",
            "55553/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)  10]\n",
            "55554/60000 [D 0.20, acc. (on x_real and x_fake)  72] [G 0.45, acc. (on x_fake)  11]\n",
            "55555/60000 [D 0.22, acc. (on x_real and x_fake)  65] [G 0.45, acc. (on x_fake)  14]\n",
            "55556/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.47, acc. (on x_fake)  11]\n",
            "55557/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.49, acc. (on x_fake)  10]\n",
            "55558/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)  13]\n",
            "55559/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.51, acc. (on x_fake)   9]\n",
            "55560/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.49, acc. (on x_fake)   8]\n",
            "55561/60000 [D 0.19, acc. (on x_real and x_fake)  68] [G 0.47, acc. (on x_fake)  12]\n",
            "55562/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)  16]\n",
            "55563/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)  10]\n",
            "55564/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.45, acc. (on x_fake)  11]\n",
            "55565/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.49, acc. (on x_fake)   7]\n",
            "55566/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)   7]\n",
            "55567/60000 [D 0.20, acc. (on x_real and x_fake)  68] [G 0.50, acc. (on x_fake)  10]\n",
            "55568/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.50, acc. (on x_fake)  13]\n",
            "55569/60000 [D 0.20, acc. (on x_real and x_fake)  66] [G 0.50, acc. (on x_fake)   3]\n",
            "55570/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  11]\n",
            "55571/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)  11]\n",
            "55572/60000 [D 0.20, acc. (on x_real and x_fake)  70] [G 0.48, acc. (on x_fake)  13]\n",
            "55573/60000 [D 0.16, acc. (on x_real and x_fake)  80] [G 0.51, acc. (on x_fake)  11]\n",
            "55574/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)   7]\n",
            "55575/60000 [D 0.19, acc. (on x_real and x_fake)  75] [G 0.45, acc. (on x_fake)  12]\n",
            "55576/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.50, acc. (on x_fake)   7]\n",
            "55577/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.47, acc. (on x_fake)  14]\n",
            "55578/60000 [D 0.18, acc. (on x_real and x_fake)  78] [G 0.48, acc. (on x_fake)  13]\n",
            "55579/60000 [D 0.19, acc. (on x_real and x_fake)  68] [G 0.47, acc. (on x_fake)  17]\n",
            "55580/60000 [D 0.20, acc. (on x_real and x_fake)  66] [G 0.49, acc. (on x_fake)  11]\n",
            "55581/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.44, acc. (on x_fake)  16]\n",
            "55582/60000 [D 0.21, acc. (on x_real and x_fake)  68] [G 0.47, acc. (on x_fake)  12]\n",
            "55583/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)  13]\n",
            "55584/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)   4]\n",
            "55585/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  12]\n",
            "55586/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)  10]\n",
            "55587/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.46, acc. (on x_fake)  11]\n",
            "55588/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.46, acc. (on x_fake)   9]\n",
            "55589/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.44, acc. (on x_fake)   9]\n",
            "55590/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.47, acc. (on x_fake)  10]\n",
            "55591/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  11]\n",
            "55592/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.46, acc. (on x_fake)  14]\n",
            "55593/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.45, acc. (on x_fake)  12]\n",
            "55594/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  14]\n",
            "55595/60000 [D 0.19, acc. (on x_real and x_fake)  67] [G 0.48, acc. (on x_fake)  11]\n",
            "55596/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  13]\n",
            "55597/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   9]\n",
            "55598/60000 [D 0.20, acc. (on x_real and x_fake)  66] [G 0.45, acc. (on x_fake)  19]\n",
            "55599/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)  11]\n",
            "55600/60000 [D 0.16, acc. (on x_real and x_fake)  81] [G 0.50, acc. (on x_fake)   8]\n",
            "55601/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)   9]\n",
            "55602/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.46, acc. (on x_fake)   9]\n",
            "55603/60000 [D 0.20, acc. (on x_real and x_fake)  66] [G 0.47, acc. (on x_fake)   8]\n",
            "55604/60000 [D 0.19, acc. (on x_real and x_fake)  75] [G 0.46, acc. (on x_fake)   9]\n",
            "55605/60000 [D 0.19, acc. (on x_real and x_fake)  68] [G 0.48, acc. (on x_fake)  10]\n",
            "55606/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)   7]\n",
            "55607/60000 [D 0.20, acc. (on x_real and x_fake)  67] [G 0.47, acc. (on x_fake)  10]\n",
            "55608/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.47, acc. (on x_fake)   9]\n",
            "55609/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)  11]\n",
            "55610/60000 [D 0.20, acc. (on x_real and x_fake)  65] [G 0.48, acc. (on x_fake)  10]\n",
            "55611/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.50, acc. (on x_fake)  10]\n",
            "55612/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.48, acc. (on x_fake)   9]\n",
            "55613/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  10]\n",
            "55614/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  14]\n",
            "55615/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.46, acc. (on x_fake)  13]\n",
            "55616/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.45, acc. (on x_fake)  11]\n",
            "55617/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.45, acc. (on x_fake)  10]\n",
            "55618/60000 [D 0.16, acc. (on x_real and x_fake)  77] [G 0.50, acc. (on x_fake)   8]\n",
            "55619/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.49, acc. (on x_fake)  13]\n",
            "55620/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)  13]\n",
            "55621/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)   8]\n",
            "55622/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.50, acc. (on x_fake)   4]\n",
            "55623/60000 [D 0.20, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)  10]\n",
            "55624/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.45, acc. (on x_fake)  14]\n",
            "55625/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.45, acc. (on x_fake)   9]\n",
            "55626/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.45, acc. (on x_fake)  11]\n",
            "55627/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.45, acc. (on x_fake)  12]\n",
            "55628/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)  10]\n",
            "55629/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)   9]\n",
            "55630/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)   9]\n",
            "55631/60000 [D 0.18, acc. (on x_real and x_fake)  78] [G 0.48, acc. (on x_fake)   7]\n",
            "55632/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  12]\n",
            "55633/60000 [D 0.20, acc. (on x_real and x_fake)  72] [G 0.44, acc. (on x_fake)  16]\n",
            "55634/60000 [D 0.18, acc. (on x_real and x_fake)  77] [G 0.45, acc. (on x_fake)  14]\n",
            "55635/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.46, acc. (on x_fake)  13]\n",
            "55636/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)  10]\n",
            "55637/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)  12]\n",
            "55638/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)  14]\n",
            "55639/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.46, acc. (on x_fake)  13]\n",
            "55640/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.48, acc. (on x_fake)  11]\n",
            "55641/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.51, acc. (on x_fake)   8]\n",
            "55642/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  17]\n",
            "55643/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)   9]\n",
            "55644/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)   9]\n",
            "55645/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.48, acc. (on x_fake)   7]\n",
            "55646/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.46, acc. (on x_fake)  10]\n",
            "55647/60000 [D 0.18, acc. (on x_real and x_fake)  70] [G 0.45, acc. (on x_fake)  15]\n",
            "55648/60000 [D 0.17, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)   8]\n",
            "55649/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.45, acc. (on x_fake)  13]\n",
            "55650/60000 [D 0.20, acc. (on x_real and x_fake)  70] [G 0.46, acc. (on x_fake)  10]\n",
            "55651/60000 [D 0.17, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)   7]\n",
            "55652/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.50, acc. (on x_fake)   6]\n",
            "55653/60000 [D 0.20, acc. (on x_real and x_fake)  68] [G 0.47, acc. (on x_fake)   9]\n",
            "55654/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)  13]\n",
            "55655/60000 [D 0.16, acc. (on x_real and x_fake)  78] [G 0.47, acc. (on x_fake)  12]\n",
            "55656/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  13]\n",
            "55657/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  15]\n",
            "55658/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)   9]\n",
            "55659/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)   8]\n",
            "55660/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)   7]\n",
            "55661/60000 [D 0.19, acc. (on x_real and x_fake)  75] [G 0.46, acc. (on x_fake)  12]\n",
            "55662/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)   9]\n",
            "55663/60000 [D 0.17, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)   9]\n",
            "55664/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)  10]\n",
            "55665/60000 [D 0.18, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)   8]\n",
            "55666/60000 [D 0.19, acc. (on x_real and x_fake)  75] [G 0.46, acc. (on x_fake)  12]\n",
            "55667/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)   8]\n",
            "55668/60000 [D 0.21, acc. (on x_real and x_fake)  66] [G 0.47, acc. (on x_fake)  13]\n",
            "55669/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)   9]\n",
            "55670/60000 [D 0.20, acc. (on x_real and x_fake)  66] [G 0.46, acc. (on x_fake)  15]\n",
            "55671/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)   8]\n",
            "55672/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.51, acc. (on x_fake)   5]\n",
            "55673/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)   7]\n",
            "55674/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.47, acc. (on x_fake)  11]\n",
            "55675/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)  11]\n",
            "55676/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.45, acc. (on x_fake)  12]\n",
            "55677/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.45, acc. (on x_fake)  11]\n",
            "55678/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)   9]\n",
            "55679/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   9]\n",
            "55680/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)  12]\n",
            "55681/60000 [D 0.17, acc. (on x_real and x_fake)  79] [G 0.50, acc. (on x_fake)   5]\n",
            "55682/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  10]\n",
            "55683/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)  11]\n",
            "55684/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.51, acc. (on x_fake)   4]\n",
            "55685/60000 [D 0.20, acc. (on x_real and x_fake)  70] [G 0.48, acc. (on x_fake)  11]\n",
            "55686/60000 [D 0.16, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)   9]\n",
            "55687/60000 [D 0.13, acc. (on x_real and x_fake)  85] [G 0.51, acc. (on x_fake)  10]\n",
            "55688/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)   9]\n",
            "55689/60000 [D 0.15, acc. (on x_real and x_fake)  81] [G 0.49, acc. (on x_fake)   9]\n",
            "55690/60000 [D 0.21, acc. (on x_real and x_fake)  65] [G 0.44, acc. (on x_fake)  20]\n",
            "55691/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  14]\n",
            "55692/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)  11]\n",
            "55693/60000 [D 0.20, acc. (on x_real and x_fake)  70] [G 0.48, acc. (on x_fake)  11]\n",
            "55694/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.50, acc. (on x_fake)   9]\n",
            "55695/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.52, acc. (on x_fake)   7]\n",
            "55696/60000 [D 0.18, acc. (on x_real and x_fake)  69] [G 0.50, acc. (on x_fake)  10]\n",
            "55697/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)  14]\n",
            "55698/60000 [D 0.20, acc. (on x_real and x_fake)  70] [G 0.45, acc. (on x_fake)  16]\n",
            "55699/60000 [D 0.18, acc. (on x_real and x_fake)  78] [G 0.47, acc. (on x_fake)   8]\n",
            "55700/60000 [D 0.20, acc. (on x_real and x_fake)  68] [G 0.45, acc. (on x_fake)  17]\n",
            "55701/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.46, acc. (on x_fake)  17]\n",
            "55702/60000 [D 0.17, acc. (on x_real and x_fake)  79] [G 0.50, acc. (on x_fake)   6]\n",
            "55703/60000 [D 0.20, acc. (on x_real and x_fake)  68] [G 0.44, acc. (on x_fake)  13]\n",
            "55704/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)  10]\n",
            "55705/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.49, acc. (on x_fake)   8]\n",
            "55706/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.50, acc. (on x_fake)  13]\n",
            "55707/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.45, acc. (on x_fake)  14]\n",
            "55708/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.46, acc. (on x_fake)  12]\n",
            "55709/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.44, acc. (on x_fake)  15]\n",
            "55710/60000 [D 0.18, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)  10]\n",
            "55711/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  13]\n",
            "55712/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)   9]\n",
            "55713/60000 [D 0.17, acc. (on x_real and x_fake)  73] [G 0.50, acc. (on x_fake)   6]\n",
            "55714/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)  10]\n",
            "55715/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.46, acc. (on x_fake)  10]\n",
            "55716/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)  14]\n",
            "55717/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)  13]\n",
            "55718/60000 [D 0.20, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)  11]\n",
            "55719/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.45, acc. (on x_fake)  11]\n",
            "55720/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.45, acc. (on x_fake)  14]\n",
            "55721/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)  10]\n",
            "55722/60000 [D 0.18, acc. (on x_real and x_fake)  69] [G 0.50, acc. (on x_fake)   7]\n",
            "55723/60000 [D 0.20, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)   8]\n",
            "55724/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.45, acc. (on x_fake)  15]\n",
            "55725/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)   9]\n",
            "55726/60000 [D 0.16, acc. (on x_real and x_fake)  81] [G 0.48, acc. (on x_fake)   9]\n",
            "55727/60000 [D 0.19, acc. (on x_real and x_fake)  66] [G 0.46, acc. (on x_fake)  17]\n",
            "55728/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  10]\n",
            "55729/60000 [D 0.18, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)  10]\n",
            "55730/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)  11]\n",
            "55731/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.48, acc. (on x_fake)   8]\n",
            "55732/60000 [D 0.17, acc. (on x_real and x_fake)  79] [G 0.49, acc. (on x_fake)  10]\n",
            "55733/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  14]\n",
            "55734/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.46, acc. (on x_fake)   9]\n",
            "55735/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)  11]\n",
            "55736/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.49, acc. (on x_fake)   6]\n",
            "55737/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)  10]\n",
            "55738/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)  11]\n",
            "55739/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.46, acc. (on x_fake)   9]\n",
            "55740/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)   7]\n",
            "55741/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)   7]\n",
            "55742/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)  12]\n",
            "55743/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)  11]\n",
            "55744/60000 [D 0.18, acc. (on x_real and x_fake)  78] [G 0.47, acc. (on x_fake)   8]\n",
            "55745/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)   7]\n",
            "55746/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.44, acc. (on x_fake)  14]\n",
            "55747/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.49, acc. (on x_fake)  10]\n",
            "55748/60000 [D 0.15, acc. (on x_real and x_fake)  78] [G 0.55, acc. (on x_fake)   3]\n",
            "55749/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)  10]\n",
            "55750/60000 [D 0.20, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)  19]\n",
            "55751/60000 [D 0.21, acc. (on x_real and x_fake)  66] [G 0.46, acc. (on x_fake)  13]\n",
            "55752/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)   4]\n",
            "55753/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.51, acc. (on x_fake)   9]\n",
            "55754/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.46, acc. (on x_fake)  10]\n",
            "55755/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)  10]\n",
            "55756/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.46, acc. (on x_fake)  17]\n",
            "55757/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.43, acc. (on x_fake)  20]\n",
            "55758/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)   8]\n",
            "55759/60000 [D 0.20, acc. (on x_real and x_fake)  71] [G 0.46, acc. (on x_fake)  16]\n",
            "55760/60000 [D 0.19, acc. (on x_real and x_fake)  68] [G 0.43, acc. (on x_fake)  19]\n",
            "55761/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)  13]\n",
            "55762/60000 [D 0.16, acc. (on x_real and x_fake)  79] [G 0.46, acc. (on x_fake)  13]\n",
            "55763/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   8]\n",
            "55764/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.47, acc. (on x_fake)  13]\n",
            "55765/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.45, acc. (on x_fake)   9]\n",
            "55766/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.47, acc. (on x_fake)  10]\n",
            "55767/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.50, acc. (on x_fake)   6]\n",
            "55768/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  10]\n",
            "55769/60000 [D 0.20, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)  14]\n",
            "55770/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.46, acc. (on x_fake)  13]\n",
            "55771/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.46, acc. (on x_fake)  10]\n",
            "55772/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  10]\n",
            "55773/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)   9]\n",
            "55774/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.43, acc. (on x_fake)  15]\n",
            "55775/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.45, acc. (on x_fake)  12]\n",
            "55776/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.48, acc. (on x_fake)  10]\n",
            "55777/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.45, acc. (on x_fake)  20]\n",
            "55778/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)  10]\n",
            "55779/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)  11]\n",
            "55780/60000 [D 0.21, acc. (on x_real and x_fake)  64] [G 0.44, acc. (on x_fake)  14]\n",
            "55781/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  10]\n",
            "55782/60000 [D 0.16, acc. (on x_real and x_fake)  82] [G 0.46, acc. (on x_fake)   8]\n",
            "55783/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)  10]\n",
            "55784/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)   8]\n",
            "55785/60000 [D 0.17, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)  11]\n",
            "55786/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)   5]\n",
            "55787/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  11]\n",
            "55788/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.47, acc. (on x_fake)  14]\n",
            "55789/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)   8]\n",
            "55790/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  10]\n",
            "55791/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.49, acc. (on x_fake)   8]\n",
            "55792/60000 [D 0.16, acc. (on x_real and x_fake)  81] [G 0.44, acc. (on x_fake)  14]\n",
            "55793/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)   9]\n",
            "55794/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.50, acc. (on x_fake)   7]\n",
            "55795/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)  11]\n",
            "55796/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.50, acc. (on x_fake)  10]\n",
            "55797/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)   6]\n",
            "55798/60000 [D 0.20, acc. (on x_real and x_fake)  70] [G 0.45, acc. (on x_fake)  19]\n",
            "55799/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.49, acc. (on x_fake)   9]\n",
            "55800/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  11]\n",
            "55801/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.45, acc. (on x_fake)  13]\n",
            "55802/60000 [D 0.20, acc. (on x_real and x_fake)  70] [G 0.45, acc. (on x_fake)  16]\n",
            "55803/60000 [D 0.20, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)  10]\n",
            "55804/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  11]\n",
            "55805/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  19]\n",
            "55806/60000 [D 0.17, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)  12]\n",
            "55807/60000 [D 0.19, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)   7]\n",
            "55808/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.50, acc. (on x_fake)   6]\n",
            "55809/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.45, acc. (on x_fake)  16]\n",
            "55810/60000 [D 0.20, acc. (on x_real and x_fake)  70] [G 0.46, acc. (on x_fake)  13]\n",
            "55811/60000 [D 0.20, acc. (on x_real and x_fake)  68] [G 0.47, acc. (on x_fake)   8]\n",
            "55812/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)   6]\n",
            "55813/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  11]\n",
            "55814/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)   7]\n",
            "55815/60000 [D 0.20, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)   7]\n",
            "55816/60000 [D 0.18, acc. (on x_real and x_fake)  78] [G 0.48, acc. (on x_fake)   9]\n",
            "55817/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)  10]\n",
            "55818/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  11]\n",
            "55819/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)  15]\n",
            "55820/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)  12]\n",
            "55821/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.47, acc. (on x_fake)   8]\n",
            "55822/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)   9]\n",
            "55823/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)   8]\n",
            "55824/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)   7]\n",
            "55825/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.50, acc. (on x_fake)   9]\n",
            "55826/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)   8]\n",
            "55827/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.51, acc. (on x_fake)   7]\n",
            "55828/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.46, acc. (on x_fake)  12]\n",
            "55829/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)  15]\n",
            "55830/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.46, acc. (on x_fake)  12]\n",
            "55831/60000 [D 0.16, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  12]\n",
            "55832/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.45, acc. (on x_fake)  15]\n",
            "55833/60000 [D 0.21, acc. (on x_real and x_fake)  68] [G 0.42, acc. (on x_fake)  18]\n",
            "55834/60000 [D 0.16, acc. (on x_real and x_fake)  76] [G 0.49, acc. (on x_fake)   9]\n",
            "55835/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  15]\n",
            "55836/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.49, acc. (on x_fake)  15]\n",
            "55837/60000 [D 0.20, acc. (on x_real and x_fake)  68] [G 0.45, acc. (on x_fake)  17]\n",
            "55838/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)  10]\n",
            "55839/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)  12]\n",
            "55840/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.50, acc. (on x_fake)  12]\n",
            "55841/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)  12]\n",
            "55842/60000 [D 0.19, acc. (on x_real and x_fake)  76] [G 0.48, acc. (on x_fake)   8]\n",
            "55843/60000 [D 0.17, acc. (on x_real and x_fake)  79] [G 0.48, acc. (on x_fake)  11]\n",
            "55844/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  13]\n",
            "55845/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)  14]\n",
            "55846/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.50, acc. (on x_fake)  13]\n",
            "55847/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)  14]\n",
            "55848/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  16]\n",
            "55849/60000 [D 0.16, acc. (on x_real and x_fake)  77] [G 0.48, acc. (on x_fake)  10]\n",
            "55850/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)  13]\n",
            "55851/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  12]\n",
            "55852/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)   9]\n",
            "55853/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.50, acc. (on x_fake)   7]\n",
            "55854/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.45, acc. (on x_fake)  18]\n",
            "55855/60000 [D 0.20, acc. (on x_real and x_fake)  66] [G 0.46, acc. (on x_fake)  19]\n",
            "55856/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  13]\n",
            "55857/60000 [D 0.16, acc. (on x_real and x_fake)  80] [G 0.49, acc. (on x_fake)   9]\n",
            "55858/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.50, acc. (on x_fake)  13]\n",
            "55859/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  15]\n",
            "55860/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)   6]\n",
            "55861/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.50, acc. (on x_fake)  11]\n",
            "55862/60000 [D 0.16, acc. (on x_real and x_fake)  76] [G 0.51, acc. (on x_fake)   6]\n",
            "55863/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)  12]\n",
            "55864/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)  10]\n",
            "55865/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.49, acc. (on x_fake)  11]\n",
            "55866/60000 [D 0.17, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)  10]\n",
            "55867/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)  15]\n",
            "55868/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.45, acc. (on x_fake)  11]\n",
            "55869/60000 [D 0.16, acc. (on x_real and x_fake)  80] [G 0.49, acc. (on x_fake)  13]\n",
            "55870/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)  12]\n",
            "55871/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)  13]\n",
            "55872/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  10]\n",
            "55873/60000 [D 0.20, acc. (on x_real and x_fake)  65] [G 0.48, acc. (on x_fake)  13]\n",
            "55874/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.50, acc. (on x_fake)  11]\n",
            "55875/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.50, acc. (on x_fake)   6]\n",
            "55876/60000 [D 0.20, acc. (on x_real and x_fake)  67] [G 0.45, acc. (on x_fake)  14]\n",
            "55877/60000 [D 0.18, acc. (on x_real and x_fake)  77] [G 0.49, acc. (on x_fake)  10]\n",
            "55878/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  12]\n",
            "55879/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.50, acc. (on x_fake)   8]\n",
            "55880/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)  10]\n",
            "55881/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)  12]\n",
            "55882/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.46, acc. (on x_fake)   6]\n",
            "55883/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.47, acc. (on x_fake)   9]\n",
            "55884/60000 [D 0.17, acc. (on x_real and x_fake)  80] [G 0.47, acc. (on x_fake)   8]\n",
            "55885/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.44, acc. (on x_fake)  15]\n",
            "55886/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.45, acc. (on x_fake)  16]\n",
            "55887/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.48, acc. (on x_fake)   7]\n",
            "55888/60000 [D 0.20, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)   4]\n",
            "55889/60000 [D 0.18, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)   8]\n",
            "55890/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.44, acc. (on x_fake)   9]\n",
            "55891/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)  10]\n",
            "55892/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.45, acc. (on x_fake)   8]\n",
            "55893/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.46, acc. (on x_fake)  11]\n",
            "55894/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.45, acc. (on x_fake)  14]\n",
            "55895/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)   9]\n",
            "55896/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)  14]\n",
            "55897/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   6]\n",
            "55898/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.50, acc. (on x_fake)   5]\n",
            "55899/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)   6]\n",
            "55900/60000 [D 0.18, acc. (on x_real and x_fake)  78] [G 0.46, acc. (on x_fake)   7]\n",
            "55901/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)   8]\n",
            "55902/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  10]\n",
            "55903/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)  11]\n",
            "55904/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)  13]\n",
            "55905/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.46, acc. (on x_fake)  10]\n",
            "55906/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.46, acc. (on x_fake)  11]\n",
            "55907/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.49, acc. (on x_fake)  15]\n",
            "55908/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  16]\n",
            "55909/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)   8]\n",
            "55910/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)   7]\n",
            "55911/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  12]\n",
            "55912/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.46, acc. (on x_fake)  11]\n",
            "55913/60000 [D 0.17, acc. (on x_real and x_fake)  81] [G 0.47, acc. (on x_fake)  10]\n",
            "55914/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.49, acc. (on x_fake)  13]\n",
            "55915/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  11]\n",
            "55916/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.46, acc. (on x_fake)  13]\n",
            "55917/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.45, acc. (on x_fake)  16]\n",
            "55918/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.46, acc. (on x_fake)  13]\n",
            "55919/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.46, acc. (on x_fake)   7]\n",
            "55920/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.50, acc. (on x_fake)   8]\n",
            "55921/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)  10]\n",
            "55922/60000 [D 0.20, acc. (on x_real and x_fake)  72] [G 0.45, acc. (on x_fake)  13]\n",
            "55923/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  10]\n",
            "55924/60000 [D 0.20, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)  10]\n",
            "55925/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)   6]\n",
            "55926/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)  12]\n",
            "55927/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.49, acc. (on x_fake)  13]\n",
            "55928/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)   6]\n",
            "55929/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.50, acc. (on x_fake)  10]\n",
            "55930/60000 [D 0.21, acc. (on x_real and x_fake)  64] [G 0.48, acc. (on x_fake)   9]\n",
            "55931/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)   8]\n",
            "55932/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  13]\n",
            "55933/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)   9]\n",
            "55934/60000 [D 0.21, acc. (on x_real and x_fake)  64] [G 0.45, acc. (on x_fake)  17]\n",
            "55935/60000 [D 0.20, acc. (on x_real and x_fake)  68] [G 0.45, acc. (on x_fake)  22]\n",
            "55936/60000 [D 0.19, acc. (on x_real and x_fake)  67] [G 0.45, acc. (on x_fake)  14]\n",
            "55937/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.45, acc. (on x_fake)  15]\n",
            "55938/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)   8]\n",
            "55939/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.47, acc. (on x_fake)  10]\n",
            "55940/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)   8]\n",
            "55941/60000 [D 0.21, acc. (on x_real and x_fake)  66] [G 0.47, acc. (on x_fake)  13]\n",
            "55942/60000 [D 0.20, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)  14]\n",
            "55943/60000 [D 0.18, acc. (on x_real and x_fake)  77] [G 0.48, acc. (on x_fake)   9]\n",
            "55944/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)   6]\n",
            "55945/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)   7]\n",
            "55946/60000 [D 0.18, acc. (on x_real and x_fake)  70] [G 0.48, acc. (on x_fake)  11]\n",
            "55947/60000 [D 0.17, acc. (on x_real and x_fake)  80] [G 0.50, acc. (on x_fake)   8]\n",
            "55948/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.45, acc. (on x_fake)  16]\n",
            "55949/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)  11]\n",
            "55950/60000 [D 0.18, acc. (on x_real and x_fake)  69] [G 0.46, acc. (on x_fake)  19]\n",
            "55951/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.44, acc. (on x_fake)  14]\n",
            "55952/60000 [D 0.19, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   9]\n",
            "55953/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)   7]\n",
            "55954/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  11]\n",
            "55955/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  12]\n",
            "55956/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)   9]\n",
            "55957/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)  13]\n",
            "55958/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.50, acc. (on x_fake)   8]\n",
            "55959/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.46, acc. (on x_fake)   9]\n",
            "55960/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)  13]\n",
            "55961/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.51, acc. (on x_fake)   4]\n",
            "55962/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)  11]\n",
            "55963/60000 [D 0.18, acc. (on x_real and x_fake)  77] [G 0.49, acc. (on x_fake)  10]\n",
            "55964/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.46, acc. (on x_fake)  13]\n",
            "55965/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)  10]\n",
            "55966/60000 [D 0.20, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)   9]\n",
            "55967/60000 [D 0.19, acc. (on x_real and x_fake)  68] [G 0.48, acc. (on x_fake)  14]\n",
            "55968/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.43, acc. (on x_fake)  17]\n",
            "55969/60000 [D 0.20, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)   9]\n",
            "55970/60000 [D 0.20, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)  13]\n",
            "55971/60000 [D 0.20, acc. (on x_real and x_fake)  66] [G 0.50, acc. (on x_fake)  10]\n",
            "55972/60000 [D 0.21, acc. (on x_real and x_fake)  69] [G 0.44, acc. (on x_fake)  14]\n",
            "55973/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.46, acc. (on x_fake)  14]\n",
            "55974/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.51, acc. (on x_fake)   9]\n",
            "55975/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.45, acc. (on x_fake)  13]\n",
            "55976/60000 [D 0.18, acc. (on x_real and x_fake)  77] [G 0.50, acc. (on x_fake)  11]\n",
            "55977/60000 [D 0.17, acc. (on x_real and x_fake)  80] [G 0.49, acc. (on x_fake)   7]\n",
            "55978/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.51, acc. (on x_fake)  10]\n",
            "55979/60000 [D 0.16, acc. (on x_real and x_fake)  79] [G 0.47, acc. (on x_fake)  10]\n",
            "55980/60000 [D 0.17, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)   6]\n",
            "55981/60000 [D 0.16, acc. (on x_real and x_fake)  77] [G 0.47, acc. (on x_fake)   8]\n",
            "55982/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.48, acc. (on x_fake)  11]\n",
            "55983/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)  14]\n",
            "55984/60000 [D 0.22, acc. (on x_real and x_fake)  61] [G 0.42, acc. (on x_fake)  15]\n",
            "55985/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.47, acc. (on x_fake)  16]\n",
            "55986/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.50, acc. (on x_fake)   7]\n",
            "55987/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.44, acc. (on x_fake)  11]\n",
            "55988/60000 [D 0.20, acc. (on x_real and x_fake)  66] [G 0.45, acc. (on x_fake)  10]\n",
            "55989/60000 [D 0.20, acc. (on x_real and x_fake)  67] [G 0.43, acc. (on x_fake)  15]\n",
            "55990/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.49, acc. (on x_fake)   9]\n",
            "55991/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.46, acc. (on x_fake)  15]\n",
            "55992/60000 [D 0.18, acc. (on x_real and x_fake)  77] [G 0.50, acc. (on x_fake)   7]\n",
            "55993/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   8]\n",
            "55994/60000 [D 0.20, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)  11]\n",
            "55995/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)   7]\n",
            "55996/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.51, acc. (on x_fake)   8]\n",
            "55997/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  11]\n",
            "55998/60000 [D 0.19, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)  11]\n",
            "55999/60000 [D 0.21, acc. (on x_real and x_fake)  68] [G 0.48, acc. (on x_fake)  11]\n",
            "56000/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.49, acc. (on x_fake)   8]\n",
            "56001/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  12]\n",
            "56002/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)  15]\n",
            "56003/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)   9]\n",
            "56004/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.45, acc. (on x_fake)  10]\n",
            "56005/60000 [D 0.15, acc. (on x_real and x_fake)  83] [G 0.54, acc. (on x_fake)   1]\n",
            "56006/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.50, acc. (on x_fake)   7]\n",
            "56007/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)   8]\n",
            "56008/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.48, acc. (on x_fake)   8]\n",
            "56009/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.45, acc. (on x_fake)  11]\n",
            "56010/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)   9]\n",
            "56011/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.46, acc. (on x_fake)  10]\n",
            "56012/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)  11]\n",
            "56013/60000 [D 0.17, acc. (on x_real and x_fake)  81] [G 0.48, acc. (on x_fake)  14]\n",
            "56014/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)  11]\n",
            "56015/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.48, acc. (on x_fake)  12]\n",
            "56016/60000 [D 0.21, acc. (on x_real and x_fake)  70] [G 0.46, acc. (on x_fake)   7]\n",
            "56017/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)   7]\n",
            "56018/60000 [D 0.18, acc. (on x_real and x_fake)  70] [G 0.45, acc. (on x_fake)  13]\n",
            "56019/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  10]\n",
            "56020/60000 [D 0.15, acc. (on x_real and x_fake)  83] [G 0.48, acc. (on x_fake)  11]\n",
            "56021/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.47, acc. (on x_fake)  12]\n",
            "56022/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)  14]\n",
            "56023/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)   7]\n",
            "56024/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)  10]\n",
            "56025/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  13]\n",
            "56026/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.45, acc. (on x_fake)  14]\n",
            "56027/60000 [D 0.20, acc. (on x_real and x_fake)  68] [G 0.46, acc. (on x_fake)   9]\n",
            "56028/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)   8]\n",
            "56029/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)  13]\n",
            "56030/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.48, acc. (on x_fake)   6]\n",
            "56031/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  13]\n",
            "56032/60000 [D 0.17, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)  12]\n",
            "56033/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)  14]\n",
            "56034/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   6]\n",
            "56035/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.45, acc. (on x_fake)  10]\n",
            "56036/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)   7]\n",
            "56037/60000 [D 0.17, acc. (on x_real and x_fake)  73] [G 0.51, acc. (on x_fake)   7]\n",
            "56038/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)  12]\n",
            "56039/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.46, acc. (on x_fake)   8]\n",
            "56040/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.50, acc. (on x_fake)  11]\n",
            "56041/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.45, acc. (on x_fake)  12]\n",
            "56042/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   7]\n",
            "56043/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)   9]\n",
            "56044/60000 [D 0.20, acc. (on x_real and x_fake)  71] [G 0.46, acc. (on x_fake)  17]\n",
            "56045/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)   5]\n",
            "56046/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)   7]\n",
            "56047/60000 [D 0.16, acc. (on x_real and x_fake)  78] [G 0.48, acc. (on x_fake)   6]\n",
            "56048/60000 [D 0.19, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)   9]\n",
            "56049/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  14]\n",
            "56050/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)   6]\n",
            "56051/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.49, acc. (on x_fake)   7]\n",
            "56052/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)  11]\n",
            "56053/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  10]\n",
            "56054/60000 [D 0.20, acc. (on x_real and x_fake)  74] [G 0.45, acc. (on x_fake)  13]\n",
            "56055/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)  12]\n",
            "56056/60000 [D 0.21, acc. (on x_real and x_fake)  67] [G 0.42, acc. (on x_fake)  16]\n",
            "56057/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.48, acc. (on x_fake)   9]\n",
            "56058/60000 [D 0.21, acc. (on x_real and x_fake)  68] [G 0.44, acc. (on x_fake)  15]\n",
            "56059/60000 [D 0.18, acc. (on x_real and x_fake)  77] [G 0.46, acc. (on x_fake)  14]\n",
            "56060/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.45, acc. (on x_fake)  13]\n",
            "56061/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.46, acc. (on x_fake)  11]\n",
            "56062/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   9]\n",
            "56063/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.51, acc. (on x_fake)   4]\n",
            "56064/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  11]\n",
            "56065/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)  10]\n",
            "56066/60000 [D 0.20, acc. (on x_real and x_fake)  68] [G 0.45, acc. (on x_fake)  14]\n",
            "56067/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)  12]\n",
            "56068/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.46, acc. (on x_fake)  12]\n",
            "56069/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  10]\n",
            "56070/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  10]\n",
            "56071/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.49, acc. (on x_fake)  11]\n",
            "56072/60000 [D 0.20, acc. (on x_real and x_fake)  71] [G 0.44, acc. (on x_fake)  16]\n",
            "56073/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.45, acc. (on x_fake)  11]\n",
            "56074/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)   4]\n",
            "56075/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.46, acc. (on x_fake)  11]\n",
            "56076/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.46, acc. (on x_fake)  15]\n",
            "56077/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)  11]\n",
            "56078/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)  12]\n",
            "56079/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.45, acc. (on x_fake)  17]\n",
            "56080/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.46, acc. (on x_fake)  10]\n",
            "56081/60000 [D 0.20, acc. (on x_real and x_fake)  68] [G 0.45, acc. (on x_fake)  13]\n",
            "56082/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  12]\n",
            "56083/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)   9]\n",
            "56084/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  13]\n",
            "56085/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.45, acc. (on x_fake)  13]\n",
            "56086/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.48, acc. (on x_fake)  11]\n",
            "56087/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  13]\n",
            "56088/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)   7]\n",
            "56089/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)  13]\n",
            "56090/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.45, acc. (on x_fake)  13]\n",
            "56091/60000 [D 0.20, acc. (on x_real and x_fake)  67] [G 0.48, acc. (on x_fake)  12]\n",
            "56092/60000 [D 0.19, acc. (on x_real and x_fake)  68] [G 0.46, acc. (on x_fake)   9]\n",
            "56093/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.47, acc. (on x_fake)  14]\n",
            "56094/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.47, acc. (on x_fake)  16]\n",
            "56095/60000 [D 0.18, acc. (on x_real and x_fake)  78] [G 0.47, acc. (on x_fake)   8]\n",
            "56096/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.46, acc. (on x_fake)  17]\n",
            "56097/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  13]\n",
            "56098/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.47, acc. (on x_fake)  11]\n",
            "56099/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)   7]\n",
            "56100/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.50, acc. (on x_fake)   8]\n",
            "56101/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.46, acc. (on x_fake)  13]\n",
            "56102/60000 [D 0.20, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)  16]\n",
            "56103/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)   8]\n",
            "56104/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)  12]\n",
            "56105/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)   9]\n",
            "56106/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.47, acc. (on x_fake)  12]\n",
            "56107/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.49, acc. (on x_fake)   9]\n",
            "56108/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)   9]\n",
            "56109/60000 [D 0.15, acc. (on x_real and x_fake)  79] [G 0.50, acc. (on x_fake)   7]\n",
            "56110/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  10]\n",
            "56111/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  10]\n",
            "56112/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)  15]\n",
            "56113/60000 [D 0.16, acc. (on x_real and x_fake)  78] [G 0.49, acc. (on x_fake)   6]\n",
            "56114/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.49, acc. (on x_fake)   9]\n",
            "56115/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.49, acc. (on x_fake)  10]\n",
            "56116/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)  11]\n",
            "56117/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.45, acc. (on x_fake)  14]\n",
            "56118/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.48, acc. (on x_fake)   9]\n",
            "56119/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.46, acc. (on x_fake)  11]\n",
            "56120/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)   8]\n",
            "56121/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.46, acc. (on x_fake)   7]\n",
            "56122/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)  14]\n",
            "56123/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.45, acc. (on x_fake)   9]\n",
            "56124/60000 [D 0.16, acc. (on x_real and x_fake)  81] [G 0.48, acc. (on x_fake)  11]\n",
            "56125/60000 [D 0.20, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  16]\n",
            "56126/60000 [D 0.19, acc. (on x_real and x_fake)  68] [G 0.45, acc. (on x_fake)  14]\n",
            "56127/60000 [D 0.16, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)   5]\n",
            "56128/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.44, acc. (on x_fake)  17]\n",
            "56129/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.45, acc. (on x_fake)  14]\n",
            "56130/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)   8]\n",
            "56131/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)  14]\n",
            "56132/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.47, acc. (on x_fake)  11]\n",
            "56133/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.49, acc. (on x_fake)  14]\n",
            "56134/60000 [D 0.20, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)  14]\n",
            "56135/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.46, acc. (on x_fake)  16]\n",
            "56136/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.51, acc. (on x_fake)  10]\n",
            "56137/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)   9]\n",
            "56138/60000 [D 0.17, acc. (on x_real and x_fake)  80] [G 0.49, acc. (on x_fake)   9]\n",
            "56139/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.50, acc. (on x_fake)   8]\n",
            "56140/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)  10]\n",
            "56141/60000 [D 0.19, acc. (on x_real and x_fake)  67] [G 0.48, acc. (on x_fake)  11]\n",
            "56142/60000 [D 0.21, acc. (on x_real and x_fake)  63] [G 0.45, acc. (on x_fake)  12]\n",
            "56143/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.50, acc. (on x_fake)   8]\n",
            "56144/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.46, acc. (on x_fake)  10]\n",
            "56145/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)   9]\n",
            "56146/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.45, acc. (on x_fake)  10]\n",
            "56147/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)  15]\n",
            "56148/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)   9]\n",
            "56149/60000 [D 0.18, acc. (on x_real and x_fake)  78] [G 0.46, acc. (on x_fake)  15]\n",
            "56150/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  15]\n",
            "56151/60000 [D 0.19, acc. (on x_real and x_fake)  68] [G 0.44, acc. (on x_fake)   7]\n",
            "56152/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.50, acc. (on x_fake)   6]\n",
            "56153/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.50, acc. (on x_fake)  11]\n",
            "56154/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)   9]\n",
            "56155/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  12]\n",
            "56156/60000 [D 0.17, acc. (on x_real and x_fake)  79] [G 0.47, acc. (on x_fake)  10]\n",
            "56157/60000 [D 0.16, acc. (on x_real and x_fake)  76] [G 0.49, acc. (on x_fake)  11]\n",
            "56158/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.49, acc. (on x_fake)  10]\n",
            "56159/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)   9]\n",
            "56160/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)  13]\n",
            "56161/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)  13]\n",
            "56162/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.50, acc. (on x_fake)   9]\n",
            "56163/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)  12]\n",
            "56164/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)   6]\n",
            "56165/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)  10]\n",
            "56166/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)  10]\n",
            "56167/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.46, acc. (on x_fake)  16]\n",
            "56168/60000 [D 0.16, acc. (on x_real and x_fake)  79] [G 0.51, acc. (on x_fake)   8]\n",
            "56169/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  12]\n",
            "56170/60000 [D 0.19, acc. (on x_real and x_fake)  67] [G 0.47, acc. (on x_fake)  12]\n",
            "56171/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)  13]\n",
            "56172/60000 [D 0.16, acc. (on x_real and x_fake)  79] [G 0.51, acc. (on x_fake)  11]\n",
            "56173/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.50, acc. (on x_fake)  12]\n",
            "56174/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.49, acc. (on x_fake)  14]\n",
            "56175/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.48, acc. (on x_fake)  11]\n",
            "56176/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.48, acc. (on x_fake)  11]\n",
            "56177/60000 [D 0.20, acc. (on x_real and x_fake)  66] [G 0.48, acc. (on x_fake)  13]\n",
            "56178/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)  12]\n",
            "56179/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)  11]\n",
            "56180/60000 [D 0.20, acc. (on x_real and x_fake)  71] [G 0.47, acc. (on x_fake)  14]\n",
            "56181/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)   6]\n",
            "56182/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)   6]\n",
            "56183/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.50, acc. (on x_fake)  10]\n",
            "56184/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.46, acc. (on x_fake)  15]\n",
            "56185/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)   7]\n",
            "56186/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)   9]\n",
            "56187/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.48, acc. (on x_fake)  13]\n",
            "56188/60000 [D 0.20, acc. (on x_real and x_fake)  68] [G 0.46, acc. (on x_fake)  10]\n",
            "56189/60000 [D 0.20, acc. (on x_real and x_fake)  68] [G 0.50, acc. (on x_fake)  10]\n",
            "56190/60000 [D 0.21, acc. (on x_real and x_fake)  66] [G 0.46, acc. (on x_fake)  10]\n",
            "56191/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)  13]\n",
            "56192/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.45, acc. (on x_fake)  11]\n",
            "56193/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)   9]\n",
            "56194/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.46, acc. (on x_fake)  10]\n",
            "56195/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.46, acc. (on x_fake)   9]\n",
            "56196/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.45, acc. (on x_fake)   9]\n",
            "56197/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)  13]\n",
            "56198/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.46, acc. (on x_fake)  15]\n",
            "56199/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)   6]\n",
            "56200/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.44, acc. (on x_fake)  15]\n",
            "56201/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   7]\n",
            "56202/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  11]\n",
            "56203/60000 [D 0.16, acc. (on x_real and x_fake)  77] [G 0.49, acc. (on x_fake)  10]\n",
            "56204/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)   8]\n",
            "56205/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.51, acc. (on x_fake)   4]\n",
            "56206/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   7]\n",
            "56207/60000 [D 0.19, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  10]\n",
            "56208/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.47, acc. (on x_fake)  13]\n",
            "56209/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)  17]\n",
            "56210/60000 [D 0.18, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)  11]\n",
            "56211/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.49, acc. (on x_fake)   8]\n",
            "56212/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.49, acc. (on x_fake)  12]\n",
            "56213/60000 [D 0.18, acc. (on x_real and x_fake)  69] [G 0.49, acc. (on x_fake)   8]\n",
            "56214/60000 [D 0.19, acc. (on x_real and x_fake)  76] [G 0.45, acc. (on x_fake)  14]\n",
            "56215/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)   7]\n",
            "56216/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)  11]\n",
            "56217/60000 [D 0.18, acc. (on x_real and x_fake)  78] [G 0.46, acc. (on x_fake)  11]\n",
            "56218/60000 [D 0.20, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)  10]\n",
            "56219/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.45, acc. (on x_fake)  12]\n",
            "56220/60000 [D 0.20, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  11]\n",
            "56221/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  13]\n",
            "56222/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)  14]\n",
            "56223/60000 [D 0.19, acc. (on x_real and x_fake)  65] [G 0.46, acc. (on x_fake)  11]\n",
            "56224/60000 [D 0.19, acc. (on x_real and x_fake)  68] [G 0.48, acc. (on x_fake)  12]\n",
            "56225/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)  11]\n",
            "56226/60000 [D 0.18, acc. (on x_real and x_fake)  77] [G 0.49, acc. (on x_fake)   9]\n",
            "56227/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.46, acc. (on x_fake)  12]\n",
            "56228/60000 [D 0.20, acc. (on x_real and x_fake)  68] [G 0.47, acc. (on x_fake)   8]\n",
            "56229/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)   5]\n",
            "56230/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.45, acc. (on x_fake)  21]\n",
            "56231/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.45, acc. (on x_fake)  15]\n",
            "56232/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  11]\n",
            "56233/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)   9]\n",
            "56234/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)   7]\n",
            "56235/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.49, acc. (on x_fake)  10]\n",
            "56236/60000 [D 0.19, acc. (on x_real and x_fake)  68] [G 0.48, acc. (on x_fake)   9]\n",
            "56237/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)   7]\n",
            "56238/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)  10]\n",
            "56239/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   6]\n",
            "56240/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.46, acc. (on x_fake)   9]\n",
            "56241/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.48, acc. (on x_fake)  11]\n",
            "56242/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.48, acc. (on x_fake)   9]\n",
            "56243/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.46, acc. (on x_fake)  16]\n",
            "56244/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  12]\n",
            "56245/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)   9]\n",
            "56246/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.46, acc. (on x_fake)  12]\n",
            "56247/60000 [D 0.20, acc. (on x_real and x_fake)  70] [G 0.45, acc. (on x_fake)  14]\n",
            "56248/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)   9]\n",
            "56249/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)  12]\n",
            "56250/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  13]\n",
            "56251/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.50, acc. (on x_fake)   7]\n",
            "56252/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.45, acc. (on x_fake)   8]\n",
            "56253/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  18]\n",
            "56254/60000 [D 0.19, acc. (on x_real and x_fake)  67] [G 0.46, acc. (on x_fake)  16]\n",
            "56255/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  10]\n",
            "56256/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.50, acc. (on x_fake)   7]\n",
            "56257/60000 [D 0.20, acc. (on x_real and x_fake)  71] [G 0.46, acc. (on x_fake)  11]\n",
            "56258/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)  11]\n",
            "56259/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)  14]\n",
            "56260/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.48, acc. (on x_fake)   8]\n",
            "56261/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.47, acc. (on x_fake)  12]\n",
            "56262/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  11]\n",
            "56263/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  12]\n",
            "56264/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.44, acc. (on x_fake)  16]\n",
            "56265/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.44, acc. (on x_fake)  15]\n",
            "56266/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  11]\n",
            "56267/60000 [D 0.16, acc. (on x_real and x_fake)  80] [G 0.49, acc. (on x_fake)   6]\n",
            "56268/60000 [D 0.17, acc. (on x_real and x_fake)  79] [G 0.50, acc. (on x_fake)  12]\n",
            "56269/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.52, acc. (on x_fake)   4]\n",
            "56270/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   6]\n",
            "56271/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)  11]\n",
            "56272/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)   8]\n",
            "56273/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)  15]\n",
            "56274/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.51, acc. (on x_fake)   6]\n",
            "56275/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)  11]\n",
            "56276/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.43, acc. (on x_fake)  13]\n",
            "56277/60000 [D 0.16, acc. (on x_real and x_fake)  79] [G 0.47, acc. (on x_fake)  13]\n",
            "56278/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  12]\n",
            "56279/60000 [D 0.16, acc. (on x_real and x_fake)  77] [G 0.48, acc. (on x_fake)  13]\n",
            "56280/60000 [D 0.18, acc. (on x_real and x_fake)  77] [G 0.50, acc. (on x_fake)  10]\n",
            "56281/60000 [D 0.20, acc. (on x_real and x_fake)  65] [G 0.47, acc. (on x_fake)  14]\n",
            "56282/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.46, acc. (on x_fake)  10]\n",
            "56283/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)   9]\n",
            "56284/60000 [D 0.21, acc. (on x_real and x_fake)  69] [G 0.43, acc. (on x_fake)  16]\n",
            "56285/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.43, acc. (on x_fake)  15]\n",
            "56286/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  11]\n",
            "56287/60000 [D 0.20, acc. (on x_real and x_fake)  75] [G 0.45, acc. (on x_fake)  11]\n",
            "56288/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.45, acc. (on x_fake)  16]\n",
            "56289/60000 [D 0.18, acc. (on x_real and x_fake)  77] [G 0.49, acc. (on x_fake)  13]\n",
            "56290/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)   9]\n",
            "56291/60000 [D 0.20, acc. (on x_real and x_fake)  67] [G 0.47, acc. (on x_fake)  11]\n",
            "56292/60000 [D 0.17, acc. (on x_real and x_fake)  80] [G 0.48, acc. (on x_fake)  10]\n",
            "56293/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.46, acc. (on x_fake)   8]\n",
            "56294/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  10]\n",
            "56295/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.49, acc. (on x_fake)  11]\n",
            "56296/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.50, acc. (on x_fake)   7]\n",
            "56297/60000 [D 0.20, acc. (on x_real and x_fake)  68] [G 0.46, acc. (on x_fake)   7]\n",
            "56298/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)   8]\n",
            "56299/60000 [D 0.16, acc. (on x_real and x_fake)  80] [G 0.49, acc. (on x_fake)  12]\n",
            "56300/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  15]\n",
            "56301/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.47, acc. (on x_fake)  12]\n",
            "56302/60000 [D 0.15, acc. (on x_real and x_fake)  80] [G 0.50, acc. (on x_fake)   4]\n",
            "56303/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)   6]\n",
            "56304/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)   8]\n",
            "56305/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.49, acc. (on x_fake)   6]\n",
            "56306/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.47, acc. (on x_fake)  12]\n",
            "56307/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)   8]\n",
            "56308/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.45, acc. (on x_fake)   7]\n",
            "56309/60000 [D 0.21, acc. (on x_real and x_fake)  67] [G 0.50, acc. (on x_fake)   8]\n",
            "56310/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)   8]\n",
            "56311/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.43, acc. (on x_fake)  16]\n",
            "56312/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.46, acc. (on x_fake)  13]\n",
            "56313/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.50, acc. (on x_fake)   9]\n",
            "56314/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.49, acc. (on x_fake)  10]\n",
            "56315/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)   5]\n",
            "56316/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  11]\n",
            "56317/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  12]\n",
            "56318/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)  10]\n",
            "56319/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.46, acc. (on x_fake)  11]\n",
            "56320/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  15]\n",
            "56321/60000 [D 0.20, acc. (on x_real and x_fake)  67] [G 0.45, acc. (on x_fake)  13]\n",
            "56322/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  12]\n",
            "56323/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.45, acc. (on x_fake)  11]\n",
            "56324/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.51, acc. (on x_fake)  10]\n",
            "56325/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)   9]\n",
            "56326/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.51, acc. (on x_fake)   4]\n",
            "56327/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.45, acc. (on x_fake)  14]\n",
            "56328/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.51, acc. (on x_fake)   9]\n",
            "56329/60000 [D 0.21, acc. (on x_real and x_fake)  64] [G 0.45, acc. (on x_fake)   9]\n",
            "56330/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.46, acc. (on x_fake)  14]\n",
            "56331/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.45, acc. (on x_fake)  12]\n",
            "56332/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)   9]\n",
            "56333/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.49, acc. (on x_fake)   8]\n",
            "56334/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)  10]\n",
            "56335/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)   8]\n",
            "56336/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  16]\n",
            "56337/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.44, acc. (on x_fake)  10]\n",
            "56338/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.44, acc. (on x_fake)  12]\n",
            "56339/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)  16]\n",
            "56340/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)   8]\n",
            "56341/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)  10]\n",
            "56342/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.47, acc. (on x_fake)  13]\n",
            "56343/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.44, acc. (on x_fake)  16]\n",
            "56344/60000 [D 0.20, acc. (on x_real and x_fake)  66] [G 0.45, acc. (on x_fake)  20]\n",
            "56345/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.46, acc. (on x_fake)   5]\n",
            "56346/60000 [D 0.22, acc. (on x_real and x_fake)  67] [G 0.47, acc. (on x_fake)   9]\n",
            "56347/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)  13]\n",
            "56348/60000 [D 0.20, acc. (on x_real and x_fake)  72] [G 0.43, acc. (on x_fake)  22]\n",
            "56349/60000 [D 0.16, acc. (on x_real and x_fake)  80] [G 0.49, acc. (on x_fake)  13]\n",
            "56350/60000 [D 0.16, acc. (on x_real and x_fake)  78] [G 0.49, acc. (on x_fake)   7]\n",
            "56351/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)  15]\n",
            "56352/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)  10]\n",
            "56353/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.46, acc. (on x_fake)   8]\n",
            "56354/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.46, acc. (on x_fake)  12]\n",
            "56355/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)  10]\n",
            "56356/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)  12]\n",
            "56357/60000 [D 0.17, acc. (on x_real and x_fake)  73] [G 0.45, acc. (on x_fake)  15]\n",
            "56358/60000 [D 0.16, acc. (on x_real and x_fake)  79] [G 0.49, acc. (on x_fake)  10]\n",
            "56359/60000 [D 0.20, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  13]\n",
            "56360/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)   9]\n",
            "56361/60000 [D 0.18, acc. (on x_real and x_fake)  77] [G 0.52, acc. (on x_fake)  10]\n",
            "56362/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)   6]\n",
            "56363/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)   9]\n",
            "56364/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.51, acc. (on x_fake)   6]\n",
            "56365/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.43, acc. (on x_fake)  15]\n",
            "56366/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.46, acc. (on x_fake)  19]\n",
            "56367/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.45, acc. (on x_fake)  16]\n",
            "56368/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.46, acc. (on x_fake)  13]\n",
            "56369/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.49, acc. (on x_fake)  14]\n",
            "56370/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  10]\n",
            "56371/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)   8]\n",
            "56372/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.49, acc. (on x_fake)  12]\n",
            "56373/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)  15]\n",
            "56374/60000 [D 0.19, acc. (on x_real and x_fake)  75] [G 0.46, acc. (on x_fake)  12]\n",
            "56375/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  11]\n",
            "56376/60000 [D 0.20, acc. (on x_real and x_fake)  67] [G 0.48, acc. (on x_fake)   8]\n",
            "56377/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.48, acc. (on x_fake)  15]\n",
            "56378/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.51, acc. (on x_fake)   8]\n",
            "56379/60000 [D 0.18, acc. (on x_real and x_fake)  70] [G 0.49, acc. (on x_fake)   6]\n",
            "56380/60000 [D 0.18, acc. (on x_real and x_fake)  70] [G 0.49, acc. (on x_fake)  11]\n",
            "56381/60000 [D 0.18, acc. (on x_real and x_fake)  70] [G 0.48, acc. (on x_fake)  14]\n",
            "56382/60000 [D 0.19, acc. (on x_real and x_fake)  68] [G 0.46, acc. (on x_fake)  12]\n",
            "56383/60000 [D 0.18, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)   9]\n",
            "56384/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.49, acc. (on x_fake)  13]\n",
            "56385/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)  12]\n",
            "56386/60000 [D 0.20, acc. (on x_real and x_fake)  67] [G 0.45, acc. (on x_fake)  20]\n",
            "56387/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)   9]\n",
            "56388/60000 [D 0.16, acc. (on x_real and x_fake)  79] [G 0.49, acc. (on x_fake)  10]\n",
            "56389/60000 [D 0.19, acc. (on x_real and x_fake)  77] [G 0.48, acc. (on x_fake)  13]\n",
            "56390/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.48, acc. (on x_fake)  12]\n",
            "56391/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)   9]\n",
            "56392/60000 [D 0.17, acc. (on x_real and x_fake)  79] [G 0.48, acc. (on x_fake)   6]\n",
            "56393/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.45, acc. (on x_fake)  16]\n",
            "56394/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)   6]\n",
            "56395/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.50, acc. (on x_fake)  13]\n",
            "56396/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   7]\n",
            "56397/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.51, acc. (on x_fake)   5]\n",
            "56398/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)   8]\n",
            "56399/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.44, acc. (on x_fake)  12]\n",
            "56400/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.48, acc. (on x_fake)  10]\n",
            "56401/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)  10]\n",
            "56402/60000 [D 0.17, acc. (on x_real and x_fake)  73] [G 0.51, acc. (on x_fake)  10]\n",
            "56403/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.44, acc. (on x_fake)  18]\n",
            "56404/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)  14]\n",
            "56405/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.47, acc. (on x_fake)   8]\n",
            "56406/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.47, acc. (on x_fake)  11]\n",
            "56407/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.50, acc. (on x_fake)  12]\n",
            "56408/60000 [D 0.20, acc. (on x_real and x_fake)  68] [G 0.46, acc. (on x_fake)  14]\n",
            "56409/60000 [D 0.17, acc. (on x_real and x_fake)  79] [G 0.44, acc. (on x_fake)  13]\n",
            "56410/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.46, acc. (on x_fake)  10]\n",
            "56411/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.46, acc. (on x_fake)  10]\n",
            "56412/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.51, acc. (on x_fake)   7]\n",
            "56413/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.51, acc. (on x_fake)   8]\n",
            "56414/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)   8]\n",
            "56415/60000 [D 0.20, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)   9]\n",
            "56416/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.45, acc. (on x_fake)  16]\n",
            "56417/60000 [D 0.21, acc. (on x_real and x_fake)  67] [G 0.51, acc. (on x_fake)   8]\n",
            "56418/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)   8]\n",
            "56419/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)  10]\n",
            "56420/60000 [D 0.20, acc. (on x_real and x_fake)  68] [G 0.47, acc. (on x_fake)  13]\n",
            "56421/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.45, acc. (on x_fake)  13]\n",
            "56422/60000 [D 0.19, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  10]\n",
            "56423/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)  11]\n",
            "56424/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)   9]\n",
            "56425/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)  12]\n",
            "56426/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.50, acc. (on x_fake)   7]\n",
            "56427/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.50, acc. (on x_fake)  13]\n",
            "56428/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)   9]\n",
            "56429/60000 [D 0.20, acc. (on x_real and x_fake)  66] [G 0.47, acc. (on x_fake)  14]\n",
            "56430/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.45, acc. (on x_fake)  13]\n",
            "56431/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.48, acc. (on x_fake)   8]\n",
            "56432/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.51, acc. (on x_fake)  13]\n",
            "56433/60000 [D 0.20, acc. (on x_real and x_fake)  67] [G 0.45, acc. (on x_fake)  12]\n",
            "56434/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.50, acc. (on x_fake)  10]\n",
            "56435/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)   9]\n",
            "56436/60000 [D 0.18, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)  11]\n",
            "56437/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.46, acc. (on x_fake)  10]\n",
            "56438/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)   8]\n",
            "56439/60000 [D 0.16, acc. (on x_real and x_fake)  76] [G 0.47, acc. (on x_fake)  14]\n",
            "56440/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.45, acc. (on x_fake)  15]\n",
            "56441/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.46, acc. (on x_fake)  11]\n",
            "56442/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)  12]\n",
            "56443/60000 [D 0.16, acc. (on x_real and x_fake)  80] [G 0.50, acc. (on x_fake)  11]\n",
            "56444/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.52, acc. (on x_fake)   7]\n",
            "56445/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   7]\n",
            "56446/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)   9]\n",
            "56447/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.47, acc. (on x_fake)  11]\n",
            "56448/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.44, acc. (on x_fake)  17]\n",
            "56449/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.51, acc. (on x_fake)   7]\n",
            "56450/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  15]\n",
            "56451/60000 [D 0.21, acc. (on x_real and x_fake)  66] [G 0.47, acc. (on x_fake)   8]\n",
            "56452/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)   7]\n",
            "56453/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)  16]\n",
            "56454/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  10]\n",
            "56455/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)  11]\n",
            "56456/60000 [D 0.17, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)   9]\n",
            "56457/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)  13]\n",
            "56458/60000 [D 0.16, acc. (on x_real and x_fake)  78] [G 0.48, acc. (on x_fake)  10]\n",
            "56459/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)   9]\n",
            "56460/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.51, acc. (on x_fake)   8]\n",
            "56461/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  15]\n",
            "56462/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.46, acc. (on x_fake)  16]\n",
            "56463/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.46, acc. (on x_fake)   8]\n",
            "56464/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.51, acc. (on x_fake)   9]\n",
            "56465/60000 [D 0.17, acc. (on x_real and x_fake)  81] [G 0.48, acc. (on x_fake)  11]\n",
            "56466/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.47, acc. (on x_fake)  12]\n",
            "56467/60000 [D 0.18, acc. (on x_real and x_fake)  79] [G 0.46, acc. (on x_fake)   7]\n",
            "56468/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.45, acc. (on x_fake)  21]\n",
            "56469/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)   8]\n",
            "56470/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)  13]\n",
            "56471/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.51, acc. (on x_fake)   5]\n",
            "56472/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.46, acc. (on x_fake)  10]\n",
            "56473/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.47, acc. (on x_fake)  12]\n",
            "56474/60000 [D 0.21, acc. (on x_real and x_fake)  64] [G 0.47, acc. (on x_fake)   9]\n",
            "56475/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.45, acc. (on x_fake)  14]\n",
            "56476/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.46, acc. (on x_fake)  11]\n",
            "56477/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  10]\n",
            "56478/60000 [D 0.21, acc. (on x_real and x_fake)  66] [G 0.42, acc. (on x_fake)  17]\n",
            "56479/60000 [D 0.16, acc. (on x_real and x_fake)  81] [G 0.51, acc. (on x_fake)   6]\n",
            "56480/60000 [D 0.17, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)   9]\n",
            "56481/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.49, acc. (on x_fake)  10]\n",
            "56482/60000 [D 0.18, acc. (on x_real and x_fake)  78] [G 0.50, acc. (on x_fake)   8]\n",
            "56483/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.45, acc. (on x_fake)  16]\n",
            "56484/60000 [D 0.17, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)   9]\n",
            "56485/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  11]\n",
            "56486/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.51, acc. (on x_fake)   7]\n",
            "56487/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.46, acc. (on x_fake)  12]\n",
            "56488/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.49, acc. (on x_fake)   6]\n",
            "56489/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.52, acc. (on x_fake)   4]\n",
            "56490/60000 [D 0.22, acc. (on x_real and x_fake)  66] [G 0.46, acc. (on x_fake)   6]\n",
            "56491/60000 [D 0.19, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   8]\n",
            "56492/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)  10]\n",
            "56493/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)  12]\n",
            "56494/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.45, acc. (on x_fake)  13]\n",
            "56495/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)   8]\n",
            "56496/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)  14]\n",
            "56497/60000 [D 0.16, acc. (on x_real and x_fake)  77] [G 0.48, acc. (on x_fake)   8]\n",
            "56498/60000 [D 0.18, acc. (on x_real and x_fake)  78] [G 0.53, acc. (on x_fake)   8]\n",
            "56499/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.46, acc. (on x_fake)  13]\n",
            "56500/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.50, acc. (on x_fake)   9]\n",
            "56501/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.49, acc. (on x_fake)  11]\n",
            "56502/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)  10]\n",
            "56503/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)  11]\n",
            "56504/60000 [D 0.20, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)   8]\n",
            "56505/60000 [D 0.20, acc. (on x_real and x_fake)  71] [G 0.46, acc. (on x_fake)   8]\n",
            "56506/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.44, acc. (on x_fake)  10]\n",
            "56507/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)   3]\n",
            "56508/60000 [D 0.16, acc. (on x_real and x_fake)  78] [G 0.46, acc. (on x_fake)   8]\n",
            "56509/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)   6]\n",
            "56510/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.46, acc. (on x_fake)  14]\n",
            "56511/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.46, acc. (on x_fake)  14]\n",
            "56512/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.48, acc. (on x_fake)  11]\n",
            "56513/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)   8]\n",
            "56514/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.46, acc. (on x_fake)  14]\n",
            "56515/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.50, acc. (on x_fake)  18]\n",
            "56516/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.47, acc. (on x_fake)  14]\n",
            "56517/60000 [D 0.20, acc. (on x_real and x_fake)  64] [G 0.45, acc. (on x_fake)  11]\n",
            "56518/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  10]\n",
            "56519/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.46, acc. (on x_fake)  12]\n",
            "56520/60000 [D 0.15, acc. (on x_real and x_fake)  81] [G 0.49, acc. (on x_fake)  13]\n",
            "56521/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.47, acc. (on x_fake)  11]\n",
            "56522/60000 [D 0.22, acc. (on x_real and x_fake)  67] [G 0.46, acc. (on x_fake)  14]\n",
            "56523/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.46, acc. (on x_fake)   9]\n",
            "56524/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.47, acc. (on x_fake)  11]\n",
            "56525/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.46, acc. (on x_fake)  11]\n",
            "56526/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.44, acc. (on x_fake)  20]\n",
            "56527/60000 [D 0.16, acc. (on x_real and x_fake)  78] [G 0.47, acc. (on x_fake)  12]\n",
            "56528/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)  11]\n",
            "56529/60000 [D 0.16, acc. (on x_real and x_fake)  77] [G 0.48, acc. (on x_fake)   8]\n",
            "56530/60000 [D 0.20, acc. (on x_real and x_fake)  68] [G 0.46, acc. (on x_fake)  13]\n",
            "56531/60000 [D 0.17, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  10]\n",
            "56532/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)  11]\n",
            "56533/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.47, acc. (on x_fake)   8]\n",
            "56534/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.46, acc. (on x_fake)  11]\n",
            "56535/60000 [D 0.20, acc. (on x_real and x_fake)  68] [G 0.48, acc. (on x_fake)  11]\n",
            "56536/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)  11]\n",
            "56537/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)  14]\n",
            "56538/60000 [D 0.17, acc. (on x_real and x_fake)  69] [G 0.49, acc. (on x_fake)   7]\n",
            "56539/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.46, acc. (on x_fake)  13]\n",
            "56540/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  13]\n",
            "56541/60000 [D 0.20, acc. (on x_real and x_fake)  63] [G 0.42, acc. (on x_fake)  20]\n",
            "56542/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)   9]\n",
            "56543/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)  11]\n",
            "56544/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.46, acc. (on x_fake)  15]\n",
            "56545/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.46, acc. (on x_fake)  16]\n",
            "56546/60000 [D 0.20, acc. (on x_real and x_fake)  66] [G 0.48, acc. (on x_fake)  10]\n",
            "56547/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   6]\n",
            "56548/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.49, acc. (on x_fake)  10]\n",
            "56549/60000 [D 0.20, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)   9]\n",
            "56550/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.44, acc. (on x_fake)  13]\n",
            "56551/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)   7]\n",
            "56552/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)  11]\n",
            "56553/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)  12]\n",
            "56554/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.45, acc. (on x_fake)  14]\n",
            "56555/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)  10]\n",
            "56556/60000 [D 0.18, acc. (on x_real and x_fake)  77] [G 0.47, acc. (on x_fake)  14]\n",
            "56557/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)   9]\n",
            "56558/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  10]\n",
            "56559/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.44, acc. (on x_fake)  12]\n",
            "56560/60000 [D 0.19, acc. (on x_real and x_fake)  68] [G 0.45, acc. (on x_fake)  11]\n",
            "56561/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  11]\n",
            "56562/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.47, acc. (on x_fake)   7]\n",
            "56563/60000 [D 0.20, acc. (on x_real and x_fake)  70] [G 0.49, acc. (on x_fake)  10]\n",
            "56564/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.49, acc. (on x_fake)   5]\n",
            "56565/60000 [D 0.16, acc. (on x_real and x_fake)  81] [G 0.49, acc. (on x_fake)   6]\n",
            "56566/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   5]\n",
            "56567/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  13]\n",
            "56568/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)  15]\n",
            "56569/60000 [D 0.16, acc. (on x_real and x_fake)  78] [G 0.51, acc. (on x_fake)   8]\n",
            "56570/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)  10]\n",
            "56571/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)   7]\n",
            "56572/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.46, acc. (on x_fake)  11]\n",
            "56573/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.51, acc. (on x_fake)  10]\n",
            "56574/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   8]\n",
            "56575/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.45, acc. (on x_fake)  16]\n",
            "56576/60000 [D 0.20, acc. (on x_real and x_fake)  64] [G 0.47, acc. (on x_fake)  11]\n",
            "56577/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  14]\n",
            "56578/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)   8]\n",
            "56579/60000 [D 0.17, acc. (on x_real and x_fake)  79] [G 0.48, acc. (on x_fake)  10]\n",
            "56580/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  14]\n",
            "56581/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.51, acc. (on x_fake)  10]\n",
            "56582/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)   9]\n",
            "56583/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.49, acc. (on x_fake)   8]\n",
            "56584/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.48, acc. (on x_fake)  11]\n",
            "56585/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)  14]\n",
            "56586/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)   8]\n",
            "56587/60000 [D 0.17, acc. (on x_real and x_fake)  73] [G 0.51, acc. (on x_fake)   4]\n",
            "56588/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)  14]\n",
            "56589/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.46, acc. (on x_fake)  16]\n",
            "56590/60000 [D 0.18, acc. (on x_real and x_fake)  70] [G 0.45, acc. (on x_fake)  11]\n",
            "56591/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)  13]\n",
            "56592/60000 [D 0.17, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)  12]\n",
            "56593/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.50, acc. (on x_fake)   5]\n",
            "56594/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)   4]\n",
            "56595/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)   4]\n",
            "56596/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)   7]\n",
            "56597/60000 [D 0.20, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  13]\n",
            "56598/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   8]\n",
            "56599/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.46, acc. (on x_fake)  12]\n",
            "56600/60000 [D 0.20, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)   7]\n",
            "56601/60000 [D 0.19, acc. (on x_real and x_fake)  65] [G 0.46, acc. (on x_fake)  11]\n",
            "56602/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  10]\n",
            "56603/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)  11]\n",
            "56604/60000 [D 0.20, acc. (on x_real and x_fake)  70] [G 0.46, acc. (on x_fake)  11]\n",
            "56605/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)  11]\n",
            "56606/60000 [D 0.17, acc. (on x_real and x_fake)  72] [G 0.50, acc. (on x_fake)  12]\n",
            "56607/60000 [D 0.16, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)   7]\n",
            "56608/60000 [D 0.19, acc. (on x_real and x_fake)  67] [G 0.49, acc. (on x_fake)  11]\n",
            "56609/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.52, acc. (on x_fake)   6]\n",
            "56610/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)  12]\n",
            "56611/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.49, acc. (on x_fake)   6]\n",
            "56612/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  13]\n",
            "56613/60000 [D 0.19, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)  10]\n",
            "56614/60000 [D 0.16, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)  11]\n",
            "56615/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)  12]\n",
            "56616/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)   7]\n",
            "56617/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)  11]\n",
            "56618/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.48, acc. (on x_fake)   7]\n",
            "56619/60000 [D 0.18, acc. (on x_real and x_fake)  77] [G 0.46, acc. (on x_fake)  10]\n",
            "56620/60000 [D 0.16, acc. (on x_real and x_fake)  78] [G 0.50, acc. (on x_fake)   9]\n",
            "56621/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)  17]\n",
            "56622/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.51, acc. (on x_fake)  11]\n",
            "56623/60000 [D 0.19, acc. (on x_real and x_fake)  67] [G 0.47, acc. (on x_fake)  13]\n",
            "56624/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.49, acc. (on x_fake)  19]\n",
            "56625/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.50, acc. (on x_fake)  10]\n",
            "56626/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)  14]\n",
            "56627/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.50, acc. (on x_fake)   8]\n",
            "56628/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.51, acc. (on x_fake)  10]\n",
            "56629/60000 [D 0.20, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)   7]\n",
            "56630/60000 [D 0.16, acc. (on x_real and x_fake)  80] [G 0.47, acc. (on x_fake)  11]\n",
            "56631/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.52, acc. (on x_fake)   9]\n",
            "56632/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.51, acc. (on x_fake)   8]\n",
            "56633/60000 [D 0.18, acc. (on x_real and x_fake)  70] [G 0.49, acc. (on x_fake)   8]\n",
            "56634/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.51, acc. (on x_fake)   8]\n",
            "56635/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.46, acc. (on x_fake)  16]\n",
            "56636/60000 [D 0.20, acc. (on x_real and x_fake)  68] [G 0.46, acc. (on x_fake)  20]\n",
            "56637/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)  13]\n",
            "56638/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)  12]\n",
            "56639/60000 [D 0.20, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)  13]\n",
            "56640/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.46, acc. (on x_fake)  16]\n",
            "56641/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.49, acc. (on x_fake)   9]\n",
            "56642/60000 [D 0.16, acc. (on x_real and x_fake)  78] [G 0.47, acc. (on x_fake)  15]\n",
            "56643/60000 [D 0.16, acc. (on x_real and x_fake)  78] [G 0.51, acc. (on x_fake)  10]\n",
            "56644/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  11]\n",
            "56645/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  13]\n",
            "56646/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.50, acc. (on x_fake)  12]\n",
            "56647/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.53, acc. (on x_fake)   9]\n",
            "56648/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  12]\n",
            "56649/60000 [D 0.20, acc. (on x_real and x_fake)  68] [G 0.50, acc. (on x_fake)   5]\n",
            "56650/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.48, acc. (on x_fake)  10]\n",
            "56651/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.50, acc. (on x_fake)   9]\n",
            "56652/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)   9]\n",
            "56653/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  14]\n",
            "56654/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)   7]\n",
            "56655/60000 [D 0.20, acc. (on x_real and x_fake)  70] [G 0.48, acc. (on x_fake)  10]\n",
            "56656/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  13]\n",
            "56657/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.51, acc. (on x_fake)   5]\n",
            "56658/60000 [D 0.20, acc. (on x_real and x_fake)  66] [G 0.46, acc. (on x_fake)  16]\n",
            "56659/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.50, acc. (on x_fake)   9]\n",
            "56660/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.45, acc. (on x_fake)  14]\n",
            "56661/60000 [D 0.21, acc. (on x_real and x_fake)  69] [G 0.45, acc. (on x_fake)  12]\n",
            "56662/60000 [D 0.16, acc. (on x_real and x_fake)  76] [G 0.48, acc. (on x_fake)   7]\n",
            "56663/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.50, acc. (on x_fake)   7]\n",
            "56664/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.48, acc. (on x_fake)  10]\n",
            "56665/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)  11]\n",
            "56666/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.48, acc. (on x_fake)   7]\n",
            "56667/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.46, acc. (on x_fake)  12]\n",
            "56668/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)  13]\n",
            "56669/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)  10]\n",
            "56670/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.49, acc. (on x_fake)  11]\n",
            "56671/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  11]\n",
            "56672/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  11]\n",
            "56673/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.48, acc. (on x_fake)   8]\n",
            "56674/60000 [D 0.18, acc. (on x_real and x_fake)  70] [G 0.49, acc. (on x_fake)   9]\n",
            "56675/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.46, acc. (on x_fake)  10]\n",
            "56676/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.43, acc. (on x_fake)  14]\n",
            "56677/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)  10]\n",
            "56678/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.50, acc. (on x_fake)   8]\n",
            "56679/60000 [D 0.17, acc. (on x_real and x_fake)  73] [G 0.51, acc. (on x_fake)  10]\n",
            "56680/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.50, acc. (on x_fake)  10]\n",
            "56681/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)  16]\n",
            "56682/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)  14]\n",
            "56683/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)  10]\n",
            "56684/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)   8]\n",
            "56685/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  11]\n",
            "56686/60000 [D 0.16, acc. (on x_real and x_fake)  79] [G 0.50, acc. (on x_fake)   6]\n",
            "56687/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.51, acc. (on x_fake)   9]\n",
            "56688/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.50, acc. (on x_fake)   9]\n",
            "56689/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.49, acc. (on x_fake)  10]\n",
            "56690/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.49, acc. (on x_fake)   7]\n",
            "56691/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.45, acc. (on x_fake)  12]\n",
            "56692/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)   8]\n",
            "56693/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)   7]\n",
            "56694/60000 [D 0.21, acc. (on x_real and x_fake)  66] [G 0.46, acc. (on x_fake)  15]\n",
            "56695/60000 [D 0.20, acc. (on x_real and x_fake)  67] [G 0.47, acc. (on x_fake)  16]\n",
            "56696/60000 [D 0.19, acc. (on x_real and x_fake)  66] [G 0.45, acc. (on x_fake)  11]\n",
            "56697/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  11]\n",
            "56698/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.44, acc. (on x_fake)  16]\n",
            "56699/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.43, acc. (on x_fake)  16]\n",
            "56700/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.50, acc. (on x_fake)   6]\n",
            "56701/60000 [D 0.20, acc. (on x_real and x_fake)  66] [G 0.45, acc. (on x_fake)  13]\n",
            "56702/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.46, acc. (on x_fake)  16]\n",
            "56703/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.45, acc. (on x_fake)  15]\n",
            "56704/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.46, acc. (on x_fake)  13]\n",
            "56705/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.53, acc. (on x_fake)   5]\n",
            "56706/60000 [D 0.16, acc. (on x_real and x_fake)  76] [G 0.50, acc. (on x_fake)  10]\n",
            "56707/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  13]\n",
            "56708/60000 [D 0.17, acc. (on x_real and x_fake)  79] [G 0.48, acc. (on x_fake)  11]\n",
            "56709/60000 [D 0.16, acc. (on x_real and x_fake)  78] [G 0.49, acc. (on x_fake)   6]\n",
            "56710/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)   9]\n",
            "56711/60000 [D 0.17, acc. (on x_real and x_fake)  79] [G 0.51, acc. (on x_fake)  12]\n",
            "56712/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.46, acc. (on x_fake)   8]\n",
            "56713/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.44, acc. (on x_fake)  12]\n",
            "56714/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  16]\n",
            "56715/60000 [D 0.20, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  11]\n",
            "56716/60000 [D 0.17, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  12]\n",
            "56717/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)  15]\n",
            "56718/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)   7]\n",
            "56719/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.44, acc. (on x_fake)  12]\n",
            "56720/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.50, acc. (on x_fake)  18]\n",
            "56721/60000 [D 0.18, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)  10]\n",
            "56722/60000 [D 0.17, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  17]\n",
            "56723/60000 [D 0.16, acc. (on x_real and x_fake)  80] [G 0.49, acc. (on x_fake)  12]\n",
            "56724/60000 [D 0.20, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)  14]\n",
            "56725/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.50, acc. (on x_fake)   6]\n",
            "56726/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)  10]\n",
            "56727/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.50, acc. (on x_fake)   7]\n",
            "56728/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  13]\n",
            "56729/60000 [D 0.18, acc. (on x_real and x_fake)  77] [G 0.51, acc. (on x_fake)   4]\n",
            "56730/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)  10]\n",
            "56731/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)   8]\n",
            "56732/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  11]\n",
            "56733/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)   9]\n",
            "56734/60000 [D 0.20, acc. (on x_real and x_fake)  68] [G 0.50, acc. (on x_fake)   6]\n",
            "56735/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)  11]\n",
            "56736/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)  10]\n",
            "56737/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  12]\n",
            "56738/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)   9]\n",
            "56739/60000 [D 0.16, acc. (on x_real and x_fake)  81] [G 0.51, acc. (on x_fake)   6]\n",
            "56740/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.46, acc. (on x_fake)  15]\n",
            "56741/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.44, acc. (on x_fake)  12]\n",
            "56742/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.43, acc. (on x_fake)  15]\n",
            "56743/60000 [D 0.19, acc. (on x_real and x_fake)  68] [G 0.45, acc. (on x_fake)  11]\n",
            "56744/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   7]\n",
            "56745/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)   6]\n",
            "56746/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)  12]\n",
            "56747/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.50, acc. (on x_fake)  12]\n",
            "56748/60000 [D 0.19, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  14]\n",
            "56749/60000 [D 0.20, acc. (on x_real and x_fake)  72] [G 0.43, acc. (on x_fake)  19]\n",
            "56750/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)  10]\n",
            "56751/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.45, acc. (on x_fake)  12]\n",
            "56752/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)  12]\n",
            "56753/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)  13]\n",
            "56754/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)   4]\n",
            "56755/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)   9]\n",
            "56756/60000 [D 0.19, acc. (on x_real and x_fake)  67] [G 0.48, acc. (on x_fake)  14]\n",
            "56757/60000 [D 0.18, acc. (on x_real and x_fake)  70] [G 0.49, acc. (on x_fake)   9]\n",
            "56758/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.50, acc. (on x_fake)   8]\n",
            "56759/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.52, acc. (on x_fake)   7]\n",
            "56760/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)  11]\n",
            "56761/60000 [D 0.18, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)   9]\n",
            "56762/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.46, acc. (on x_fake)   8]\n",
            "56763/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  13]\n",
            "56764/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)  18]\n",
            "56765/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.52, acc. (on x_fake)   7]\n",
            "56766/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.50, acc. (on x_fake)  11]\n",
            "56767/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.52, acc. (on x_fake)   5]\n",
            "56768/60000 [D 0.20, acc. (on x_real and x_fake)  68] [G 0.48, acc. (on x_fake)  10]\n",
            "56769/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.49, acc. (on x_fake)  10]\n",
            "56770/60000 [D 0.18, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)  11]\n",
            "56771/60000 [D 0.20, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)  14]\n",
            "56772/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  11]\n",
            "56773/60000 [D 0.20, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  12]\n",
            "56774/60000 [D 0.18, acc. (on x_real and x_fake)  77] [G 0.44, acc. (on x_fake)  14]\n",
            "56775/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.51, acc. (on x_fake)   9]\n",
            "56776/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.52, acc. (on x_fake)   6]\n",
            "56777/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.46, acc. (on x_fake)  16]\n",
            "56778/60000 [D 0.21, acc. (on x_real and x_fake)  66] [G 0.45, acc. (on x_fake)  15]\n",
            "56779/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.48, acc. (on x_fake)  12]\n",
            "56780/60000 [D 0.16, acc. (on x_real and x_fake)  76] [G 0.49, acc. (on x_fake)  10]\n",
            "56781/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)   7]\n",
            "56782/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)   9]\n",
            "56783/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.48, acc. (on x_fake)   8]\n",
            "56784/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)   6]\n",
            "56785/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.46, acc. (on x_fake)  14]\n",
            "56786/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.51, acc. (on x_fake)   9]\n",
            "56787/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.46, acc. (on x_fake)  15]\n",
            "56788/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)   7]\n",
            "56789/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.51, acc. (on x_fake)  11]\n",
            "56790/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)  11]\n",
            "56791/60000 [D 0.19, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  13]\n",
            "56792/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  10]\n",
            "56793/60000 [D 0.18, acc. (on x_real and x_fake)  77] [G 0.47, acc. (on x_fake)  12]\n",
            "56794/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)  11]\n",
            "56795/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.46, acc. (on x_fake)  14]\n",
            "56796/60000 [D 0.16, acc. (on x_real and x_fake)  79] [G 0.51, acc. (on x_fake)   7]\n",
            "56797/60000 [D 0.18, acc. (on x_real and x_fake)  70] [G 0.48, acc. (on x_fake)  12]\n",
            "56798/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.47, acc. (on x_fake)   9]\n",
            "56799/60000 [D 0.16, acc. (on x_real and x_fake)  77] [G 0.51, acc. (on x_fake)   7]\n",
            "56800/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.47, acc. (on x_fake)   9]\n",
            "56801/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.45, acc. (on x_fake)  17]\n",
            "56802/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.45, acc. (on x_fake)  12]\n",
            "56803/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)   8]\n",
            "56804/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.51, acc. (on x_fake)   5]\n",
            "56805/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.46, acc. (on x_fake)  10]\n",
            "56806/60000 [D 0.21, acc. (on x_real and x_fake)  65] [G 0.45, acc. (on x_fake)  15]\n",
            "56807/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)  13]\n",
            "56808/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)  10]\n",
            "56809/60000 [D 0.19, acc. (on x_real and x_fake)  76] [G 0.44, acc. (on x_fake)  11]\n",
            "56810/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)  10]\n",
            "56811/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  19]\n",
            "56812/60000 [D 0.19, acc. (on x_real and x_fake)  68] [G 0.47, acc. (on x_fake)  16]\n",
            "56813/60000 [D 0.21, acc. (on x_real and x_fake)  67] [G 0.46, acc. (on x_fake)  13]\n",
            "56814/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.52, acc. (on x_fake)   4]\n",
            "56815/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   8]\n",
            "56816/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)  10]\n",
            "56817/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.43, acc. (on x_fake)  16]\n",
            "56818/60000 [D 0.21, acc. (on x_real and x_fake)  64] [G 0.44, acc. (on x_fake)  13]\n",
            "56819/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)   7]\n",
            "56820/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)  11]\n",
            "56821/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.50, acc. (on x_fake)  10]\n",
            "56822/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.47, acc. (on x_fake)  15]\n",
            "56823/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.46, acc. (on x_fake)  10]\n",
            "56824/60000 [D 0.21, acc. (on x_real and x_fake)  69] [G 0.46, acc. (on x_fake)   9]\n",
            "56825/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.47, acc. (on x_fake)   5]\n",
            "56826/60000 [D 0.21, acc. (on x_real and x_fake)  66] [G 0.49, acc. (on x_fake)   8]\n",
            "56827/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.45, acc. (on x_fake)   8]\n",
            "56828/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.50, acc. (on x_fake)  10]\n",
            "56829/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)   8]\n",
            "56830/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.45, acc. (on x_fake)  10]\n",
            "56831/60000 [D 0.16, acc. (on x_real and x_fake)  78] [G 0.50, acc. (on x_fake)   7]\n",
            "56832/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)   7]\n",
            "56833/60000 [D 0.20, acc. (on x_real and x_fake)  71] [G 0.46, acc. (on x_fake)  13]\n",
            "56834/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)  11]\n",
            "56835/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.45, acc. (on x_fake)  19]\n",
            "56836/60000 [D 0.16, acc. (on x_real and x_fake)  76] [G 0.48, acc. (on x_fake)  11]\n",
            "56837/60000 [D 0.17, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  16]\n",
            "56838/60000 [D 0.21, acc. (on x_real and x_fake)  67] [G 0.44, acc. (on x_fake)  16]\n",
            "56839/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  17]\n",
            "56840/60000 [D 0.20, acc. (on x_real and x_fake)  68] [G 0.44, acc. (on x_fake)  21]\n",
            "56841/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.45, acc. (on x_fake)  17]\n",
            "56842/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.47, acc. (on x_fake)  12]\n",
            "56843/60000 [D 0.21, acc. (on x_real and x_fake)  64] [G 0.45, acc. (on x_fake)  19]\n",
            "56844/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)   9]\n",
            "56845/60000 [D 0.19, acc. (on x_real and x_fake)  77] [G 0.49, acc. (on x_fake)   9]\n",
            "56846/60000 [D 0.20, acc. (on x_real and x_fake)  68] [G 0.47, acc. (on x_fake)  12]\n",
            "56847/60000 [D 0.18, acc. (on x_real and x_fake)  77] [G 0.49, acc. (on x_fake)   5]\n",
            "56848/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.48, acc. (on x_fake)  13]\n",
            "56849/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.46, acc. (on x_fake)  14]\n",
            "56850/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.46, acc. (on x_fake)  14]\n",
            "56851/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)   9]\n",
            "56852/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.44, acc. (on x_fake)  15]\n",
            "56853/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  12]\n",
            "56854/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.50, acc. (on x_fake)   8]\n",
            "56855/60000 [D 0.19, acc. (on x_real and x_fake)  67] [G 0.46, acc. (on x_fake)  14]\n",
            "56856/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.46, acc. (on x_fake)  18]\n",
            "56857/60000 [D 0.20, acc. (on x_real and x_fake)  70] [G 0.48, acc. (on x_fake)  11]\n",
            "56858/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.51, acc. (on x_fake)  11]\n",
            "56859/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  10]\n",
            "56860/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)   7]\n",
            "56861/60000 [D 0.20, acc. (on x_real and x_fake)  67] [G 0.46, acc. (on x_fake)  14]\n",
            "56862/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  13]\n",
            "56863/60000 [D 0.20, acc. (on x_real and x_fake)  68] [G 0.48, acc. (on x_fake)   7]\n",
            "56864/60000 [D 0.18, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)  13]\n",
            "56865/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  12]\n",
            "56866/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.46, acc. (on x_fake)   9]\n",
            "56867/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  14]\n",
            "56868/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.51, acc. (on x_fake)   9]\n",
            "56869/60000 [D 0.17, acc. (on x_real and x_fake)  73] [G 0.50, acc. (on x_fake)   8]\n",
            "56870/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   9]\n",
            "56871/60000 [D 0.18, acc. (on x_real and x_fake)  78] [G 0.45, acc. (on x_fake)  18]\n",
            "56872/60000 [D 0.15, acc. (on x_real and x_fake)  81] [G 0.52, acc. (on x_fake)   8]\n",
            "56873/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)  15]\n",
            "56874/60000 [D 0.16, acc. (on x_real and x_fake)  81] [G 0.51, acc. (on x_fake)   5]\n",
            "56875/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  12]\n",
            "56876/60000 [D 0.19, acc. (on x_real and x_fake)  76] [G 0.47, acc. (on x_fake)  10]\n",
            "56877/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.48, acc. (on x_fake)   9]\n",
            "56878/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   5]\n",
            "56879/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)   9]\n",
            "56880/60000 [D 0.16, acc. (on x_real and x_fake)  79] [G 0.50, acc. (on x_fake)   9]\n",
            "56881/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)   9]\n",
            "56882/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  12]\n",
            "56883/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)  10]\n",
            "56884/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.47, acc. (on x_fake)   7]\n",
            "56885/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)   9]\n",
            "56886/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.46, acc. (on x_fake)  15]\n",
            "56887/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.50, acc. (on x_fake)   8]\n",
            "56888/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  14]\n",
            "56889/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)   9]\n",
            "56890/60000 [D 0.18, acc. (on x_real and x_fake)  70] [G 0.51, acc. (on x_fake)   5]\n",
            "56891/60000 [D 0.21, acc. (on x_real and x_fake)  64] [G 0.47, acc. (on x_fake)   8]\n",
            "56892/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)  12]\n",
            "56893/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)  11]\n",
            "56894/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  14]\n",
            "56895/60000 [D 0.20, acc. (on x_real and x_fake)  73] [G 0.46, acc. (on x_fake)  10]\n",
            "56896/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.47, acc. (on x_fake)   4]\n",
            "56897/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.51, acc. (on x_fake)   2]\n",
            "56898/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.50, acc. (on x_fake)   6]\n",
            "56899/60000 [D 0.18, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)  13]\n",
            "56900/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)   5]\n",
            "56901/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   6]\n",
            "56902/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.47, acc. (on x_fake)  13]\n",
            "56903/60000 [D 0.17, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)  12]\n",
            "56904/60000 [D 0.16, acc. (on x_real and x_fake)  79] [G 0.50, acc. (on x_fake)  10]\n",
            "56905/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.45, acc. (on x_fake)  15]\n",
            "56906/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)  12]\n",
            "56907/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  13]\n",
            "56908/60000 [D 0.20, acc. (on x_real and x_fake)  68] [G 0.46, acc. (on x_fake)   7]\n",
            "56909/60000 [D 0.16, acc. (on x_real and x_fake)  75] [G 0.51, acc. (on x_fake)   7]\n",
            "56910/60000 [D 0.21, acc. (on x_real and x_fake)  65] [G 0.46, acc. (on x_fake)  13]\n",
            "56911/60000 [D 0.17, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)   8]\n",
            "56912/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)   8]\n",
            "56913/60000 [D 0.19, acc. (on x_real and x_fake)  68] [G 0.47, acc. (on x_fake)  11]\n",
            "56914/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.45, acc. (on x_fake)  11]\n",
            "56915/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.45, acc. (on x_fake)  12]\n",
            "56916/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)  11]\n",
            "56917/60000 [D 0.18, acc. (on x_real and x_fake)  77] [G 0.47, acc. (on x_fake)   9]\n",
            "56918/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   9]\n",
            "56919/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)   7]\n",
            "56920/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.50, acc. (on x_fake)   9]\n",
            "56921/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.46, acc. (on x_fake)  13]\n",
            "56922/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.48, acc. (on x_fake)  10]\n",
            "56923/60000 [D 0.16, acc. (on x_real and x_fake)  78] [G 0.47, acc. (on x_fake)  16]\n",
            "56924/60000 [D 0.20, acc. (on x_real and x_fake)  68] [G 0.47, acc. (on x_fake)  17]\n",
            "56925/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)  12]\n",
            "56926/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.46, acc. (on x_fake)  17]\n",
            "56927/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  12]\n",
            "56928/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)  10]\n",
            "56929/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)  13]\n",
            "56930/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)  10]\n",
            "56931/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.46, acc. (on x_fake)   5]\n",
            "56932/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.49, acc. (on x_fake)   9]\n",
            "56933/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.44, acc. (on x_fake)  19]\n",
            "56934/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.51, acc. (on x_fake)   5]\n",
            "56935/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)  10]\n",
            "56936/60000 [D 0.18, acc. (on x_real and x_fake)  77] [G 0.49, acc. (on x_fake)   8]\n",
            "56937/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)  13]\n",
            "56938/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.47, acc. (on x_fake)  10]\n",
            "56939/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)   7]\n",
            "56940/60000 [D 0.17, acc. (on x_real and x_fake)  70] [G 0.49, acc. (on x_fake)  10]\n",
            "56941/60000 [D 0.17, acc. (on x_real and x_fake)  79] [G 0.49, acc. (on x_fake)  12]\n",
            "56942/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.50, acc. (on x_fake)   8]\n",
            "56943/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.52, acc. (on x_fake)  10]\n",
            "56944/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)  12]\n",
            "56945/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)  12]\n",
            "56946/60000 [D 0.18, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)  11]\n",
            "56947/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)   9]\n",
            "56948/60000 [D 0.19, acc. (on x_real and x_fake)  67] [G 0.46, acc. (on x_fake)  12]\n",
            "56949/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.51, acc. (on x_fake)  10]\n",
            "56950/60000 [D 0.20, acc. (on x_real and x_fake)  68] [G 0.46, acc. (on x_fake)   7]\n",
            "56951/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)  10]\n",
            "56952/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.50, acc. (on x_fake)  10]\n",
            "56953/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.43, acc. (on x_fake)  15]\n",
            "56954/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.46, acc. (on x_fake)  14]\n",
            "56955/60000 [D 0.20, acc. (on x_real and x_fake)  67] [G 0.43, acc. (on x_fake)  15]\n",
            "56956/60000 [D 0.19, acc. (on x_real and x_fake)  76] [G 0.48, acc. (on x_fake)  11]\n",
            "56957/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.46, acc. (on x_fake)  13]\n",
            "56958/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.48, acc. (on x_fake)  10]\n",
            "56959/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)  13]\n",
            "56960/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)  12]\n",
            "56961/60000 [D 0.20, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)  10]\n",
            "56962/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   5]\n",
            "56963/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.49, acc. (on x_fake)  12]\n",
            "56964/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.49, acc. (on x_fake)   8]\n",
            "56965/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)   9]\n",
            "56966/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.50, acc. (on x_fake)   8]\n",
            "56967/60000 [D 0.18, acc. (on x_real and x_fake)  78] [G 0.46, acc. (on x_fake)  12]\n",
            "56968/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.47, acc. (on x_fake)  10]\n",
            "56969/60000 [D 0.18, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)  14]\n",
            "56970/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.50, acc. (on x_fake)   4]\n",
            "56971/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)   9]\n",
            "56972/60000 [D 0.16, acc. (on x_real and x_fake)  79] [G 0.47, acc. (on x_fake)   9]\n",
            "56973/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.48, acc. (on x_fake)  12]\n",
            "56974/60000 [D 0.17, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)  10]\n",
            "56975/60000 [D 0.17, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)  10]\n",
            "56976/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)   6]\n",
            "56977/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)  10]\n",
            "56978/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.48, acc. (on x_fake)  12]\n",
            "56979/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  16]\n",
            "56980/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.49, acc. (on x_fake)  11]\n",
            "56981/60000 [D 0.16, acc. (on x_real and x_fake)  79] [G 0.52, acc. (on x_fake)   8]\n",
            "56982/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   9]\n",
            "56983/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.49, acc. (on x_fake)   9]\n",
            "56984/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.51, acc. (on x_fake)   6]\n",
            "56985/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.45, acc. (on x_fake)  16]\n",
            "56986/60000 [D 0.19, acc. (on x_real and x_fake)  68] [G 0.52, acc. (on x_fake)   6]\n",
            "56987/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.46, acc. (on x_fake)  13]\n",
            "56988/60000 [D 0.16, acc. (on x_real and x_fake)  80] [G 0.52, acc. (on x_fake)   6]\n",
            "56989/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)   9]\n",
            "56990/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)  10]\n",
            "56991/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)   9]\n",
            "56992/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.50, acc. (on x_fake)  10]\n",
            "56993/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.45, acc. (on x_fake)  12]\n",
            "56994/60000 [D 0.20, acc. (on x_real and x_fake)  70] [G 0.44, acc. (on x_fake)  12]\n",
            "56995/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.48, acc. (on x_fake)   9]\n",
            "56996/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)  12]\n",
            "56997/60000 [D 0.18, acc. (on x_real and x_fake)  77] [G 0.45, acc. (on x_fake)  14]\n",
            "56998/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  14]\n",
            "56999/60000 [D 0.20, acc. (on x_real and x_fake)  67] [G 0.46, acc. (on x_fake)  11]\n",
            "57000/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.48, acc. (on x_fake)  12]\n",
            "57001/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.49, acc. (on x_fake)   5]\n",
            "57002/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  10]\n",
            "57003/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.52, acc. (on x_fake)   6]\n",
            "57004/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.50, acc. (on x_fake)   9]\n",
            "57005/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   7]\n",
            "57006/60000 [D 0.18, acc. (on x_real and x_fake)  78] [G 0.46, acc. (on x_fake)  14]\n",
            "57007/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)  12]\n",
            "57008/60000 [D 0.21, acc. (on x_real and x_fake)  70] [G 0.44, acc. (on x_fake)  16]\n",
            "57009/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.46, acc. (on x_fake)  11]\n",
            "57010/60000 [D 0.19, acc. (on x_real and x_fake)  76] [G 0.44, acc. (on x_fake)  12]\n",
            "57011/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)   8]\n",
            "57012/60000 [D 0.18, acc. (on x_real and x_fake)  77] [G 0.48, acc. (on x_fake)  11]\n",
            "57013/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.45, acc. (on x_fake)  15]\n",
            "57014/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.51, acc. (on x_fake)   7]\n",
            "57015/60000 [D 0.20, acc. (on x_real and x_fake)  67] [G 0.44, acc. (on x_fake)  20]\n",
            "57016/60000 [D 0.20, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)   9]\n",
            "57017/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)  11]\n",
            "57018/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.46, acc. (on x_fake)  12]\n",
            "57019/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.46, acc. (on x_fake)  12]\n",
            "57020/60000 [D 0.17, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)  19]\n",
            "57021/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.51, acc. (on x_fake)  10]\n",
            "57022/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  11]\n",
            "57023/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.45, acc. (on x_fake)  12]\n",
            "57024/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.51, acc. (on x_fake)   8]\n",
            "57025/60000 [D 0.16, acc. (on x_real and x_fake)  78] [G 0.48, acc. (on x_fake)  11]\n",
            "57026/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)  12]\n",
            "57027/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.52, acc. (on x_fake)  11]\n",
            "57028/60000 [D 0.22, acc. (on x_real and x_fake)  63] [G 0.44, acc. (on x_fake)  16]\n",
            "57029/60000 [D 0.17, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)  11]\n",
            "57030/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.46, acc. (on x_fake)  10]\n",
            "57031/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  11]\n",
            "57032/60000 [D 0.22, acc. (on x_real and x_fake)  63] [G 0.46, acc. (on x_fake)  15]\n",
            "57033/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.49, acc. (on x_fake)  11]\n",
            "57034/60000 [D 0.20, acc. (on x_real and x_fake)  66] [G 0.48, acc. (on x_fake)   6]\n",
            "57035/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)  10]\n",
            "57036/60000 [D 0.15, acc. (on x_real and x_fake)  81] [G 0.50, acc. (on x_fake)   9]\n",
            "57037/60000 [D 0.16, acc. (on x_real and x_fake)  79] [G 0.49, acc. (on x_fake)  11]\n",
            "57038/60000 [D 0.16, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  12]\n",
            "57039/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  15]\n",
            "57040/60000 [D 0.18, acc. (on x_real and x_fake)  70] [G 0.50, acc. (on x_fake)   6]\n",
            "57041/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)  14]\n",
            "57042/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.46, acc. (on x_fake)  12]\n",
            "57043/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.50, acc. (on x_fake)   9]\n",
            "57044/60000 [D 0.20, acc. (on x_real and x_fake)  66] [G 0.48, acc. (on x_fake)   9]\n",
            "57045/60000 [D 0.16, acc. (on x_real and x_fake)  79] [G 0.48, acc. (on x_fake)  11]\n",
            "57046/60000 [D 0.20, acc. (on x_real and x_fake)  67] [G 0.44, acc. (on x_fake)  13]\n",
            "57047/60000 [D 0.17, acc. (on x_real and x_fake)  79] [G 0.47, acc. (on x_fake)  13]\n",
            "57048/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.44, acc. (on x_fake)  13]\n",
            "57049/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.45, acc. (on x_fake)  11]\n",
            "57050/60000 [D 0.20, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)  16]\n",
            "57051/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.47, acc. (on x_fake)   8]\n",
            "57052/60000 [D 0.18, acc. (on x_real and x_fake)  69] [G 0.50, acc. (on x_fake)   5]\n",
            "57053/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.45, acc. (on x_fake)  12]\n",
            "57054/60000 [D 0.18, acc. (on x_real and x_fake)  69] [G 0.46, acc. (on x_fake)  16]\n",
            "57055/60000 [D 0.15, acc. (on x_real and x_fake)  79] [G 0.48, acc. (on x_fake)  13]\n",
            "57056/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  17]\n",
            "57057/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.49, acc. (on x_fake)  12]\n",
            "57058/60000 [D 0.17, acc. (on x_real and x_fake)  73] [G 0.46, acc. (on x_fake)  16]\n",
            "57059/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.47, acc. (on x_fake)   9]\n",
            "57060/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)   7]\n",
            "57061/60000 [D 0.20, acc. (on x_real and x_fake)  70] [G 0.44, acc. (on x_fake)  16]\n",
            "57062/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.48, acc. (on x_fake)   7]\n",
            "57063/60000 [D 0.21, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)  11]\n",
            "57064/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.52, acc. (on x_fake)  10]\n",
            "57065/60000 [D 0.18, acc. (on x_real and x_fake)  77] [G 0.48, acc. (on x_fake)   7]\n",
            "57066/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.46, acc. (on x_fake)   8]\n",
            "57067/60000 [D 0.20, acc. (on x_real and x_fake)  68] [G 0.44, acc. (on x_fake)  12]\n",
            "57068/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)  13]\n",
            "57069/60000 [D 0.21, acc. (on x_real and x_fake)  70] [G 0.46, acc. (on x_fake)  14]\n",
            "57070/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)  15]\n",
            "57071/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.46, acc. (on x_fake)  11]\n",
            "57072/60000 [D 0.20, acc. (on x_real and x_fake)  70] [G 0.46, acc. (on x_fake)  13]\n",
            "57073/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.47, acc. (on x_fake)  14]\n",
            "57074/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.47, acc. (on x_fake)  12]\n",
            "57075/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)  10]\n",
            "57076/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  12]\n",
            "57077/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.48, acc. (on x_fake)   7]\n",
            "57078/60000 [D 0.15, acc. (on x_real and x_fake)  81] [G 0.50, acc. (on x_fake)   9]\n",
            "57079/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.47, acc. (on x_fake)  11]\n",
            "57080/60000 [D 0.16, acc. (on x_real and x_fake)  76] [G 0.46, acc. (on x_fake)  18]\n",
            "57081/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.49, acc. (on x_fake)  11]\n",
            "57082/60000 [D 0.16, acc. (on x_real and x_fake)  79] [G 0.51, acc. (on x_fake)   6]\n",
            "57083/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.50, acc. (on x_fake)   9]\n",
            "57084/60000 [D 0.16, acc. (on x_real and x_fake)  78] [G 0.48, acc. (on x_fake)   6]\n",
            "57085/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)   7]\n",
            "57086/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.48, acc. (on x_fake)   9]\n",
            "57087/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)   7]\n",
            "57088/60000 [D 0.20, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)  11]\n",
            "57089/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)   9]\n",
            "57090/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)   9]\n",
            "57091/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.46, acc. (on x_fake)  12]\n",
            "57092/60000 [D 0.16, acc. (on x_real and x_fake)  80] [G 0.51, acc. (on x_fake)   4]\n",
            "57093/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.45, acc. (on x_fake)  14]\n",
            "57094/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.46, acc. (on x_fake)  16]\n",
            "57095/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  12]\n",
            "57096/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.44, acc. (on x_fake)  16]\n",
            "57097/60000 [D 0.21, acc. (on x_real and x_fake)  66] [G 0.47, acc. (on x_fake)  13]\n",
            "57098/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.49, acc. (on x_fake)  10]\n",
            "57099/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)   9]\n",
            "57100/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)  13]\n",
            "57101/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.50, acc. (on x_fake)   8]\n",
            "57102/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  13]\n",
            "57103/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)  13]\n",
            "57104/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)   6]\n",
            "57105/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.51, acc. (on x_fake)   5]\n",
            "57106/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)   9]\n",
            "57107/60000 [D 0.16, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   7]\n",
            "57108/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.47, acc. (on x_fake)  13]\n",
            "57109/60000 [D 0.16, acc. (on x_real and x_fake)  76] [G 0.48, acc. (on x_fake)  14]\n",
            "57110/60000 [D 0.20, acc. (on x_real and x_fake)  70] [G 0.46, acc. (on x_fake)  16]\n",
            "57111/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)  11]\n",
            "57112/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.48, acc. (on x_fake)  10]\n",
            "57113/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.45, acc. (on x_fake)  16]\n",
            "57114/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.46, acc. (on x_fake)  10]\n",
            "57115/60000 [D 0.21, acc. (on x_real and x_fake)  69] [G 0.44, acc. (on x_fake)  11]\n",
            "57116/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.46, acc. (on x_fake)  11]\n",
            "57117/60000 [D 0.19, acc. (on x_real and x_fake)  68] [G 0.48, acc. (on x_fake)  12]\n",
            "57118/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)  12]\n",
            "57119/60000 [D 0.20, acc. (on x_real and x_fake)  70] [G 0.46, acc. (on x_fake)  14]\n",
            "57120/60000 [D 0.18, acc. (on x_real and x_fake)  69] [G 0.49, acc. (on x_fake)   7]\n",
            "57121/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  11]\n",
            "57122/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.46, acc. (on x_fake)  10]\n",
            "57123/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  12]\n",
            "57124/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.50, acc. (on x_fake)   8]\n",
            "57125/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)   9]\n",
            "57126/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)  14]\n",
            "57127/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)  15]\n",
            "57128/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)  12]\n",
            "57129/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.47, acc. (on x_fake)   8]\n",
            "57130/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  17]\n",
            "57131/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.50, acc. (on x_fake)   9]\n",
            "57132/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.45, acc. (on x_fake)  17]\n",
            "57133/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  12]\n",
            "57134/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.44, acc. (on x_fake)  13]\n",
            "57135/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  11]\n",
            "57136/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)  13]\n",
            "57137/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.45, acc. (on x_fake)   9]\n",
            "57138/60000 [D 0.16, acc. (on x_real and x_fake)  78] [G 0.47, acc. (on x_fake)  11]\n",
            "57139/60000 [D 0.20, acc. (on x_real and x_fake)  68] [G 0.50, acc. (on x_fake)   8]\n",
            "57140/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.45, acc. (on x_fake)   8]\n",
            "57141/60000 [D 0.16, acc. (on x_real and x_fake)  80] [G 0.49, acc. (on x_fake)  10]\n",
            "57142/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.48, acc. (on x_fake)  10]\n",
            "57143/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.51, acc. (on x_fake)   5]\n",
            "57144/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)   9]\n",
            "57145/60000 [D 0.18, acc. (on x_real and x_fake)  69] [G 0.46, acc. (on x_fake)  17]\n",
            "57146/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)  14]\n",
            "57147/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  11]\n",
            "57148/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.50, acc. (on x_fake)   6]\n",
            "57149/60000 [D 0.20, acc. (on x_real and x_fake)  70] [G 0.48, acc. (on x_fake)   8]\n",
            "57150/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.51, acc. (on x_fake)   6]\n",
            "57151/60000 [D 0.20, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  11]\n",
            "57152/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.50, acc. (on x_fake)  12]\n",
            "57153/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.52, acc. (on x_fake)  10]\n",
            "57154/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)  10]\n",
            "57155/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.47, acc. (on x_fake)   7]\n",
            "57156/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)   8]\n",
            "57157/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  12]\n",
            "57158/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)  15]\n",
            "57159/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)  13]\n",
            "57160/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.45, acc. (on x_fake)  12]\n",
            "57161/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.48, acc. (on x_fake)   9]\n",
            "57162/60000 [D 0.19, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)  13]\n",
            "57163/60000 [D 0.20, acc. (on x_real and x_fake)  68] [G 0.47, acc. (on x_fake)  14]\n",
            "57164/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.46, acc. (on x_fake)  12]\n",
            "57165/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.46, acc. (on x_fake)  14]\n",
            "57166/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.46, acc. (on x_fake)  10]\n",
            "57167/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.45, acc. (on x_fake)  15]\n",
            "57168/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.47, acc. (on x_fake)   6]\n",
            "57169/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.51, acc. (on x_fake)  13]\n",
            "57170/60000 [D 0.20, acc. (on x_real and x_fake)  66] [G 0.48, acc. (on x_fake)   9]\n",
            "57171/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.49, acc. (on x_fake)   9]\n",
            "57172/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.45, acc. (on x_fake)  14]\n",
            "57173/60000 [D 0.16, acc. (on x_real and x_fake)  81] [G 0.51, acc. (on x_fake)  10]\n",
            "57174/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.45, acc. (on x_fake)  13]\n",
            "57175/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)   7]\n",
            "57176/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)   9]\n",
            "57177/60000 [D 0.17, acc. (on x_real and x_fake)  73] [G 0.46, acc. (on x_fake)  14]\n",
            "57178/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.44, acc. (on x_fake)  18]\n",
            "57179/60000 [D 0.20, acc. (on x_real and x_fake)  68] [G 0.48, acc. (on x_fake)  11]\n",
            "57180/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.51, acc. (on x_fake)   9]\n",
            "57181/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.51, acc. (on x_fake)   7]\n",
            "57182/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.51, acc. (on x_fake)   8]\n",
            "57183/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)   7]\n",
            "57184/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.49, acc. (on x_fake)   8]\n",
            "57185/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  10]\n",
            "57186/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.50, acc. (on x_fake)  10]\n",
            "57187/60000 [D 0.20, acc. (on x_real and x_fake)  70] [G 0.50, acc. (on x_fake)   9]\n",
            "57188/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.49, acc. (on x_fake)  10]\n",
            "57189/60000 [D 0.18, acc. (on x_real and x_fake)  77] [G 0.45, acc. (on x_fake)  11]\n",
            "57190/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)   7]\n",
            "57191/60000 [D 0.16, acc. (on x_real and x_fake)  77] [G 0.50, acc. (on x_fake)   7]\n",
            "57192/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)   9]\n",
            "57193/60000 [D 0.18, acc. (on x_real and x_fake)  70] [G 0.46, acc. (on x_fake)  11]\n",
            "57194/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  16]\n",
            "57195/60000 [D 0.18, acc. (on x_real and x_fake)  70] [G 0.49, acc. (on x_fake)   9]\n",
            "57196/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.48, acc. (on x_fake)   6]\n",
            "57197/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)  11]\n",
            "57198/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)   8]\n",
            "57199/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   9]\n",
            "57200/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)   8]\n",
            "57201/60000 [D 0.20, acc. (on x_real and x_fake)  71] [G 0.46, acc. (on x_fake)  12]\n",
            "57202/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.48, acc. (on x_fake)  11]\n",
            "57203/60000 [D 0.20, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)   9]\n",
            "57204/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.47, acc. (on x_fake)  14]\n",
            "57205/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.49, acc. (on x_fake)  10]\n",
            "57206/60000 [D 0.17, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)  13]\n",
            "57207/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.44, acc. (on x_fake)  13]\n",
            "57208/60000 [D 0.20, acc. (on x_real and x_fake)  71] [G 0.46, acc. (on x_fake)  12]\n",
            "57209/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)  12]\n",
            "57210/60000 [D 0.16, acc. (on x_real and x_fake)  78] [G 0.48, acc. (on x_fake)  10]\n",
            "57211/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  12]\n",
            "57212/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)  12]\n",
            "57213/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.46, acc. (on x_fake)  15]\n",
            "57214/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.45, acc. (on x_fake)  12]\n",
            "57215/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.42, acc. (on x_fake)  18]\n",
            "57216/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.46, acc. (on x_fake)  10]\n",
            "57217/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.48, acc. (on x_fake)  10]\n",
            "57218/60000 [D 0.19, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  10]\n",
            "57219/60000 [D 0.17, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)   8]\n",
            "57220/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.46, acc. (on x_fake)  14]\n",
            "57221/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.50, acc. (on x_fake)   5]\n",
            "57222/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)  12]\n",
            "57223/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.48, acc. (on x_fake)   9]\n",
            "57224/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.48, acc. (on x_fake)   8]\n",
            "57225/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)   6]\n",
            "57226/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)   7]\n",
            "57227/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.52, acc. (on x_fake)   5]\n",
            "57228/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)   7]\n",
            "57229/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.47, acc. (on x_fake)  10]\n",
            "57230/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)  12]\n",
            "57231/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   6]\n",
            "57232/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)   8]\n",
            "57233/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.50, acc. (on x_fake)   7]\n",
            "57234/60000 [D 0.18, acc. (on x_real and x_fake)  77] [G 0.49, acc. (on x_fake)   7]\n",
            "57235/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  13]\n",
            "57236/60000 [D 0.17, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  15]\n",
            "57237/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)   9]\n",
            "57238/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  11]\n",
            "57239/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)   8]\n",
            "57240/60000 [D 0.15, acc. (on x_real and x_fake)  82] [G 0.50, acc. (on x_fake)   8]\n",
            "57241/60000 [D 0.19, acc. (on x_real and x_fake)  68] [G 0.47, acc. (on x_fake)  13]\n",
            "57242/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.50, acc. (on x_fake)   9]\n",
            "57243/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)   7]\n",
            "57244/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.45, acc. (on x_fake)   9]\n",
            "57245/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  10]\n",
            "57246/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.47, acc. (on x_fake)  11]\n",
            "57247/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.49, acc. (on x_fake)   9]\n",
            "57248/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)   8]\n",
            "57249/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  10]\n",
            "57250/60000 [D 0.16, acc. (on x_real and x_fake)  77] [G 0.46, acc. (on x_fake)  14]\n",
            "57251/60000 [D 0.16, acc. (on x_real and x_fake)  77] [G 0.51, acc. (on x_fake)   5]\n",
            "57252/60000 [D 0.16, acc. (on x_real and x_fake)  79] [G 0.52, acc. (on x_fake)   9]\n",
            "57253/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.51, acc. (on x_fake)   7]\n",
            "57254/60000 [D 0.18, acc. (on x_real and x_fake)  70] [G 0.51, acc. (on x_fake)  13]\n",
            "57255/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)   9]\n",
            "57256/60000 [D 0.20, acc. (on x_real and x_fake)  67] [G 0.47, acc. (on x_fake)  10]\n",
            "57257/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.51, acc. (on x_fake)  12]\n",
            "57258/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.47, acc. (on x_fake)  12]\n",
            "57259/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)  15]\n",
            "57260/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)  10]\n",
            "57261/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)  10]\n",
            "57262/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)  13]\n",
            "57263/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  13]\n",
            "57264/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.49, acc. (on x_fake)  13]\n",
            "57265/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.46, acc. (on x_fake)  14]\n",
            "57266/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)  13]\n",
            "57267/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)   9]\n",
            "57268/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.48, acc. (on x_fake)  14]\n",
            "57269/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.46, acc. (on x_fake)   8]\n",
            "57270/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.44, acc. (on x_fake)  13]\n",
            "57271/60000 [D 0.21, acc. (on x_real and x_fake)  63] [G 0.46, acc. (on x_fake)  11]\n",
            "57272/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  13]\n",
            "57273/60000 [D 0.18, acc. (on x_real and x_fake)  77] [G 0.47, acc. (on x_fake)   7]\n",
            "57274/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)   8]\n",
            "57275/60000 [D 0.20, acc. (on x_real and x_fake)  65] [G 0.46, acc. (on x_fake)   6]\n",
            "57276/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  10]\n",
            "57277/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.46, acc. (on x_fake)   8]\n",
            "57278/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.45, acc. (on x_fake)  14]\n",
            "57279/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.46, acc. (on x_fake)  10]\n",
            "57280/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.46, acc. (on x_fake)  15]\n",
            "57281/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)  10]\n",
            "57282/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.50, acc. (on x_fake)  11]\n",
            "57283/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)  15]\n",
            "57284/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)   8]\n",
            "57285/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.46, acc. (on x_fake)  11]\n",
            "57286/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.47, acc. (on x_fake)  10]\n",
            "57287/60000 [D 0.17, acc. (on x_real and x_fake)  73] [G 0.50, acc. (on x_fake)  10]\n",
            "57288/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)  10]\n",
            "57289/60000 [D 0.19, acc. (on x_real and x_fake)  68] [G 0.44, acc. (on x_fake)  13]\n",
            "57290/60000 [D 0.17, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)   9]\n",
            "57291/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.46, acc. (on x_fake)  10]\n",
            "57292/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)  14]\n",
            "57293/60000 [D 0.16, acc. (on x_real and x_fake)  80] [G 0.50, acc. (on x_fake)   7]\n",
            "57294/60000 [D 0.20, acc. (on x_real and x_fake)  72] [G 0.51, acc. (on x_fake)   8]\n",
            "57295/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.45, acc. (on x_fake)  16]\n",
            "57296/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  12]\n",
            "57297/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.46, acc. (on x_fake)  12]\n",
            "57298/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.46, acc. (on x_fake)  15]\n",
            "57299/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.49, acc. (on x_fake)   8]\n",
            "57300/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)  10]\n",
            "57301/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  12]\n",
            "57302/60000 [D 0.20, acc. (on x_real and x_fake)  68] [G 0.47, acc. (on x_fake)  14]\n",
            "57303/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)  12]\n",
            "57304/60000 [D 0.18, acc. (on x_real and x_fake)  77] [G 0.48, acc. (on x_fake)   9]\n",
            "57305/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.46, acc. (on x_fake)  11]\n",
            "57306/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)   5]\n",
            "57307/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  11]\n",
            "57308/60000 [D 0.18, acc. (on x_real and x_fake)  77] [G 0.47, acc. (on x_fake)   9]\n",
            "57309/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)  10]\n",
            "57310/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  15]\n",
            "57311/60000 [D 0.18, acc. (on x_real and x_fake)  70] [G 0.45, acc. (on x_fake)  20]\n",
            "57312/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  13]\n",
            "57313/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.50, acc. (on x_fake)  11]\n",
            "57314/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.50, acc. (on x_fake)  12]\n",
            "57315/60000 [D 0.20, acc. (on x_real and x_fake)  68] [G 0.47, acc. (on x_fake)  16]\n",
            "57316/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.50, acc. (on x_fake)   9]\n",
            "57317/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)   8]\n",
            "57318/60000 [D 0.19, acc. (on x_real and x_fake)  76] [G 0.47, acc. (on x_fake)  12]\n",
            "57319/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.47, acc. (on x_fake)  13]\n",
            "57320/60000 [D 0.21, acc. (on x_real and x_fake)  67] [G 0.44, acc. (on x_fake)  13]\n",
            "57321/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.46, acc. (on x_fake)  18]\n",
            "57322/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  14]\n",
            "57323/60000 [D 0.20, acc. (on x_real and x_fake)  68] [G 0.45, acc. (on x_fake)  19]\n",
            "57324/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.46, acc. (on x_fake)  16]\n",
            "57325/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.50, acc. (on x_fake)  11]\n",
            "57326/60000 [D 0.19, acc. (on x_real and x_fake)  68] [G 0.48, acc. (on x_fake)   6]\n",
            "57327/60000 [D 0.22, acc. (on x_real and x_fake)  63] [G 0.47, acc. (on x_fake)  13]\n",
            "57328/60000 [D 0.18, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)  11]\n",
            "57329/60000 [D 0.21, acc. (on x_real and x_fake)  67] [G 0.45, acc. (on x_fake)  16]\n",
            "57330/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   8]\n",
            "57331/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)   8]\n",
            "57332/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  15]\n",
            "57333/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  10]\n",
            "57334/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.50, acc. (on x_fake)  10]\n",
            "57335/60000 [D 0.16, acc. (on x_real and x_fake)  75] [G 0.53, acc. (on x_fake)   8]\n",
            "57336/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.45, acc. (on x_fake)  14]\n",
            "57337/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.50, acc. (on x_fake)   6]\n",
            "57338/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.50, acc. (on x_fake)   6]\n",
            "57339/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.50, acc. (on x_fake)   8]\n",
            "57340/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.51, acc. (on x_fake)   6]\n",
            "57341/60000 [D 0.20, acc. (on x_real and x_fake)  68] [G 0.50, acc. (on x_fake)  10]\n",
            "57342/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.48, acc. (on x_fake)  11]\n",
            "57343/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)   8]\n",
            "57344/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.45, acc. (on x_fake)  18]\n",
            "57345/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)   6]\n",
            "57346/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.46, acc. (on x_fake)  12]\n",
            "57347/60000 [D 0.20, acc. (on x_real and x_fake)  72] [G 0.45, acc. (on x_fake)   9]\n",
            "57348/60000 [D 0.18, acc. (on x_real and x_fake)  77] [G 0.47, acc. (on x_fake)  12]\n",
            "57349/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)  13]\n",
            "57350/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  14]\n",
            "57351/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.49, acc. (on x_fake)  11]\n",
            "57352/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.48, acc. (on x_fake)  12]\n",
            "57353/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.46, acc. (on x_fake)  16]\n",
            "57354/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)   8]\n",
            "57355/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.50, acc. (on x_fake)   4]\n",
            "57356/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.49, acc. (on x_fake)   9]\n",
            "57357/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)  12]\n",
            "57358/60000 [D 0.19, acc. (on x_real and x_fake)  68] [G 0.48, acc. (on x_fake)   8]\n",
            "57359/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.50, acc. (on x_fake)   5]\n",
            "57360/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.44, acc. (on x_fake)  13]\n",
            "57361/60000 [D 0.17, acc. (on x_real and x_fake)  79] [G 0.48, acc. (on x_fake)   7]\n",
            "57362/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)  13]\n",
            "57363/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)   9]\n",
            "57364/60000 [D 0.16, acc. (on x_real and x_fake)  78] [G 0.49, acc. (on x_fake)   8]\n",
            "57365/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.44, acc. (on x_fake)  20]\n",
            "57366/60000 [D 0.18, acc. (on x_real and x_fake)  70] [G 0.49, acc. (on x_fake)   9]\n",
            "57367/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.49, acc. (on x_fake)   7]\n",
            "57368/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.49, acc. (on x_fake)   9]\n",
            "57369/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   7]\n",
            "57370/60000 [D 0.21, acc. (on x_real and x_fake)  64] [G 0.47, acc. (on x_fake)  12]\n",
            "57371/60000 [D 0.17, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)  10]\n",
            "57372/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)   7]\n",
            "57373/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)   9]\n",
            "57374/60000 [D 0.18, acc. (on x_real and x_fake)  69] [G 0.49, acc. (on x_fake)   7]\n",
            "57375/60000 [D 0.21, acc. (on x_real and x_fake)  71] [G 0.45, acc. (on x_fake)  10]\n",
            "57376/60000 [D 0.20, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)   7]\n",
            "57377/60000 [D 0.20, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)   9]\n",
            "57378/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.48, acc. (on x_fake)   6]\n",
            "57379/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.45, acc. (on x_fake)  13]\n",
            "57380/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.45, acc. (on x_fake)  15]\n",
            "57381/60000 [D 0.20, acc. (on x_real and x_fake)  68] [G 0.48, acc. (on x_fake)  15]\n",
            "57382/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)   8]\n",
            "57383/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.48, acc. (on x_fake)   7]\n",
            "57384/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.46, acc. (on x_fake)  14]\n",
            "57385/60000 [D 0.21, acc. (on x_real and x_fake)  66] [G 0.50, acc. (on x_fake)   9]\n",
            "57386/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.46, acc. (on x_fake)  11]\n",
            "57387/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)   6]\n",
            "57388/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.44, acc. (on x_fake)  16]\n",
            "57389/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.46, acc. (on x_fake)  10]\n",
            "57390/60000 [D 0.17, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)   8]\n",
            "57391/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)  10]\n",
            "57392/60000 [D 0.17, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  12]\n",
            "57393/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)  15]\n",
            "57394/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)   8]\n",
            "57395/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.47, acc. (on x_fake)   8]\n",
            "57396/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  13]\n",
            "57397/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.45, acc. (on x_fake)  15]\n",
            "57398/60000 [D 0.20, acc. (on x_real and x_fake)  68] [G 0.47, acc. (on x_fake)  14]\n",
            "57399/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.47, acc. (on x_fake)   7]\n",
            "57400/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)  11]\n",
            "57401/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.51, acc. (on x_fake)   7]\n",
            "57402/60000 [D 0.16, acc. (on x_real and x_fake)  78] [G 0.49, acc. (on x_fake)   9]\n",
            "57403/60000 [D 0.17, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)  10]\n",
            "57404/60000 [D 0.20, acc. (on x_real and x_fake)  71] [G 0.46, acc. (on x_fake)  14]\n",
            "57405/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)   8]\n",
            "57406/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)  12]\n",
            "57407/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.49, acc. (on x_fake)   6]\n",
            "57408/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)   9]\n",
            "57409/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)   9]\n",
            "57410/60000 [D 0.20, acc. (on x_real and x_fake)  66] [G 0.47, acc. (on x_fake)   9]\n",
            "57411/60000 [D 0.17, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)  17]\n",
            "57412/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.49, acc. (on x_fake)  12]\n",
            "57413/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)   7]\n",
            "57414/60000 [D 0.17, acc. (on x_real and x_fake)  73] [G 0.52, acc. (on x_fake)   9]\n",
            "57415/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.46, acc. (on x_fake)   9]\n",
            "57416/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)  17]\n",
            "57417/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  14]\n",
            "57418/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)  11]\n",
            "57419/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)  11]\n",
            "57420/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  16]\n",
            "57421/60000 [D 0.20, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  14]\n",
            "57422/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)   8]\n",
            "57423/60000 [D 0.20, acc. (on x_real and x_fake)  66] [G 0.49, acc. (on x_fake)  11]\n",
            "57424/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.45, acc. (on x_fake)  11]\n",
            "57425/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)  11]\n",
            "57426/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)  17]\n",
            "57427/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)  10]\n",
            "57428/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.49, acc. (on x_fake)  10]\n",
            "57429/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.49, acc. (on x_fake)   8]\n",
            "57430/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  10]\n",
            "57431/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)  11]\n",
            "57432/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)  16]\n",
            "57433/60000 [D 0.16, acc. (on x_real and x_fake)  77] [G 0.47, acc. (on x_fake)  10]\n",
            "57434/60000 [D 0.18, acc. (on x_real and x_fake)  77] [G 0.49, acc. (on x_fake)  11]\n",
            "57435/60000 [D 0.18, acc. (on x_real and x_fake)  70] [G 0.49, acc. (on x_fake)  11]\n",
            "57436/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.51, acc. (on x_fake)   7]\n",
            "57437/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.50, acc. (on x_fake)   9]\n",
            "57438/60000 [D 0.18, acc. (on x_real and x_fake)  70] [G 0.50, acc. (on x_fake)   7]\n",
            "57439/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  10]\n",
            "57440/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.51, acc. (on x_fake)   6]\n",
            "57441/60000 [D 0.16, acc. (on x_real and x_fake)  77] [G 0.51, acc. (on x_fake)   7]\n",
            "57442/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)  15]\n",
            "57443/60000 [D 0.20, acc. (on x_real and x_fake)  68] [G 0.50, acc. (on x_fake)   8]\n",
            "57444/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)  10]\n",
            "57445/60000 [D 0.16, acc. (on x_real and x_fake)  77] [G 0.48, acc. (on x_fake)   9]\n",
            "57446/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.47, acc. (on x_fake)   9]\n",
            "57447/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)   1]\n",
            "57448/60000 [D 0.17, acc. (on x_real and x_fake)  81] [G 0.50, acc. (on x_fake)  10]\n",
            "57449/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.47, acc. (on x_fake)   9]\n",
            "57450/60000 [D 0.17, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)   9]\n",
            "57451/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.47, acc. (on x_fake)   6]\n",
            "57452/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.47, acc. (on x_fake)  10]\n",
            "57453/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  10]\n",
            "57454/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)   7]\n",
            "57455/60000 [D 0.18, acc. (on x_real and x_fake)  69] [G 0.50, acc. (on x_fake)  10]\n",
            "57456/60000 [D 0.21, acc. (on x_real and x_fake)  65] [G 0.44, acc. (on x_fake)  15]\n",
            "57457/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)  13]\n",
            "57458/60000 [D 0.18, acc. (on x_real and x_fake)  78] [G 0.48, acc. (on x_fake)  12]\n",
            "57459/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.45, acc. (on x_fake)  14]\n",
            "57460/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)   6]\n",
            "57461/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)  10]\n",
            "57462/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)  11]\n",
            "57463/60000 [D 0.21, acc. (on x_real and x_fake)  67] [G 0.45, acc. (on x_fake)  14]\n",
            "57464/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)  10]\n",
            "57465/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.45, acc. (on x_fake)  14]\n",
            "57466/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.51, acc. (on x_fake)  10]\n",
            "57467/60000 [D 0.20, acc. (on x_real and x_fake)  71] [G 0.42, acc. (on x_fake)  17]\n",
            "57468/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.43, acc. (on x_fake)  22]\n",
            "57469/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)   8]\n",
            "57470/60000 [D 0.18, acc. (on x_real and x_fake)  70] [G 0.48, acc. (on x_fake)   4]\n",
            "57471/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.46, acc. (on x_fake)  12]\n",
            "57472/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  16]\n",
            "57473/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)  11]\n",
            "57474/60000 [D 0.20, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  13]\n",
            "57475/60000 [D 0.16, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)   9]\n",
            "57476/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.44, acc. (on x_fake)  17]\n",
            "57477/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.47, acc. (on x_fake)  13]\n",
            "57478/60000 [D 0.17, acc. (on x_real and x_fake)  80] [G 0.49, acc. (on x_fake)  13]\n",
            "57479/60000 [D 0.16, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)   9]\n",
            "57480/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.52, acc. (on x_fake)   4]\n",
            "57481/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.50, acc. (on x_fake)   9]\n",
            "57482/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)   9]\n",
            "57483/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  12]\n",
            "57484/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.51, acc. (on x_fake)   6]\n",
            "57485/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)  15]\n",
            "57486/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.51, acc. (on x_fake)   4]\n",
            "57487/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)   8]\n",
            "57488/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.45, acc. (on x_fake)  10]\n",
            "57489/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   9]\n",
            "57490/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.50, acc. (on x_fake)  12]\n",
            "57491/60000 [D 0.20, acc. (on x_real and x_fake)  68] [G 0.44, acc. (on x_fake)  14]\n",
            "57492/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  14]\n",
            "57493/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  13]\n",
            "57494/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)   8]\n",
            "57495/60000 [D 0.17, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  10]\n",
            "57496/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)   8]\n",
            "57497/60000 [D 0.18, acc. (on x_real and x_fake)  70] [G 0.46, acc. (on x_fake)  11]\n",
            "57498/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.51, acc. (on x_fake)   4]\n",
            "57499/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   7]\n",
            "57500/60000 [D 0.16, acc. (on x_real and x_fake)  77] [G 0.44, acc. (on x_fake)  12]\n",
            "57501/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)   9]\n",
            "57502/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  11]\n",
            "57503/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  12]\n",
            "57504/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  13]\n",
            "57505/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.51, acc. (on x_fake)  10]\n",
            "57506/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.47, acc. (on x_fake)   8]\n",
            "57507/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.48, acc. (on x_fake)   9]\n",
            "57508/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)   7]\n",
            "57509/60000 [D 0.16, acc. (on x_real and x_fake)  77] [G 0.50, acc. (on x_fake)  12]\n",
            "57510/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.46, acc. (on x_fake)  12]\n",
            "57511/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)   8]\n",
            "57512/60000 [D 0.21, acc. (on x_real and x_fake)  63] [G 0.44, acc. (on x_fake)  13]\n",
            "57513/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)  10]\n",
            "57514/60000 [D 0.19, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  15]\n",
            "57515/60000 [D 0.20, acc. (on x_real and x_fake)  70] [G 0.46, acc. (on x_fake)   9]\n",
            "57516/60000 [D 0.16, acc. (on x_real and x_fake)  81] [G 0.52, acc. (on x_fake)   3]\n",
            "57517/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.47, acc. (on x_fake)  10]\n",
            "57518/60000 [D 0.18, acc. (on x_real and x_fake)  70] [G 0.46, acc. (on x_fake)  10]\n",
            "57519/60000 [D 0.18, acc. (on x_real and x_fake)  70] [G 0.48, acc. (on x_fake)  10]\n",
            "57520/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)  12]\n",
            "57521/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.51, acc. (on x_fake)   9]\n",
            "57522/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.46, acc. (on x_fake)  11]\n",
            "57523/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)  10]\n",
            "57524/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)   7]\n",
            "57525/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.45, acc. (on x_fake)  16]\n",
            "57526/60000 [D 0.20, acc. (on x_real and x_fake)  71] [G 0.47, acc. (on x_fake)  14]\n",
            "57527/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)   9]\n",
            "57528/60000 [D 0.17, acc. (on x_real and x_fake)  79] [G 0.51, acc. (on x_fake)   5]\n",
            "57529/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.50, acc. (on x_fake)  13]\n",
            "57530/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)  15]\n",
            "57531/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)   8]\n",
            "57532/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)   8]\n",
            "57533/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.51, acc. (on x_fake)  10]\n",
            "57534/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)   9]\n",
            "57535/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)   8]\n",
            "57536/60000 [D 0.16, acc. (on x_real and x_fake)  78] [G 0.48, acc. (on x_fake)  11]\n",
            "57537/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.50, acc. (on x_fake)  11]\n",
            "57538/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  11]\n",
            "57539/60000 [D 0.17, acc. (on x_real and x_fake)  72] [G 0.50, acc. (on x_fake)  11]\n",
            "57540/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.46, acc. (on x_fake)  16]\n",
            "57541/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.50, acc. (on x_fake)   9]\n",
            "57542/60000 [D 0.16, acc. (on x_real and x_fake)  79] [G 0.50, acc. (on x_fake)  11]\n",
            "57543/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)   9]\n",
            "57544/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.49, acc. (on x_fake)   9]\n",
            "57545/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.47, acc. (on x_fake)  14]\n",
            "57546/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.43, acc. (on x_fake)  12]\n",
            "57547/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)   9]\n",
            "57548/60000 [D 0.21, acc. (on x_real and x_fake)  67] [G 0.46, acc. (on x_fake)  13]\n",
            "57549/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.50, acc. (on x_fake)  13]\n",
            "57550/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)  13]\n",
            "57551/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)   8]\n",
            "57552/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.46, acc. (on x_fake)  14]\n",
            "57553/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)  10]\n",
            "57554/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)  10]\n",
            "57555/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.46, acc. (on x_fake)   8]\n",
            "57556/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)   8]\n",
            "57557/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.46, acc. (on x_fake)   9]\n",
            "57558/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.48, acc. (on x_fake)   9]\n",
            "57559/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  14]\n",
            "57560/60000 [D 0.16, acc. (on x_real and x_fake)  81] [G 0.52, acc. (on x_fake)   5]\n",
            "57561/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)   7]\n",
            "57562/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  13]\n",
            "57563/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.50, acc. (on x_fake)  10]\n",
            "57564/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)  15]\n",
            "57565/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)   9]\n",
            "57566/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.45, acc. (on x_fake)  12]\n",
            "57567/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  11]\n",
            "57568/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.47, acc. (on x_fake)  13]\n",
            "57569/60000 [D 0.16, acc. (on x_real and x_fake)  78] [G 0.50, acc. (on x_fake)   3]\n",
            "57570/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.45, acc. (on x_fake)  17]\n",
            "57571/60000 [D 0.18, acc. (on x_real and x_fake)  77] [G 0.47, acc. (on x_fake)  11]\n",
            "57572/60000 [D 0.19, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   9]\n",
            "57573/60000 [D 0.16, acc. (on x_real and x_fake)  77] [G 0.50, acc. (on x_fake)   9]\n",
            "57574/60000 [D 0.20, acc. (on x_real and x_fake)  70] [G 0.51, acc. (on x_fake)   7]\n",
            "57575/60000 [D 0.16, acc. (on x_real and x_fake)  79] [G 0.51, acc. (on x_fake)  11]\n",
            "57576/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.52, acc. (on x_fake)   8]\n",
            "57577/60000 [D 0.20, acc. (on x_real and x_fake)  70] [G 0.45, acc. (on x_fake)  12]\n",
            "57578/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.45, acc. (on x_fake)  17]\n",
            "57579/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  10]\n",
            "57580/60000 [D 0.20, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)  11]\n",
            "57581/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)  13]\n",
            "57582/60000 [D 0.20, acc. (on x_real and x_fake)  70] [G 0.46, acc. (on x_fake)  17]\n",
            "57583/60000 [D 0.18, acc. (on x_real and x_fake)  77] [G 0.48, acc. (on x_fake)   8]\n",
            "57584/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.46, acc. (on x_fake)  13]\n",
            "57585/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)  10]\n",
            "57586/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.49, acc. (on x_fake)  10]\n",
            "57587/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.46, acc. (on x_fake)   6]\n",
            "57588/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.50, acc. (on x_fake)   9]\n",
            "57589/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.45, acc. (on x_fake)  14]\n",
            "57590/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.46, acc. (on x_fake)  14]\n",
            "57591/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.51, acc. (on x_fake)   3]\n",
            "57592/60000 [D 0.19, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  11]\n",
            "57593/60000 [D 0.16, acc. (on x_real and x_fake)  80] [G 0.46, acc. (on x_fake)   9]\n",
            "57594/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  15]\n",
            "57595/60000 [D 0.20, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)  13]\n",
            "57596/60000 [D 0.18, acc. (on x_real and x_fake)  70] [G 0.50, acc. (on x_fake)   6]\n",
            "57597/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)   6]\n",
            "57598/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)  11]\n",
            "57599/60000 [D 0.20, acc. (on x_real and x_fake)  71] [G 0.45, acc. (on x_fake)  12]\n",
            "57600/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.50, acc. (on x_fake)   7]\n",
            "57601/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)   9]\n",
            "57602/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)   9]\n",
            "57603/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.45, acc. (on x_fake)   8]\n",
            "57604/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.49, acc. (on x_fake)   8]\n",
            "57605/60000 [D 0.16, acc. (on x_real and x_fake)  78] [G 0.51, acc. (on x_fake)   7]\n",
            "57606/60000 [D 0.16, acc. (on x_real and x_fake)  79] [G 0.49, acc. (on x_fake)  11]\n",
            "57607/60000 [D 0.21, acc. (on x_real and x_fake)  66] [G 0.46, acc. (on x_fake)  19]\n",
            "57608/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)  13]\n",
            "57609/60000 [D 0.19, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  12]\n",
            "57610/60000 [D 0.21, acc. (on x_real and x_fake)  64] [G 0.45, acc. (on x_fake)  12]\n",
            "57611/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)  11]\n",
            "57612/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)  11]\n",
            "57613/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)   9]\n",
            "57614/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  12]\n",
            "57615/60000 [D 0.16, acc. (on x_real and x_fake)  77] [G 0.50, acc. (on x_fake)  14]\n",
            "57616/60000 [D 0.16, acc. (on x_real and x_fake)  77] [G 0.48, acc. (on x_fake)  12]\n",
            "57617/60000 [D 0.21, acc. (on x_real and x_fake)  70] [G 0.46, acc. (on x_fake)  14]\n",
            "57618/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.51, acc. (on x_fake)   9]\n",
            "57619/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.49, acc. (on x_fake)  12]\n",
            "57620/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)  12]\n",
            "57621/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)   5]\n",
            "57622/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.52, acc. (on x_fake)   6]\n",
            "57623/60000 [D 0.20, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  10]\n",
            "57624/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.47, acc. (on x_fake)   8]\n",
            "57625/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)  10]\n",
            "57626/60000 [D 0.20, acc. (on x_real and x_fake)  72] [G 0.45, acc. (on x_fake)  20]\n",
            "57627/60000 [D 0.20, acc. (on x_real and x_fake)  67] [G 0.45, acc. (on x_fake)  12]\n",
            "57628/60000 [D 0.16, acc. (on x_real and x_fake)  79] [G 0.49, acc. (on x_fake)   6]\n",
            "57629/60000 [D 0.16, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   7]\n",
            "57630/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)  11]\n",
            "57631/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  14]\n",
            "57632/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  13]\n",
            "57633/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.46, acc. (on x_fake)  10]\n",
            "57634/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)   9]\n",
            "57635/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)   8]\n",
            "57636/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.50, acc. (on x_fake)   7]\n",
            "57637/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)  15]\n",
            "57638/60000 [D 0.17, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  14]\n",
            "57639/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  11]\n",
            "57640/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.51, acc. (on x_fake)   6]\n",
            "57641/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.51, acc. (on x_fake)   7]\n",
            "57642/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.46, acc. (on x_fake)  18]\n",
            "57643/60000 [D 0.17, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)   9]\n",
            "57644/60000 [D 0.21, acc. (on x_real and x_fake)  66] [G 0.42, acc. (on x_fake)  14]\n",
            "57645/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.48, acc. (on x_fake)   4]\n",
            "57646/60000 [D 0.20, acc. (on x_real and x_fake)  68] [G 0.47, acc. (on x_fake)  12]\n",
            "57647/60000 [D 0.16, acc. (on x_real and x_fake)  78] [G 0.49, acc. (on x_fake)   9]\n",
            "57648/60000 [D 0.18, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)  10]\n",
            "57649/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.46, acc. (on x_fake)  12]\n",
            "57650/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)   9]\n",
            "57651/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)  13]\n",
            "57652/60000 [D 0.20, acc. (on x_real and x_fake)  67] [G 0.45, acc. (on x_fake)  21]\n",
            "57653/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  10]\n",
            "57654/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.52, acc. (on x_fake)   7]\n",
            "57655/60000 [D 0.20, acc. (on x_real and x_fake)  67] [G 0.46, acc. (on x_fake)  13]\n",
            "57656/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.50, acc. (on x_fake)   5]\n",
            "57657/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)  10]\n",
            "57658/60000 [D 0.17, acc. (on x_real and x_fake)  71] [G 0.51, acc. (on x_fake)   7]\n",
            "57659/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.51, acc. (on x_fake)  10]\n",
            "57660/60000 [D 0.20, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  10]\n",
            "57661/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)   7]\n",
            "57662/60000 [D 0.19, acc. (on x_real and x_fake)  75] [G 0.46, acc. (on x_fake)  14]\n",
            "57663/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.45, acc. (on x_fake)  15]\n",
            "57664/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.51, acc. (on x_fake)   2]\n",
            "57665/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.46, acc. (on x_fake)  12]\n",
            "57666/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.50, acc. (on x_fake)  10]\n",
            "57667/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.46, acc. (on x_fake)  13]\n",
            "57668/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)   9]\n",
            "57669/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.49, acc. (on x_fake)   6]\n",
            "57670/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  15]\n",
            "57671/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)  15]\n",
            "57672/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.49, acc. (on x_fake)  13]\n",
            "57673/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  16]\n",
            "57674/60000 [D 0.16, acc. (on x_real and x_fake)  78] [G 0.53, acc. (on x_fake)   7]\n",
            "57675/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)   9]\n",
            "57676/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)  13]\n",
            "57677/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.49, acc. (on x_fake)  11]\n",
            "57678/60000 [D 0.17, acc. (on x_real and x_fake)  73] [G 0.50, acc. (on x_fake)   9]\n",
            "57679/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)  10]\n",
            "57680/60000 [D 0.18, acc. (on x_real and x_fake)  70] [G 0.48, acc. (on x_fake)  14]\n",
            "57681/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  11]\n",
            "57682/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)  10]\n",
            "57683/60000 [D 0.20, acc. (on x_real and x_fake)  71] [G 0.47, acc. (on x_fake)  12]\n",
            "57684/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)  12]\n",
            "57685/60000 [D 0.20, acc. (on x_real and x_fake)  66] [G 0.43, acc. (on x_fake)  15]\n",
            "57686/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)   8]\n",
            "57687/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)   9]\n",
            "57688/60000 [D 0.18, acc. (on x_real and x_fake)  78] [G 0.48, acc. (on x_fake)   9]\n",
            "57689/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.46, acc. (on x_fake)  15]\n",
            "57690/60000 [D 0.17, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)  14]\n",
            "57691/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.48, acc. (on x_fake)  12]\n",
            "57692/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.45, acc. (on x_fake)  17]\n",
            "57693/60000 [D 0.16, acc. (on x_real and x_fake)  78] [G 0.52, acc. (on x_fake)   7]\n",
            "57694/60000 [D 0.16, acc. (on x_real and x_fake)  77] [G 0.48, acc. (on x_fake)  10]\n",
            "57695/60000 [D 0.18, acc. (on x_real and x_fake)  78] [G 0.47, acc. (on x_fake)  13]\n",
            "57696/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.50, acc. (on x_fake)   9]\n",
            "57697/60000 [D 0.21, acc. (on x_real and x_fake)  68] [G 0.44, acc. (on x_fake)  15]\n",
            "57698/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.45, acc. (on x_fake)  16]\n",
            "57699/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)  10]\n",
            "57700/60000 [D 0.16, acc. (on x_real and x_fake)  78] [G 0.48, acc. (on x_fake)   9]\n",
            "57701/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)  10]\n",
            "57702/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.46, acc. (on x_fake)  14]\n",
            "57703/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.45, acc. (on x_fake)  22]\n",
            "57704/60000 [D 0.16, acc. (on x_real and x_fake)  74] [G 0.52, acc. (on x_fake)   8]\n",
            "57705/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)   5]\n",
            "57706/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.50, acc. (on x_fake)  10]\n",
            "57707/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)  13]\n",
            "57708/60000 [D 0.16, acc. (on x_real and x_fake)  80] [G 0.49, acc. (on x_fake)  10]\n",
            "57709/60000 [D 0.21, acc. (on x_real and x_fake)  66] [G 0.49, acc. (on x_fake)   9]\n",
            "57710/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.50, acc. (on x_fake)  10]\n",
            "57711/60000 [D 0.20, acc. (on x_real and x_fake)  68] [G 0.48, acc. (on x_fake)  10]\n",
            "57712/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)  12]\n",
            "57713/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)   6]\n",
            "57714/60000 [D 0.19, acc. (on x_real and x_fake)  75] [G 0.45, acc. (on x_fake)   9]\n",
            "57715/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)  10]\n",
            "57716/60000 [D 0.20, acc. (on x_real and x_fake)  71] [G 0.45, acc. (on x_fake)  16]\n",
            "57717/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  12]\n",
            "57718/60000 [D 0.19, acc. (on x_real and x_fake)  75] [G 0.46, acc. (on x_fake)  12]\n",
            "57719/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)  11]\n",
            "57720/60000 [D 0.18, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)  12]\n",
            "57721/60000 [D 0.20, acc. (on x_real and x_fake)  67] [G 0.44, acc. (on x_fake)  16]\n",
            "57722/60000 [D 0.20, acc. (on x_real and x_fake)  67] [G 0.45, acc. (on x_fake)  14]\n",
            "57723/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.54, acc. (on x_fake)   8]\n",
            "57724/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   6]\n",
            "57725/60000 [D 0.19, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)  10]\n",
            "57726/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  13]\n",
            "57727/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)   8]\n",
            "57728/60000 [D 0.18, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)   9]\n",
            "57729/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)  14]\n",
            "57730/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.45, acc. (on x_fake)  12]\n",
            "57731/60000 [D 0.20, acc. (on x_real and x_fake)  71] [G 0.47, acc. (on x_fake)   9]\n",
            "57732/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)  11]\n",
            "57733/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.46, acc. (on x_fake)  12]\n",
            "57734/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.46, acc. (on x_fake)  11]\n",
            "57735/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)  13]\n",
            "57736/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.46, acc. (on x_fake)  11]\n",
            "57737/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  11]\n",
            "57738/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)   7]\n",
            "57739/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)   8]\n",
            "57740/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.50, acc. (on x_fake)   8]\n",
            "57741/60000 [D 0.20, acc. (on x_real and x_fake)  71] [G 0.44, acc. (on x_fake)  13]\n",
            "57742/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)  10]\n",
            "57743/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.50, acc. (on x_fake)  10]\n",
            "57744/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)   8]\n",
            "57745/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.48, acc. (on x_fake)   8]\n",
            "57746/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)   9]\n",
            "57747/60000 [D 0.17, acc. (on x_real and x_fake)  73] [G 0.50, acc. (on x_fake)   6]\n",
            "57748/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)   8]\n",
            "57749/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.50, acc. (on x_fake)   8]\n",
            "57750/60000 [D 0.22, acc. (on x_real and x_fake)  66] [G 0.42, acc. (on x_fake)  12]\n",
            "57751/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.45, acc. (on x_fake)  18]\n",
            "57752/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  12]\n",
            "57753/60000 [D 0.16, acc. (on x_real and x_fake)  78] [G 0.52, acc. (on x_fake)  11]\n",
            "57754/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  13]\n",
            "57755/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)  11]\n",
            "57756/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)   7]\n",
            "57757/60000 [D 0.16, acc. (on x_real and x_fake)  78] [G 0.46, acc. (on x_fake)  10]\n",
            "57758/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.48, acc. (on x_fake)   9]\n",
            "57759/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.44, acc. (on x_fake)  14]\n",
            "57760/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.47, acc. (on x_fake)  15]\n",
            "57761/60000 [D 0.17, acc. (on x_real and x_fake)  79] [G 0.45, acc. (on x_fake)   9]\n",
            "57762/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  11]\n",
            "57763/60000 [D 0.20, acc. (on x_real and x_fake)  68] [G 0.46, acc. (on x_fake)  15]\n",
            "57764/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  15]\n",
            "57765/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)  14]\n",
            "57766/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)   6]\n",
            "57767/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.51, acc. (on x_fake)   9]\n",
            "57768/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)  11]\n",
            "57769/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  11]\n",
            "57770/60000 [D 0.18, acc. (on x_real and x_fake)  69] [G 0.49, acc. (on x_fake)  11]\n",
            "57771/60000 [D 0.20, acc. (on x_real and x_fake)  68] [G 0.45, acc. (on x_fake)  14]\n",
            "57772/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.46, acc. (on x_fake)  15]\n",
            "57773/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.46, acc. (on x_fake)  16]\n",
            "57774/60000 [D 0.17, acc. (on x_real and x_fake)  73] [G 0.50, acc. (on x_fake)  10]\n",
            "57775/60000 [D 0.19, acc. (on x_real and x_fake)  76] [G 0.47, acc. (on x_fake)  11]\n",
            "57776/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  15]\n",
            "57777/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.46, acc. (on x_fake)  13]\n",
            "57778/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  10]\n",
            "57779/60000 [D 0.15, acc. (on x_real and x_fake)  84] [G 0.49, acc. (on x_fake)   5]\n",
            "57780/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  15]\n",
            "57781/60000 [D 0.16, acc. (on x_real and x_fake)  76] [G 0.48, acc. (on x_fake)   5]\n",
            "57782/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)  10]\n",
            "57783/60000 [D 0.20, acc. (on x_real and x_fake)  70] [G 0.46, acc. (on x_fake)  12]\n",
            "57784/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  16]\n",
            "57785/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  16]\n",
            "57786/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  11]\n",
            "57787/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.47, acc. (on x_fake)  11]\n",
            "57788/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)  12]\n",
            "57789/60000 [D 0.17, acc. (on x_real and x_fake)  79] [G 0.52, acc. (on x_fake)   9]\n",
            "57790/60000 [D 0.20, acc. (on x_real and x_fake)  70] [G 0.48, acc. (on x_fake)   8]\n",
            "57791/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.50, acc. (on x_fake)   6]\n",
            "57792/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.49, acc. (on x_fake)   8]\n",
            "57793/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.51, acc. (on x_fake)   2]\n",
            "57794/60000 [D 0.20, acc. (on x_real and x_fake)  72] [G 0.45, acc. (on x_fake)  16]\n",
            "57795/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   6]\n",
            "57796/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)   7]\n",
            "57797/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.48, acc. (on x_fake)  10]\n",
            "57798/60000 [D 0.18, acc. (on x_real and x_fake)  78] [G 0.47, acc. (on x_fake)  12]\n",
            "57799/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)  11]\n",
            "57800/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.48, acc. (on x_fake)  10]\n",
            "57801/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)  15]\n",
            "57802/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   8]\n",
            "57803/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.50, acc. (on x_fake)   4]\n",
            "57804/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)  13]\n",
            "57805/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)  10]\n",
            "57806/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.51, acc. (on x_fake)   6]\n",
            "57807/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)   7]\n",
            "57808/60000 [D 0.21, acc. (on x_real and x_fake)  66] [G 0.48, acc. (on x_fake)  14]\n",
            "57809/60000 [D 0.17, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)   9]\n",
            "57810/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)  12]\n",
            "57811/60000 [D 0.20, acc. (on x_real and x_fake)  68] [G 0.48, acc. (on x_fake)  12]\n",
            "57812/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)  12]\n",
            "57813/60000 [D 0.20, acc. (on x_real and x_fake)  66] [G 0.44, acc. (on x_fake)  10]\n",
            "57814/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)   8]\n",
            "57815/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.45, acc. (on x_fake)  13]\n",
            "57816/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)  12]\n",
            "57817/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)   7]\n",
            "57818/60000 [D 0.18, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)  10]\n",
            "57819/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.50, acc. (on x_fake)  10]\n",
            "57820/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)   7]\n",
            "57821/60000 [D 0.18, acc. (on x_real and x_fake)  69] [G 0.50, acc. (on x_fake)   9]\n",
            "57822/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)   9]\n",
            "57823/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.47, acc. (on x_fake)   9]\n",
            "57824/60000 [D 0.19, acc. (on x_real and x_fake)  68] [G 0.47, acc. (on x_fake)  10]\n",
            "57825/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  16]\n",
            "57826/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.52, acc. (on x_fake)   9]\n",
            "57827/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  13]\n",
            "57828/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.53, acc. (on x_fake)   5]\n",
            "57829/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)  11]\n",
            "57830/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  10]\n",
            "57831/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  16]\n",
            "57832/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.47, acc. (on x_fake)  10]\n",
            "57833/60000 [D 0.16, acc. (on x_real and x_fake)  79] [G 0.52, acc. (on x_fake)   5]\n",
            "57834/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)  10]\n",
            "57835/60000 [D 0.20, acc. (on x_real and x_fake)  71] [G 0.46, acc. (on x_fake)  16]\n",
            "57836/60000 [D 0.19, acc. (on x_real and x_fake)  68] [G 0.45, acc. (on x_fake)  15]\n",
            "57837/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.50, acc. (on x_fake)   7]\n",
            "57838/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.48, acc. (on x_fake)   5]\n",
            "57839/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.48, acc. (on x_fake)  15]\n",
            "57840/60000 [D 0.19, acc. (on x_real and x_fake)  68] [G 0.51, acc. (on x_fake)  13]\n",
            "57841/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.48, acc. (on x_fake)  12]\n",
            "57842/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.51, acc. (on x_fake)  11]\n",
            "57843/60000 [D 0.20, acc. (on x_real and x_fake)  73] [G 0.46, acc. (on x_fake)  11]\n",
            "57844/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)   9]\n",
            "57845/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.46, acc. (on x_fake)  13]\n",
            "57846/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)  12]\n",
            "57847/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.46, acc. (on x_fake)  14]\n",
            "57848/60000 [D 0.17, acc. (on x_real and x_fake)  72] [G 0.51, acc. (on x_fake)   7]\n",
            "57849/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.50, acc. (on x_fake)  11]\n",
            "57850/60000 [D 0.20, acc. (on x_real and x_fake)  66] [G 0.48, acc. (on x_fake)  10]\n",
            "57851/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.51, acc. (on x_fake)   8]\n",
            "57852/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)  13]\n",
            "57853/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.45, acc. (on x_fake)  13]\n",
            "57854/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  11]\n",
            "57855/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)  13]\n",
            "57856/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)  10]\n",
            "57857/60000 [D 0.19, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   7]\n",
            "57858/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.50, acc. (on x_fake)   5]\n",
            "57859/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.46, acc. (on x_fake)  19]\n",
            "57860/60000 [D 0.16, acc. (on x_real and x_fake)  73] [G 0.51, acc. (on x_fake)   8]\n",
            "57861/60000 [D 0.18, acc. (on x_real and x_fake)  69] [G 0.49, acc. (on x_fake)   8]\n",
            "57862/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  15]\n",
            "57863/60000 [D 0.20, acc. (on x_real and x_fake)  65] [G 0.43, acc. (on x_fake)  19]\n",
            "57864/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)   8]\n",
            "57865/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)  11]\n",
            "57866/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  14]\n",
            "57867/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  15]\n",
            "57868/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  17]\n",
            "57869/60000 [D 0.18, acc. (on x_real and x_fake)  70] [G 0.49, acc. (on x_fake)  10]\n",
            "57870/60000 [D 0.16, acc. (on x_real and x_fake)  76] [G 0.50, acc. (on x_fake)   9]\n",
            "57871/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  14]\n",
            "57872/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)  11]\n",
            "57873/60000 [D 0.17, acc. (on x_real and x_fake)  79] [G 0.48, acc. (on x_fake)  11]\n",
            "57874/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.50, acc. (on x_fake)  11]\n",
            "57875/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)  12]\n",
            "57876/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)  10]\n",
            "57877/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.50, acc. (on x_fake)   5]\n",
            "57878/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.46, acc. (on x_fake)  15]\n",
            "57879/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.50, acc. (on x_fake)  10]\n",
            "57880/60000 [D 0.20, acc. (on x_real and x_fake)  67] [G 0.48, acc. (on x_fake)   7]\n",
            "57881/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)   8]\n",
            "57882/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.46, acc. (on x_fake)  10]\n",
            "57883/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.49, acc. (on x_fake)   9]\n",
            "57884/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)   7]\n",
            "57885/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.45, acc. (on x_fake)   9]\n",
            "57886/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.50, acc. (on x_fake)  11]\n",
            "57887/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.43, acc. (on x_fake)  14]\n",
            "57888/60000 [D 0.21, acc. (on x_real and x_fake)  68] [G 0.45, acc. (on x_fake)  10]\n",
            "57889/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)  11]\n",
            "57890/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)  12]\n",
            "57891/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  10]\n",
            "57892/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.52, acc. (on x_fake)   5]\n",
            "57893/60000 [D 0.17, acc. (on x_real and x_fake)  71] [G 0.46, acc. (on x_fake)  10]\n",
            "57894/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.49, acc. (on x_fake)   8]\n",
            "57895/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)  10]\n",
            "57896/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.46, acc. (on x_fake)  12]\n",
            "57897/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.53, acc. (on x_fake)   8]\n",
            "57898/60000 [D 0.15, acc. (on x_real and x_fake)  79] [G 0.51, acc. (on x_fake)   9]\n",
            "57899/60000 [D 0.15, acc. (on x_real and x_fake)  79] [G 0.50, acc. (on x_fake)   6]\n",
            "57900/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.51, acc. (on x_fake)   9]\n",
            "57901/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)  13]\n",
            "57902/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   5]\n",
            "57903/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.45, acc. (on x_fake)  16]\n",
            "57904/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.49, acc. (on x_fake)  13]\n",
            "57905/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.48, acc. (on x_fake)  11]\n",
            "57906/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.51, acc. (on x_fake)   8]\n",
            "57907/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)  16]\n",
            "57908/60000 [D 0.16, acc. (on x_real and x_fake)  79] [G 0.46, acc. (on x_fake)  13]\n",
            "57909/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.51, acc. (on x_fake)   8]\n",
            "57910/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.50, acc. (on x_fake)   9]\n",
            "57911/60000 [D 0.16, acc. (on x_real and x_fake)  79] [G 0.52, acc. (on x_fake)   9]\n",
            "57912/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.50, acc. (on x_fake)   7]\n",
            "57913/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.51, acc. (on x_fake)  10]\n",
            "57914/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)  11]\n",
            "57915/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.50, acc. (on x_fake)  12]\n",
            "57916/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.49, acc. (on x_fake)   9]\n",
            "57917/60000 [D 0.20, acc. (on x_real and x_fake)  67] [G 0.48, acc. (on x_fake)  13]\n",
            "57918/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.45, acc. (on x_fake)  18]\n",
            "57919/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)  10]\n",
            "57920/60000 [D 0.19, acc. (on x_real and x_fake)  68] [G 0.48, acc. (on x_fake)  12]\n",
            "57921/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.51, acc. (on x_fake)   7]\n",
            "57922/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)  13]\n",
            "57923/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.50, acc. (on x_fake)   9]\n",
            "57924/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)   7]\n",
            "57925/60000 [D 0.16, acc. (on x_real and x_fake)  79] [G 0.49, acc. (on x_fake)  11]\n",
            "57926/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.50, acc. (on x_fake)   9]\n",
            "57927/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.49, acc. (on x_fake)  10]\n",
            "57928/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  13]\n",
            "57929/60000 [D 0.20, acc. (on x_real and x_fake)  66] [G 0.45, acc. (on x_fake)  22]\n",
            "57930/60000 [D 0.18, acc. (on x_real and x_fake)  78] [G 0.46, acc. (on x_fake)  17]\n",
            "57931/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)  13]\n",
            "57932/60000 [D 0.19, acc. (on x_real and x_fake)  75] [G 0.46, acc. (on x_fake)  13]\n",
            "57933/60000 [D 0.20, acc. (on x_real and x_fake)  70] [G 0.46, acc. (on x_fake)  11]\n",
            "57934/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.46, acc. (on x_fake)  11]\n",
            "57935/60000 [D 0.19, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)   8]\n",
            "57936/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  10]\n",
            "57937/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  12]\n",
            "57938/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)  10]\n",
            "57939/60000 [D 0.20, acc. (on x_real and x_fake)  70] [G 0.46, acc. (on x_fake)  11]\n",
            "57940/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.51, acc. (on x_fake)   8]\n",
            "57941/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  15]\n",
            "57942/60000 [D 0.16, acc. (on x_real and x_fake)  77] [G 0.49, acc. (on x_fake)  10]\n",
            "57943/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.45, acc. (on x_fake)  12]\n",
            "57944/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)  13]\n",
            "57945/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.45, acc. (on x_fake)  11]\n",
            "57946/60000 [D 0.18, acc. (on x_real and x_fake)  70] [G 0.49, acc. (on x_fake)  12]\n",
            "57947/60000 [D 0.18, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)  13]\n",
            "57948/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  13]\n",
            "57949/60000 [D 0.19, acc. (on x_real and x_fake)  67] [G 0.46, acc. (on x_fake)  13]\n",
            "57950/60000 [D 0.18, acc. (on x_real and x_fake)  77] [G 0.46, acc. (on x_fake)   9]\n",
            "57951/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.50, acc. (on x_fake)   7]\n",
            "57952/60000 [D 0.17, acc. (on x_real and x_fake)  73] [G 0.50, acc. (on x_fake)  10]\n",
            "57953/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)  10]\n",
            "57954/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  12]\n",
            "57955/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  12]\n",
            "57956/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)   7]\n",
            "57957/60000 [D 0.19, acc. (on x_real and x_fake)  68] [G 0.47, acc. (on x_fake)  11]\n",
            "57958/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.49, acc. (on x_fake)  11]\n",
            "57959/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)  12]\n",
            "57960/60000 [D 0.19, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  10]\n",
            "57961/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)   9]\n",
            "57962/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.45, acc. (on x_fake)  12]\n",
            "57963/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  13]\n",
            "57964/60000 [D 0.17, acc. (on x_real and x_fake)  73] [G 0.52, acc. (on x_fake)   6]\n",
            "57965/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.46, acc. (on x_fake)  15]\n",
            "57966/60000 [D 0.20, acc. (on x_real and x_fake)  70] [G 0.46, acc. (on x_fake)  11]\n",
            "57967/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)   9]\n",
            "57968/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.45, acc. (on x_fake)  13]\n",
            "57969/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.46, acc. (on x_fake)  12]\n",
            "57970/60000 [D 0.17, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  13]\n",
            "57971/60000 [D 0.20, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  11]\n",
            "57972/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.48, acc. (on x_fake)   8]\n",
            "57973/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   8]\n",
            "57974/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.47, acc. (on x_fake)   9]\n",
            "57975/60000 [D 0.20, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)  10]\n",
            "57976/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.47, acc. (on x_fake)   8]\n",
            "57977/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.50, acc. (on x_fake)  12]\n",
            "57978/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.52, acc. (on x_fake)   7]\n",
            "57979/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.49, acc. (on x_fake)   7]\n",
            "57980/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.49, acc. (on x_fake)   9]\n",
            "57981/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)  11]\n",
            "57982/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.47, acc. (on x_fake)  12]\n",
            "57983/60000 [D 0.21, acc. (on x_real and x_fake)  68] [G 0.49, acc. (on x_fake)   8]\n",
            "57984/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)   6]\n",
            "57985/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   9]\n",
            "57986/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)   9]\n",
            "57987/60000 [D 0.20, acc. (on x_real and x_fake)  68] [G 0.48, acc. (on x_fake)  11]\n",
            "57988/60000 [D 0.20, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)   8]\n",
            "57989/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)   9]\n",
            "57990/60000 [D 0.16, acc. (on x_real and x_fake)  76] [G 0.47, acc. (on x_fake)  12]\n",
            "57991/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)  12]\n",
            "57992/60000 [D 0.18, acc. (on x_real and x_fake)  70] [G 0.51, acc. (on x_fake)   8]\n",
            "57993/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.50, acc. (on x_fake)   6]\n",
            "57994/60000 [D 0.16, acc. (on x_real and x_fake)  77] [G 0.50, acc. (on x_fake)   9]\n",
            "57995/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.45, acc. (on x_fake)  14]\n",
            "57996/60000 [D 0.21, acc. (on x_real and x_fake)  64] [G 0.46, acc. (on x_fake)  11]\n",
            "57997/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)   9]\n",
            "57998/60000 [D 0.21, acc. (on x_real and x_fake)  63] [G 0.48, acc. (on x_fake)  12]\n",
            "57999/60000 [D 0.18, acc. (on x_real and x_fake)  70] [G 0.48, acc. (on x_fake)  10]\n",
            "58000/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  15]\n",
            "58001/60000 [D 0.16, acc. (on x_real and x_fake)  76] [G 0.47, acc. (on x_fake)  17]\n",
            "58002/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.50, acc. (on x_fake)   5]\n",
            "58003/60000 [D 0.18, acc. (on x_real and x_fake)  70] [G 0.46, acc. (on x_fake)  10]\n",
            "58004/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)  11]\n",
            "58005/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.47, acc. (on x_fake)  11]\n",
            "58006/60000 [D 0.19, acc. (on x_real and x_fake)  66] [G 0.45, acc. (on x_fake)  17]\n",
            "58007/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.44, acc. (on x_fake)  19]\n",
            "58008/60000 [D 0.17, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)  14]\n",
            "58009/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  12]\n",
            "58010/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.45, acc. (on x_fake)  16]\n",
            "58011/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)  11]\n",
            "58012/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)  12]\n",
            "58013/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.48, acc. (on x_fake)  11]\n",
            "58014/60000 [D 0.20, acc. (on x_real and x_fake)  67] [G 0.46, acc. (on x_fake)  13]\n",
            "58015/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)  12]\n",
            "58016/60000 [D 0.17, acc. (on x_real and x_fake)  73] [G 0.45, acc. (on x_fake)  12]\n",
            "58017/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)  11]\n",
            "58018/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.46, acc. (on x_fake)  11]\n",
            "58019/60000 [D 0.21, acc. (on x_real and x_fake)  66] [G 0.47, acc. (on x_fake)  13]\n",
            "58020/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.46, acc. (on x_fake)  14]\n",
            "58021/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.50, acc. (on x_fake)   8]\n",
            "58022/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)  12]\n",
            "58023/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  16]\n",
            "58024/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.46, acc. (on x_fake)   9]\n",
            "58025/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.46, acc. (on x_fake)  14]\n",
            "58026/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)  10]\n",
            "58027/60000 [D 0.20, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)   9]\n",
            "58028/60000 [D 0.20, acc. (on x_real and x_fake)  71] [G 0.47, acc. (on x_fake)  13]\n",
            "58029/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.45, acc. (on x_fake)  14]\n",
            "58030/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)   7]\n",
            "58031/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)   9]\n",
            "58032/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)  10]\n",
            "58033/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.46, acc. (on x_fake)  12]\n",
            "58034/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.46, acc. (on x_fake)  16]\n",
            "58035/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)   9]\n",
            "58036/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.50, acc. (on x_fake)   8]\n",
            "58037/60000 [D 0.18, acc. (on x_real and x_fake)  70] [G 0.49, acc. (on x_fake)   6]\n",
            "58038/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)  11]\n",
            "58039/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)  15]\n",
            "58040/60000 [D 0.19, acc. (on x_real and x_fake)  75] [G 0.46, acc. (on x_fake)  10]\n",
            "58041/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)  14]\n",
            "58042/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.46, acc. (on x_fake)  14]\n",
            "58043/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.46, acc. (on x_fake)  13]\n",
            "58044/60000 [D 0.17, acc. (on x_real and x_fake)  79] [G 0.48, acc. (on x_fake)   7]\n",
            "58045/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.50, acc. (on x_fake)   4]\n",
            "58046/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)   9]\n",
            "58047/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.46, acc. (on x_fake)   9]\n",
            "58048/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.50, acc. (on x_fake)   8]\n",
            "58049/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)  12]\n",
            "58050/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.46, acc. (on x_fake)  12]\n",
            "58051/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)   9]\n",
            "58052/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.46, acc. (on x_fake)  15]\n",
            "58053/60000 [D 0.16, acc. (on x_real and x_fake)  78] [G 0.52, acc. (on x_fake)   2]\n",
            "58054/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.45, acc. (on x_fake)  19]\n",
            "58055/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.46, acc. (on x_fake)  17]\n",
            "58056/60000 [D 0.16, acc. (on x_real and x_fake)  77] [G 0.46, acc. (on x_fake)  14]\n",
            "58057/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.47, acc. (on x_fake)  14]\n",
            "58058/60000 [D 0.19, acc. (on x_real and x_fake)  67] [G 0.47, acc. (on x_fake)   9]\n",
            "58059/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.49, acc. (on x_fake)   7]\n",
            "58060/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.49, acc. (on x_fake)  14]\n",
            "58061/60000 [D 0.18, acc. (on x_real and x_fake)  77] [G 0.47, acc. (on x_fake)  11]\n",
            "58062/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.52, acc. (on x_fake)   5]\n",
            "58063/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.48, acc. (on x_fake)  13]\n",
            "58064/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)   9]\n",
            "58065/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.46, acc. (on x_fake)  19]\n",
            "58066/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)  13]\n",
            "58067/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.50, acc. (on x_fake)   7]\n",
            "58068/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  14]\n",
            "58069/60000 [D 0.21, acc. (on x_real and x_fake)  66] [G 0.47, acc. (on x_fake)  10]\n",
            "58070/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.51, acc. (on x_fake)   8]\n",
            "58071/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   9]\n",
            "58072/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  13]\n",
            "58073/60000 [D 0.20, acc. (on x_real and x_fake)  71] [G 0.43, acc. (on x_fake)  15]\n",
            "58074/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  13]\n",
            "58075/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)   9]\n",
            "58076/60000 [D 0.21, acc. (on x_real and x_fake)  66] [G 0.48, acc. (on x_fake)  10]\n",
            "58077/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)  16]\n",
            "58078/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  13]\n",
            "58079/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  10]\n",
            "58080/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)   8]\n",
            "58081/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.47, acc. (on x_fake)  14]\n",
            "58082/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.51, acc. (on x_fake)   7]\n",
            "58083/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  11]\n",
            "58084/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  12]\n",
            "58085/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)  12]\n",
            "58086/60000 [D 0.20, acc. (on x_real and x_fake)  68] [G 0.45, acc. (on x_fake)  13]\n",
            "58087/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   9]\n",
            "58088/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)  10]\n",
            "58089/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  14]\n",
            "58090/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.48, acc. (on x_fake)   9]\n",
            "58091/60000 [D 0.16, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)  12]\n",
            "58092/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  12]\n",
            "58093/60000 [D 0.17, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  13]\n",
            "58094/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.51, acc. (on x_fake)   6]\n",
            "58095/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)  11]\n",
            "58096/60000 [D 0.17, acc. (on x_real and x_fake)  80] [G 0.50, acc. (on x_fake)  11]\n",
            "58097/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.51, acc. (on x_fake)  10]\n",
            "58098/60000 [D 0.20, acc. (on x_real and x_fake)  67] [G 0.49, acc. (on x_fake)  11]\n",
            "58099/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.50, acc. (on x_fake)  11]\n",
            "58100/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)  11]\n",
            "58101/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.48, acc. (on x_fake)  12]\n",
            "58102/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.46, acc. (on x_fake)  13]\n",
            "58103/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)  11]\n",
            "58104/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.48, acc. (on x_fake)  12]\n",
            "58105/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  13]\n",
            "58106/60000 [D 0.15, acc. (on x_real and x_fake)  79] [G 0.49, acc. (on x_fake)  14]\n",
            "58107/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.48, acc. (on x_fake)  10]\n",
            "58108/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)   8]\n",
            "58109/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)  10]\n",
            "58110/60000 [D 0.16, acc. (on x_real and x_fake)  80] [G 0.51, acc. (on x_fake)   9]\n",
            "58111/60000 [D 0.16, acc. (on x_real and x_fake)  78] [G 0.48, acc. (on x_fake)  14]\n",
            "58112/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)  13]\n",
            "58113/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.49, acc. (on x_fake)   7]\n",
            "58114/60000 [D 0.20, acc. (on x_real and x_fake)  70] [G 0.50, acc. (on x_fake)  12]\n",
            "58115/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)   9]\n",
            "58116/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)  12]\n",
            "58117/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.51, acc. (on x_fake)   8]\n",
            "58118/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)  16]\n",
            "58119/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.49, acc. (on x_fake)  10]\n",
            "58120/60000 [D 0.20, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)  10]\n",
            "58121/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.49, acc. (on x_fake)  10]\n",
            "58122/60000 [D 0.15, acc. (on x_real and x_fake)  80] [G 0.53, acc. (on x_fake)   6]\n",
            "58123/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.51, acc. (on x_fake)   8]\n",
            "58124/60000 [D 0.21, acc. (on x_real and x_fake)  66] [G 0.50, acc. (on x_fake)   5]\n",
            "58125/60000 [D 0.18, acc. (on x_real and x_fake)  70] [G 0.48, acc. (on x_fake)  11]\n",
            "58126/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)   9]\n",
            "58127/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)   7]\n",
            "58128/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)   4]\n",
            "58129/60000 [D 0.20, acc. (on x_real and x_fake)  70] [G 0.46, acc. (on x_fake)  17]\n",
            "58130/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)  10]\n",
            "58131/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.50, acc. (on x_fake)   8]\n",
            "58132/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.43, acc. (on x_fake)  16]\n",
            "58133/60000 [D 0.15, acc. (on x_real and x_fake)  78] [G 0.50, acc. (on x_fake)   8]\n",
            "58134/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.46, acc. (on x_fake)  13]\n",
            "58135/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.46, acc. (on x_fake)  12]\n",
            "58136/60000 [D 0.16, acc. (on x_real and x_fake)  78] [G 0.50, acc. (on x_fake)   5]\n",
            "58137/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.50, acc. (on x_fake)   9]\n",
            "58138/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)  14]\n",
            "58139/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   9]\n",
            "58140/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  11]\n",
            "58141/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.48, acc. (on x_fake)   4]\n",
            "58142/60000 [D 0.16, acc. (on x_real and x_fake)  78] [G 0.53, acc. (on x_fake)   4]\n",
            "58143/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.51, acc. (on x_fake)   4]\n",
            "58144/60000 [D 0.15, acc. (on x_real and x_fake)  82] [G 0.48, acc. (on x_fake)  11]\n",
            "58145/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.46, acc. (on x_fake)  16]\n",
            "58146/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  12]\n",
            "58147/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.50, acc. (on x_fake)  11]\n",
            "58148/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.50, acc. (on x_fake)   7]\n",
            "58149/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.48, acc. (on x_fake)  10]\n",
            "58150/60000 [D 0.19, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  13]\n",
            "58151/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)  10]\n",
            "58152/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.51, acc. (on x_fake)   7]\n",
            "58153/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.49, acc. (on x_fake)  12]\n",
            "58154/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)  10]\n",
            "58155/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)   3]\n",
            "58156/60000 [D 0.17, acc. (on x_real and x_fake)  79] [G 0.51, acc. (on x_fake)  10]\n",
            "58157/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.49, acc. (on x_fake)   5]\n",
            "58158/60000 [D 0.20, acc. (on x_real and x_fake)  67] [G 0.49, acc. (on x_fake)  15]\n",
            "58159/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.49, acc. (on x_fake)  10]\n",
            "58160/60000 [D 0.20, acc. (on x_real and x_fake)  67] [G 0.50, acc. (on x_fake)   8]\n",
            "58161/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)  12]\n",
            "58162/60000 [D 0.20, acc. (on x_real and x_fake)  66] [G 0.49, acc. (on x_fake)   4]\n",
            "58163/60000 [D 0.16, acc. (on x_real and x_fake)  79] [G 0.49, acc. (on x_fake)  13]\n",
            "58164/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.49, acc. (on x_fake)  12]\n",
            "58165/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.49, acc. (on x_fake)  11]\n",
            "58166/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.53, acc. (on x_fake)   5]\n",
            "58167/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.50, acc. (on x_fake)   5]\n",
            "58168/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)   9]\n",
            "58169/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)  15]\n",
            "58170/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.46, acc. (on x_fake)  12]\n",
            "58171/60000 [D 0.18, acc. (on x_real and x_fake)  77] [G 0.51, acc. (on x_fake)   3]\n",
            "58172/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.48, acc. (on x_fake)   6]\n",
            "58173/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.48, acc. (on x_fake)  14]\n",
            "58174/60000 [D 0.20, acc. (on x_real and x_fake)  70] [G 0.45, acc. (on x_fake)  13]\n",
            "58175/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)  11]\n",
            "58176/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  12]\n",
            "58177/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)  15]\n",
            "58178/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)   8]\n",
            "58179/60000 [D 0.16, acc. (on x_real and x_fake)  77] [G 0.48, acc. (on x_fake)  14]\n",
            "58180/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.45, acc. (on x_fake)  17]\n",
            "58181/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.45, acc. (on x_fake)  17]\n",
            "58182/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  14]\n",
            "58183/60000 [D 0.18, acc. (on x_real and x_fake)  70] [G 0.46, acc. (on x_fake)   8]\n",
            "58184/60000 [D 0.19, acc. (on x_real and x_fake)  67] [G 0.48, acc. (on x_fake)   9]\n",
            "58185/60000 [D 0.16, acc. (on x_real and x_fake)  78] [G 0.50, acc. (on x_fake)   7]\n",
            "58186/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)  14]\n",
            "58187/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  10]\n",
            "58188/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.46, acc. (on x_fake)  13]\n",
            "58189/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)   8]\n",
            "58190/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)  12]\n",
            "58191/60000 [D 0.16, acc. (on x_real and x_fake)  78] [G 0.48, acc. (on x_fake)   9]\n",
            "58192/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.49, acc. (on x_fake)   9]\n",
            "58193/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)   9]\n",
            "58194/60000 [D 0.17, acc. (on x_real and x_fake)  73] [G 0.46, acc. (on x_fake)  11]\n",
            "58195/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.49, acc. (on x_fake)   9]\n",
            "58196/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  15]\n",
            "58197/60000 [D 0.18, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)  14]\n",
            "58198/60000 [D 0.17, acc. (on x_real and x_fake)  79] [G 0.44, acc. (on x_fake)  12]\n",
            "58199/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  11]\n",
            "58200/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)  12]\n",
            "58201/60000 [D 0.15, acc. (on x_real and x_fake)  81] [G 0.53, acc. (on x_fake)  12]\n",
            "58202/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)   9]\n",
            "58203/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)   6]\n",
            "58204/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  13]\n",
            "58205/60000 [D 0.21, acc. (on x_real and x_fake)  64] [G 0.45, acc. (on x_fake)  18]\n",
            "58206/60000 [D 0.18, acc. (on x_real and x_fake)  70] [G 0.46, acc. (on x_fake)  13]\n",
            "58207/60000 [D 0.19, acc. (on x_real and x_fake)  68] [G 0.48, acc. (on x_fake)  13]\n",
            "58208/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  10]\n",
            "58209/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.48, acc. (on x_fake)  14]\n",
            "58210/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.47, acc. (on x_fake)  11]\n",
            "58211/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.46, acc. (on x_fake)  14]\n",
            "58212/60000 [D 0.20, acc. (on x_real and x_fake)  65] [G 0.47, acc. (on x_fake)  14]\n",
            "58213/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.48, acc. (on x_fake)   9]\n",
            "58214/60000 [D 0.16, acc. (on x_real and x_fake)  78] [G 0.52, acc. (on x_fake)   5]\n",
            "58215/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.48, acc. (on x_fake)   9]\n",
            "58216/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.49, acc. (on x_fake)  16]\n",
            "58217/60000 [D 0.21, acc. (on x_real and x_fake)  66] [G 0.48, acc. (on x_fake)  10]\n",
            "58218/60000 [D 0.20, acc. (on x_real and x_fake)  71] [G 0.46, acc. (on x_fake)  13]\n",
            "58219/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.46, acc. (on x_fake)  14]\n",
            "58220/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)   8]\n",
            "58221/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)   9]\n",
            "58222/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   8]\n",
            "58223/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.51, acc. (on x_fake)  11]\n",
            "58224/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  11]\n",
            "58225/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)  11]\n",
            "58226/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.47, acc. (on x_fake)   9]\n",
            "58227/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  10]\n",
            "58228/60000 [D 0.20, acc. (on x_real and x_fake)  68] [G 0.46, acc. (on x_fake)  12]\n",
            "58229/60000 [D 0.21, acc. (on x_real and x_fake)  67] [G 0.46, acc. (on x_fake)  15]\n",
            "58230/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  13]\n",
            "58231/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)  11]\n",
            "58232/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.46, acc. (on x_fake)  11]\n",
            "58233/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)   6]\n",
            "58234/60000 [D 0.20, acc. (on x_real and x_fake)  66] [G 0.47, acc. (on x_fake)  12]\n",
            "58235/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.49, acc. (on x_fake)  10]\n",
            "58236/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.51, acc. (on x_fake)  10]\n",
            "58237/60000 [D 0.18, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)   5]\n",
            "58238/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.47, acc. (on x_fake)  13]\n",
            "58239/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.49, acc. (on x_fake)  12]\n",
            "58240/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.45, acc. (on x_fake)  18]\n",
            "58241/60000 [D 0.21, acc. (on x_real and x_fake)  67] [G 0.47, acc. (on x_fake)  11]\n",
            "58242/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.48, acc. (on x_fake)   9]\n",
            "58243/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)   9]\n",
            "58244/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.47, acc. (on x_fake)  12]\n",
            "58245/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.50, acc. (on x_fake)  11]\n",
            "58246/60000 [D 0.16, acc. (on x_real and x_fake)  77] [G 0.48, acc. (on x_fake)  13]\n",
            "58247/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.46, acc. (on x_fake)  14]\n",
            "58248/60000 [D 0.18, acc. (on x_real and x_fake)  77] [G 0.44, acc. (on x_fake)  18]\n",
            "58249/60000 [D 0.16, acc. (on x_real and x_fake)  77] [G 0.49, acc. (on x_fake)  14]\n",
            "58250/60000 [D 0.16, acc. (on x_real and x_fake)  78] [G 0.47, acc. (on x_fake)  14]\n",
            "58251/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)   7]\n",
            "58252/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.46, acc. (on x_fake)  13]\n",
            "58253/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.46, acc. (on x_fake)  12]\n",
            "58254/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)  16]\n",
            "58255/60000 [D 0.16, acc. (on x_real and x_fake)  81] [G 0.51, acc. (on x_fake)  14]\n",
            "58256/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)   9]\n",
            "58257/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)   8]\n",
            "58258/60000 [D 0.18, acc. (on x_real and x_fake)  70] [G 0.48, acc. (on x_fake)  12]\n",
            "58259/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.50, acc. (on x_fake)   7]\n",
            "58260/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)  13]\n",
            "58261/60000 [D 0.18, acc. (on x_real and x_fake)  77] [G 0.48, acc. (on x_fake)  10]\n",
            "58262/60000 [D 0.20, acc. (on x_real and x_fake)  66] [G 0.50, acc. (on x_fake)   9]\n",
            "58263/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  11]\n",
            "58264/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)   8]\n",
            "58265/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.45, acc. (on x_fake)  15]\n",
            "58266/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  14]\n",
            "58267/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.50, acc. (on x_fake)   7]\n",
            "58268/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)  12]\n",
            "58269/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.48, acc. (on x_fake)  11]\n",
            "58270/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.48, acc. (on x_fake)   7]\n",
            "58271/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  10]\n",
            "58272/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.51, acc. (on x_fake)   6]\n",
            "58273/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)  10]\n",
            "58274/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.46, acc. (on x_fake)  14]\n",
            "58275/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.46, acc. (on x_fake)  18]\n",
            "58276/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.46, acc. (on x_fake)  16]\n",
            "58277/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)   8]\n",
            "58278/60000 [D 0.17, acc. (on x_real and x_fake)  73] [G 0.52, acc. (on x_fake)  10]\n",
            "58279/60000 [D 0.16, acc. (on x_real and x_fake)  78] [G 0.50, acc. (on x_fake)   7]\n",
            "58280/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)  10]\n",
            "58281/60000 [D 0.22, acc. (on x_real and x_fake)  62] [G 0.46, acc. (on x_fake)  13]\n",
            "58282/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)   7]\n",
            "58283/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  11]\n",
            "58284/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  12]\n",
            "58285/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)   9]\n",
            "58286/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.45, acc. (on x_fake)   9]\n",
            "58287/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)   8]\n",
            "58288/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)   6]\n",
            "58289/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.43, acc. (on x_fake)  16]\n",
            "58290/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)  10]\n",
            "58291/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.45, acc. (on x_fake)  14]\n",
            "58292/60000 [D 0.20, acc. (on x_real and x_fake)  70] [G 0.43, acc. (on x_fake)  16]\n",
            "58293/60000 [D 0.18, acc. (on x_real and x_fake)  70] [G 0.45, acc. (on x_fake)  12]\n",
            "58294/60000 [D 0.17, acc. (on x_real and x_fake)  79] [G 0.48, acc. (on x_fake)  13]\n",
            "58295/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)   9]\n",
            "58296/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)  11]\n",
            "58297/60000 [D 0.18, acc. (on x_real and x_fake)  70] [G 0.46, acc. (on x_fake)   9]\n",
            "58298/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.50, acc. (on x_fake)   7]\n",
            "58299/60000 [D 0.17, acc. (on x_real and x_fake)  79] [G 0.46, acc. (on x_fake)  14]\n",
            "58300/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.46, acc. (on x_fake)   8]\n",
            "58301/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.50, acc. (on x_fake)  12]\n",
            "58302/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)   9]\n",
            "58303/60000 [D 0.15, acc. (on x_real and x_fake)  79] [G 0.52, acc. (on x_fake)   7]\n",
            "58304/60000 [D 0.15, acc. (on x_real and x_fake)  81] [G 0.51, acc. (on x_fake)   4]\n",
            "58305/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.51, acc. (on x_fake)  11]\n",
            "58306/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.44, acc. (on x_fake)  19]\n",
            "58307/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)  13]\n",
            "58308/60000 [D 0.19, acc. (on x_real and x_fake)  75] [G 0.44, acc. (on x_fake)  17]\n",
            "58309/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)   8]\n",
            "58310/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.47, acc. (on x_fake)  15]\n",
            "58311/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)  11]\n",
            "58312/60000 [D 0.16, acc. (on x_real and x_fake)  75] [G 0.51, acc. (on x_fake)   6]\n",
            "58313/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.46, acc. (on x_fake)   9]\n",
            "58314/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)   8]\n",
            "58315/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)   9]\n",
            "58316/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.50, acc. (on x_fake)  10]\n",
            "58317/60000 [D 0.16, acc. (on x_real and x_fake)  79] [G 0.47, acc. (on x_fake)  13]\n",
            "58318/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.46, acc. (on x_fake)   9]\n",
            "58319/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.50, acc. (on x_fake)   8]\n",
            "58320/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.49, acc. (on x_fake)  12]\n",
            "58321/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.48, acc. (on x_fake)   6]\n",
            "58322/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)   6]\n",
            "58323/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.46, acc. (on x_fake)  15]\n",
            "58324/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  14]\n",
            "58325/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  14]\n",
            "58326/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  11]\n",
            "58327/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.48, acc. (on x_fake)   9]\n",
            "58328/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.46, acc. (on x_fake)   7]\n",
            "58329/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)  17]\n",
            "58330/60000 [D 0.19, acc. (on x_real and x_fake)  68] [G 0.46, acc. (on x_fake)  17]\n",
            "58331/60000 [D 0.17, acc. (on x_real and x_fake)  79] [G 0.48, acc. (on x_fake)  11]\n",
            "58332/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)  13]\n",
            "58333/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)   9]\n",
            "58334/60000 [D 0.21, acc. (on x_real and x_fake)  66] [G 0.45, acc. (on x_fake)  18]\n",
            "58335/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)   7]\n",
            "58336/60000 [D 0.19, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)  13]\n",
            "58337/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.47, acc. (on x_fake)  14]\n",
            "58338/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.47, acc. (on x_fake)  11]\n",
            "58339/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.48, acc. (on x_fake)  12]\n",
            "58340/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.48, acc. (on x_fake)  10]\n",
            "58341/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)   4]\n",
            "58342/60000 [D 0.18, acc. (on x_real and x_fake)  78] [G 0.44, acc. (on x_fake)  15]\n",
            "58343/60000 [D 0.20, acc. (on x_real and x_fake)  70] [G 0.46, acc. (on x_fake)   9]\n",
            "58344/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.47, acc. (on x_fake)  12]\n",
            "58345/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.47, acc. (on x_fake)  11]\n",
            "58346/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.46, acc. (on x_fake)  13]\n",
            "58347/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.51, acc. (on x_fake)   3]\n",
            "58348/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  11]\n",
            "58349/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  13]\n",
            "58350/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.48, acc. (on x_fake)   8]\n",
            "58351/60000 [D 0.17, acc. (on x_real and x_fake)  79] [G 0.47, acc. (on x_fake)  10]\n",
            "58352/60000 [D 0.17, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)   9]\n",
            "58353/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  10]\n",
            "58354/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.50, acc. (on x_fake)   8]\n",
            "58355/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)   7]\n",
            "58356/60000 [D 0.16, acc. (on x_real and x_fake)  81] [G 0.48, acc. (on x_fake)   8]\n",
            "58357/60000 [D 0.17, acc. (on x_real and x_fake)  70] [G 0.51, acc. (on x_fake)   7]\n",
            "58358/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  10]\n",
            "58359/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.51, acc. (on x_fake)   6]\n",
            "58360/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)  12]\n",
            "58361/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.53, acc. (on x_fake)   7]\n",
            "58362/60000 [D 0.20, acc. (on x_real and x_fake)  68] [G 0.48, acc. (on x_fake)  10]\n",
            "58363/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)   8]\n",
            "58364/60000 [D 0.19, acc. (on x_real and x_fake)  67] [G 0.47, acc. (on x_fake)  14]\n",
            "58365/60000 [D 0.18, acc. (on x_real and x_fake)  78] [G 0.49, acc. (on x_fake)   7]\n",
            "58366/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.47, acc. (on x_fake)  14]\n",
            "58367/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)   9]\n",
            "58368/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  13]\n",
            "58369/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.42, acc. (on x_fake)  17]\n",
            "58370/60000 [D 0.20, acc. (on x_real and x_fake)  72] [G 0.43, acc. (on x_fake)  12]\n",
            "58371/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)  10]\n",
            "58372/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.49, acc. (on x_fake)   8]\n",
            "58373/60000 [D 0.20, acc. (on x_real and x_fake)  68] [G 0.48, acc. (on x_fake)  11]\n",
            "58374/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.46, acc. (on x_fake)  20]\n",
            "58375/60000 [D 0.17, acc. (on x_real and x_fake)  79] [G 0.51, acc. (on x_fake)  10]\n",
            "58376/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.48, acc. (on x_fake)  10]\n",
            "58377/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)   7]\n",
            "58378/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  12]\n",
            "58379/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.49, acc. (on x_fake)  11]\n",
            "58380/60000 [D 0.16, acc. (on x_real and x_fake)  78] [G 0.48, acc. (on x_fake)  14]\n",
            "58381/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)  12]\n",
            "58382/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.49, acc. (on x_fake)   6]\n",
            "58383/60000 [D 0.16, acc. (on x_real and x_fake)  79] [G 0.50, acc. (on x_fake)   5]\n",
            "58384/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)   7]\n",
            "58385/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.44, acc. (on x_fake)  20]\n",
            "58386/60000 [D 0.17, acc. (on x_real and x_fake)  73] [G 0.46, acc. (on x_fake)   9]\n",
            "58387/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  13]\n",
            "58388/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.46, acc. (on x_fake)  15]\n",
            "58389/60000 [D 0.19, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)   8]\n",
            "58390/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  17]\n",
            "58391/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.49, acc. (on x_fake)  12]\n",
            "58392/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.46, acc. (on x_fake)   9]\n",
            "58393/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)  10]\n",
            "58394/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.45, acc. (on x_fake)  12]\n",
            "58395/60000 [D 0.18, acc. (on x_real and x_fake)  77] [G 0.46, acc. (on x_fake)  12]\n",
            "58396/60000 [D 0.20, acc. (on x_real and x_fake)  71] [G 0.47, acc. (on x_fake)   8]\n",
            "58397/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.47, acc. (on x_fake)   8]\n",
            "58398/60000 [D 0.20, acc. (on x_real and x_fake)  70] [G 0.49, acc. (on x_fake)   8]\n",
            "58399/60000 [D 0.18, acc. (on x_real and x_fake)  70] [G 0.49, acc. (on x_fake)  12]\n",
            "58400/60000 [D 0.19, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   9]\n",
            "58401/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)  13]\n",
            "58402/60000 [D 0.20, acc. (on x_real and x_fake)  71] [G 0.43, acc. (on x_fake)  15]\n",
            "58403/60000 [D 0.16, acc. (on x_real and x_fake)  79] [G 0.52, acc. (on x_fake)   5]\n",
            "58404/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)   9]\n",
            "58405/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  13]\n",
            "58406/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.49, acc. (on x_fake)   9]\n",
            "58407/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.51, acc. (on x_fake)  10]\n",
            "58408/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.49, acc. (on x_fake)  10]\n",
            "58409/60000 [D 0.20, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)   5]\n",
            "58410/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  11]\n",
            "58411/60000 [D 0.17, acc. (on x_real and x_fake)  70] [G 0.50, acc. (on x_fake)   6]\n",
            "58412/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)  13]\n",
            "58413/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)  10]\n",
            "58414/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)  10]\n",
            "58415/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)   7]\n",
            "58416/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)   9]\n",
            "58417/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  10]\n",
            "58418/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.45, acc. (on x_fake)  18]\n",
            "58419/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)   7]\n",
            "58420/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.46, acc. (on x_fake)  19]\n",
            "58421/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  13]\n",
            "58422/60000 [D 0.16, acc. (on x_real and x_fake)  76] [G 0.49, acc. (on x_fake)   9]\n",
            "58423/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)  13]\n",
            "58424/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.50, acc. (on x_fake)   7]\n",
            "58425/60000 [D 0.15, acc. (on x_real and x_fake)  78] [G 0.49, acc. (on x_fake)   8]\n",
            "58426/60000 [D 0.20, acc. (on x_real and x_fake)  67] [G 0.48, acc. (on x_fake)   7]\n",
            "58427/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  11]\n",
            "58428/60000 [D 0.19, acc. (on x_real and x_fake)  68] [G 0.45, acc. (on x_fake)  12]\n",
            "58429/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)   9]\n",
            "58430/60000 [D 0.19, acc. (on x_real and x_fake)  76] [G 0.48, acc. (on x_fake)   8]\n",
            "58431/60000 [D 0.16, acc. (on x_real and x_fake)  81] [G 0.47, acc. (on x_fake)  14]\n",
            "58432/60000 [D 0.21, acc. (on x_real and x_fake)  71] [G 0.47, acc. (on x_fake)  11]\n",
            "58433/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.51, acc. (on x_fake)   4]\n",
            "58434/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.44, acc. (on x_fake)  20]\n",
            "58435/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.47, acc. (on x_fake)  10]\n",
            "58436/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)  11]\n",
            "58437/60000 [D 0.18, acc. (on x_real and x_fake)  78] [G 0.46, acc. (on x_fake)  14]\n",
            "58438/60000 [D 0.20, acc. (on x_real and x_fake)  70] [G 0.49, acc. (on x_fake)  12]\n",
            "58439/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.44, acc. (on x_fake)  10]\n",
            "58440/60000 [D 0.18, acc. (on x_real and x_fake)  78] [G 0.47, acc. (on x_fake)   6]\n",
            "58441/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.51, acc. (on x_fake)   7]\n",
            "58442/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.51, acc. (on x_fake)   9]\n",
            "58443/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.50, acc. (on x_fake)  11]\n",
            "58444/60000 [D 0.17, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)   8]\n",
            "58445/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.45, acc. (on x_fake)  15]\n",
            "58446/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.51, acc. (on x_fake)   9]\n",
            "58447/60000 [D 0.16, acc. (on x_real and x_fake)  78] [G 0.46, acc. (on x_fake)  13]\n",
            "58448/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)   9]\n",
            "58449/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)  16]\n",
            "58450/60000 [D 0.19, acc. (on x_real and x_fake)  75] [G 0.51, acc. (on x_fake)  10]\n",
            "58451/60000 [D 0.20, acc. (on x_real and x_fake)  66] [G 0.45, acc. (on x_fake)  13]\n",
            "58452/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)  11]\n",
            "58453/60000 [D 0.18, acc. (on x_real and x_fake)  70] [G 0.48, acc. (on x_fake)   7]\n",
            "58454/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.50, acc. (on x_fake)  14]\n",
            "58455/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.49, acc. (on x_fake)  12]\n",
            "58456/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.46, acc. (on x_fake)  16]\n",
            "58457/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.46, acc. (on x_fake)  11]\n",
            "58458/60000 [D 0.17, acc. (on x_real and x_fake)  79] [G 0.47, acc. (on x_fake)  14]\n",
            "58459/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.50, acc. (on x_fake)  12]\n",
            "58460/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  15]\n",
            "58461/60000 [D 0.17, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  17]\n",
            "58462/60000 [D 0.16, acc. (on x_real and x_fake)  79] [G 0.50, acc. (on x_fake)  12]\n",
            "58463/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)  11]\n",
            "58464/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.45, acc. (on x_fake)  18]\n",
            "58465/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.50, acc. (on x_fake)  11]\n",
            "58466/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)  12]\n",
            "58467/60000 [D 0.19, acc. (on x_real and x_fake)  68] [G 0.50, acc. (on x_fake)   7]\n",
            "58468/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  16]\n",
            "58469/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   9]\n",
            "58470/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.49, acc. (on x_fake)  10]\n",
            "58471/60000 [D 0.20, acc. (on x_real and x_fake)  67] [G 0.44, acc. (on x_fake)  17]\n",
            "58472/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)   8]\n",
            "58473/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.51, acc. (on x_fake)   5]\n",
            "58474/60000 [D 0.21, acc. (on x_real and x_fake)  65] [G 0.48, acc. (on x_fake)  10]\n",
            "58475/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)   6]\n",
            "58476/60000 [D 0.20, acc. (on x_real and x_fake)  68] [G 0.45, acc. (on x_fake)  12]\n",
            "58477/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.45, acc. (on x_fake)  12]\n",
            "58478/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)  11]\n",
            "58479/60000 [D 0.17, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  10]\n",
            "58480/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.50, acc. (on x_fake)   7]\n",
            "58481/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.45, acc. (on x_fake)  11]\n",
            "58482/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)  11]\n",
            "58483/60000 [D 0.16, acc. (on x_real and x_fake)  78] [G 0.47, acc. (on x_fake)   6]\n",
            "58484/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)   7]\n",
            "58485/60000 [D 0.21, acc. (on x_real and x_fake)  67] [G 0.45, acc. (on x_fake)  16]\n",
            "58486/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.47, acc. (on x_fake)  10]\n",
            "58487/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.49, acc. (on x_fake)   8]\n",
            "58488/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.46, acc. (on x_fake)  12]\n",
            "58489/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  10]\n",
            "58490/60000 [D 0.20, acc. (on x_real and x_fake)  66] [G 0.47, acc. (on x_fake)   8]\n",
            "58491/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.46, acc. (on x_fake)  11]\n",
            "58492/60000 [D 0.16, acc. (on x_real and x_fake)  78] [G 0.49, acc. (on x_fake)   8]\n",
            "58493/60000 [D 0.16, acc. (on x_real and x_fake)  77] [G 0.50, acc. (on x_fake)   5]\n",
            "58494/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)   7]\n",
            "58495/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.51, acc. (on x_fake)   5]\n",
            "58496/60000 [D 0.17, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)  13]\n",
            "58497/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)   9]\n",
            "58498/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)  13]\n",
            "58499/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.45, acc. (on x_fake)  15]\n",
            "58500/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)   8]\n",
            "58501/60000 [D 0.20, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)   6]\n",
            "58502/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.46, acc. (on x_fake)  14]\n",
            "58503/60000 [D 0.16, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  14]\n",
            "58504/60000 [D 0.20, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)  14]\n",
            "58505/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  10]\n",
            "58506/60000 [D 0.20, acc. (on x_real and x_fake)  68] [G 0.46, acc. (on x_fake)  11]\n",
            "58507/60000 [D 0.16, acc. (on x_real and x_fake)  77] [G 0.52, acc. (on x_fake)   7]\n",
            "58508/60000 [D 0.20, acc. (on x_real and x_fake)  65] [G 0.46, acc. (on x_fake)  15]\n",
            "58509/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.49, acc. (on x_fake)  11]\n",
            "58510/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.55, acc. (on x_fake)   6]\n",
            "58511/60000 [D 0.19, acc. (on x_real and x_fake)  68] [G 0.47, acc. (on x_fake)  17]\n",
            "58512/60000 [D 0.15, acc. (on x_real and x_fake)  81] [G 0.48, acc. (on x_fake)  11]\n",
            "58513/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.50, acc. (on x_fake)   6]\n",
            "58514/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.50, acc. (on x_fake)  11]\n",
            "58515/60000 [D 0.19, acc. (on x_real and x_fake)  65] [G 0.48, acc. (on x_fake)   8]\n",
            "58516/60000 [D 0.16, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  11]\n",
            "58517/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.50, acc. (on x_fake)   7]\n",
            "58518/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.50, acc. (on x_fake)  10]\n",
            "58519/60000 [D 0.15, acc. (on x_real and x_fake)  81] [G 0.52, acc. (on x_fake)   5]\n",
            "58520/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)  10]\n",
            "58521/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.51, acc. (on x_fake)   9]\n",
            "58522/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.52, acc. (on x_fake)   8]\n",
            "58523/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)  14]\n",
            "58524/60000 [D 0.20, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)  11]\n",
            "58525/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)  12]\n",
            "58526/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.52, acc. (on x_fake)   3]\n",
            "58527/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)   7]\n",
            "58528/60000 [D 0.18, acc. (on x_real and x_fake)  67] [G 0.49, acc. (on x_fake)   8]\n",
            "58529/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  10]\n",
            "58530/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.48, acc. (on x_fake)   7]\n",
            "58531/60000 [D 0.18, acc. (on x_real and x_fake)  70] [G 0.49, acc. (on x_fake)   6]\n",
            "58532/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  11]\n",
            "58533/60000 [D 0.18, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)  14]\n",
            "58534/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)  15]\n",
            "58535/60000 [D 0.18, acc. (on x_real and x_fake)  70] [G 0.46, acc. (on x_fake)  11]\n",
            "58536/60000 [D 0.21, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)  13]\n",
            "58537/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)   7]\n",
            "58538/60000 [D 0.16, acc. (on x_real and x_fake)  78] [G 0.49, acc. (on x_fake)  10]\n",
            "58539/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.49, acc. (on x_fake)  13]\n",
            "58540/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.50, acc. (on x_fake)   9]\n",
            "58541/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)   9]\n",
            "58542/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.47, acc. (on x_fake)  13]\n",
            "58543/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.48, acc. (on x_fake)  10]\n",
            "58544/60000 [D 0.16, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)  11]\n",
            "58545/60000 [D 0.21, acc. (on x_real and x_fake)  66] [G 0.46, acc. (on x_fake)  13]\n",
            "58546/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)  15]\n",
            "58547/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.48, acc. (on x_fake)  11]\n",
            "58548/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)   7]\n",
            "58549/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  10]\n",
            "58550/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)  12]\n",
            "58551/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.46, acc. (on x_fake)   9]\n",
            "58552/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.50, acc. (on x_fake)   9]\n",
            "58553/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.49, acc. (on x_fake)   6]\n",
            "58554/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.50, acc. (on x_fake)   7]\n",
            "58555/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)   6]\n",
            "58556/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.48, acc. (on x_fake)   8]\n",
            "58557/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  10]\n",
            "58558/60000 [D 0.15, acc. (on x_real and x_fake)  80] [G 0.48, acc. (on x_fake)  10]\n",
            "58559/60000 [D 0.15, acc. (on x_real and x_fake)  79] [G 0.50, acc. (on x_fake)   9]\n",
            "58560/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)   6]\n",
            "58561/60000 [D 0.20, acc. (on x_real and x_fake)  66] [G 0.47, acc. (on x_fake)   5]\n",
            "58562/60000 [D 0.19, acc. (on x_real and x_fake)  68] [G 0.48, acc. (on x_fake)  17]\n",
            "58563/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.50, acc. (on x_fake)   6]\n",
            "58564/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)  13]\n",
            "58565/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.49, acc. (on x_fake)  10]\n",
            "58566/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.52, acc. (on x_fake)   6]\n",
            "58567/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.47, acc. (on x_fake)  12]\n",
            "58568/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.48, acc. (on x_fake)   8]\n",
            "58569/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)   9]\n",
            "58570/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.46, acc. (on x_fake)   9]\n",
            "58571/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)  10]\n",
            "58572/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)  10]\n",
            "58573/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)  12]\n",
            "58574/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)  11]\n",
            "58575/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.45, acc. (on x_fake)  11]\n",
            "58576/60000 [D 0.16, acc. (on x_real and x_fake)  79] [G 0.50, acc. (on x_fake)  12]\n",
            "58577/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   7]\n",
            "58578/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.52, acc. (on x_fake)   9]\n",
            "58579/60000 [D 0.20, acc. (on x_real and x_fake)  70] [G 0.48, acc. (on x_fake)  13]\n",
            "58580/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)   9]\n",
            "58581/60000 [D 0.20, acc. (on x_real and x_fake)  68] [G 0.48, acc. (on x_fake)   9]\n",
            "58582/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  14]\n",
            "58583/60000 [D 0.20, acc. (on x_real and x_fake)  64] [G 0.49, acc. (on x_fake)   9]\n",
            "58584/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.50, acc. (on x_fake)  10]\n",
            "58585/60000 [D 0.16, acc. (on x_real and x_fake)  77] [G 0.51, acc. (on x_fake)  10]\n",
            "58586/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.44, acc. (on x_fake)  14]\n",
            "58587/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.51, acc. (on x_fake)   7]\n",
            "58588/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)  10]\n",
            "58589/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.49, acc. (on x_fake)  10]\n",
            "58590/60000 [D 0.20, acc. (on x_real and x_fake)  70] [G 0.43, acc. (on x_fake)  18]\n",
            "58591/60000 [D 0.17, acc. (on x_real and x_fake)  79] [G 0.48, acc. (on x_fake)  12]\n",
            "58592/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.46, acc. (on x_fake)  13]\n",
            "58593/60000 [D 0.18, acc. (on x_real and x_fake)  78] [G 0.46, acc. (on x_fake)   9]\n",
            "58594/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)   8]\n",
            "58595/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)  14]\n",
            "58596/60000 [D 0.20, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)   9]\n",
            "58597/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.49, acc. (on x_fake)   6]\n",
            "58598/60000 [D 0.20, acc. (on x_real and x_fake)  68] [G 0.46, acc. (on x_fake)  13]\n",
            "58599/60000 [D 0.16, acc. (on x_real and x_fake)  78] [G 0.47, acc. (on x_fake)  12]\n",
            "58600/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)  15]\n",
            "58601/60000 [D 0.21, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)  19]\n",
            "58602/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.47, acc. (on x_fake)  12]\n",
            "58603/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   5]\n",
            "58604/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.52, acc. (on x_fake)   5]\n",
            "58605/60000 [D 0.20, acc. (on x_real and x_fake)  66] [G 0.46, acc. (on x_fake)  14]\n",
            "58606/60000 [D 0.16, acc. (on x_real and x_fake)  77] [G 0.51, acc. (on x_fake)   7]\n",
            "58607/60000 [D 0.21, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)  12]\n",
            "58608/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  18]\n",
            "58609/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.50, acc. (on x_fake)  10]\n",
            "58610/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)   8]\n",
            "58611/60000 [D 0.19, acc. (on x_real and x_fake)  68] [G 0.48, acc. (on x_fake)  12]\n",
            "58612/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.50, acc. (on x_fake)   8]\n",
            "58613/60000 [D 0.21, acc. (on x_real and x_fake)  66] [G 0.45, acc. (on x_fake)  12]\n",
            "58614/60000 [D 0.16, acc. (on x_real and x_fake)  80] [G 0.48, acc. (on x_fake)  10]\n",
            "58615/60000 [D 0.18, acc. (on x_real and x_fake)  70] [G 0.51, acc. (on x_fake)   7]\n",
            "58616/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.50, acc. (on x_fake)   4]\n",
            "58617/60000 [D 0.17, acc. (on x_real and x_fake)  73] [G 0.46, acc. (on x_fake)   9]\n",
            "58618/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)   8]\n",
            "58619/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.46, acc. (on x_fake)  15]\n",
            "58620/60000 [D 0.18, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)   9]\n",
            "58621/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)  10]\n",
            "58622/60000 [D 0.16, acc. (on x_real and x_fake)  79] [G 0.53, acc. (on x_fake)   7]\n",
            "58623/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.52, acc. (on x_fake)   3]\n",
            "58624/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.50, acc. (on x_fake)   5]\n",
            "58625/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.49, acc. (on x_fake)  13]\n",
            "58626/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)  10]\n",
            "58627/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)  12]\n",
            "58628/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  11]\n",
            "58629/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)  11]\n",
            "58630/60000 [D 0.21, acc. (on x_real and x_fake)  64] [G 0.46, acc. (on x_fake)   8]\n",
            "58631/60000 [D 0.16, acc. (on x_real and x_fake)  73] [G 0.54, acc. (on x_fake)   5]\n",
            "58632/60000 [D 0.20, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)  10]\n",
            "58633/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  13]\n",
            "58634/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.51, acc. (on x_fake)   4]\n",
            "58635/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)   7]\n",
            "58636/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)   9]\n",
            "58637/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)   4]\n",
            "58638/60000 [D 0.17, acc. (on x_real and x_fake)  80] [G 0.47, acc. (on x_fake)   6]\n",
            "58639/60000 [D 0.19, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   6]\n",
            "58640/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.46, acc. (on x_fake)  11]\n",
            "58641/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)   9]\n",
            "58642/60000 [D 0.19, acc. (on x_real and x_fake)  68] [G 0.46, acc. (on x_fake)   8]\n",
            "58643/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.49, acc. (on x_fake)   7]\n",
            "58644/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.45, acc. (on x_fake)  11]\n",
            "58645/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)  11]\n",
            "58646/60000 [D 0.16, acc. (on x_real and x_fake)  77] [G 0.48, acc. (on x_fake)  11]\n",
            "58647/60000 [D 0.20, acc. (on x_real and x_fake)  71] [G 0.50, acc. (on x_fake)   7]\n",
            "58648/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)  14]\n",
            "58649/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.49, acc. (on x_fake)   7]\n",
            "58650/60000 [D 0.20, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)  11]\n",
            "58651/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.44, acc. (on x_fake)  16]\n",
            "58652/60000 [D 0.17, acc. (on x_real and x_fake)  73] [G 0.45, acc. (on x_fake)   9]\n",
            "58653/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.46, acc. (on x_fake)  14]\n",
            "58654/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.45, acc. (on x_fake)  12]\n",
            "58655/60000 [D 0.19, acc. (on x_real and x_fake)  75] [G 0.51, acc. (on x_fake)   6]\n",
            "58656/60000 [D 0.20, acc. (on x_real and x_fake)  67] [G 0.46, acc. (on x_fake)  16]\n",
            "58657/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.46, acc. (on x_fake)  16]\n",
            "58658/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  17]\n",
            "58659/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.46, acc. (on x_fake)  11]\n",
            "58660/60000 [D 0.19, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  14]\n",
            "58661/60000 [D 0.16, acc. (on x_real and x_fake)  80] [G 0.52, acc. (on x_fake)   6]\n",
            "58662/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.45, acc. (on x_fake)  12]\n",
            "58663/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)  12]\n",
            "58664/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.50, acc. (on x_fake)   6]\n",
            "58665/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)   6]\n",
            "58666/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.50, acc. (on x_fake)  10]\n",
            "58667/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)   7]\n",
            "58668/60000 [D 0.18, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)  10]\n",
            "58669/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.47, acc. (on x_fake)  13]\n",
            "58670/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.48, acc. (on x_fake)   7]\n",
            "58671/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)  10]\n",
            "58672/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)   8]\n",
            "58673/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.50, acc. (on x_fake)  10]\n",
            "58674/60000 [D 0.19, acc. (on x_real and x_fake)  77] [G 0.49, acc. (on x_fake)  14]\n",
            "58675/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.53, acc. (on x_fake)   5]\n",
            "58676/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)   5]\n",
            "58677/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  12]\n",
            "58678/60000 [D 0.19, acc. (on x_real and x_fake)  67] [G 0.46, acc. (on x_fake)  12]\n",
            "58679/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.46, acc. (on x_fake)  15]\n",
            "58680/60000 [D 0.20, acc. (on x_real and x_fake)  66] [G 0.48, acc. (on x_fake)  11]\n",
            "58681/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.52, acc. (on x_fake)   7]\n",
            "58682/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)  12]\n",
            "58683/60000 [D 0.20, acc. (on x_real and x_fake)  67] [G 0.49, acc. (on x_fake)   8]\n",
            "58684/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  12]\n",
            "58685/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.46, acc. (on x_fake)   8]\n",
            "58686/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)   6]\n",
            "58687/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)   8]\n",
            "58688/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.48, acc. (on x_fake)   9]\n",
            "58689/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   6]\n",
            "58690/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.45, acc. (on x_fake)  11]\n",
            "58691/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.48, acc. (on x_fake)   9]\n",
            "58692/60000 [D 0.20, acc. (on x_real and x_fake)  68] [G 0.46, acc. (on x_fake)  13]\n",
            "58693/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.46, acc. (on x_fake)  14]\n",
            "58694/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)  10]\n",
            "58695/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.49, acc. (on x_fake)   9]\n",
            "58696/60000 [D 0.18, acc. (on x_real and x_fake)  78] [G 0.50, acc. (on x_fake)   5]\n",
            "58697/60000 [D 0.18, acc. (on x_real and x_fake)  77] [G 0.48, acc. (on x_fake)   9]\n",
            "58698/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.50, acc. (on x_fake)  10]\n",
            "58699/60000 [D 0.16, acc. (on x_real and x_fake)  80] [G 0.47, acc. (on x_fake)   8]\n",
            "58700/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.45, acc. (on x_fake)  15]\n",
            "58701/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)  14]\n",
            "58702/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)   7]\n",
            "58703/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  11]\n",
            "58704/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  15]\n",
            "58705/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)  10]\n",
            "58706/60000 [D 0.19, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)   9]\n",
            "58707/60000 [D 0.17, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  13]\n",
            "58708/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.45, acc. (on x_fake)  16]\n",
            "58709/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  16]\n",
            "58710/60000 [D 0.21, acc. (on x_real and x_fake)  64] [G 0.45, acc. (on x_fake)  13]\n",
            "58711/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)  11]\n",
            "58712/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)   9]\n",
            "58713/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.50, acc. (on x_fake)   6]\n",
            "58714/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  14]\n",
            "58715/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  11]\n",
            "58716/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)  10]\n",
            "58717/60000 [D 0.16, acc. (on x_real and x_fake)  78] [G 0.49, acc. (on x_fake)   8]\n",
            "58718/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.52, acc. (on x_fake)   8]\n",
            "58719/60000 [D 0.21, acc. (on x_real and x_fake)  65] [G 0.48, acc. (on x_fake)  14]\n",
            "58720/60000 [D 0.16, acc. (on x_real and x_fake)  80] [G 0.49, acc. (on x_fake)  10]\n",
            "58721/60000 [D 0.18, acc. (on x_real and x_fake)  69] [G 0.46, acc. (on x_fake)  13]\n",
            "58722/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)  12]\n",
            "58723/60000 [D 0.16, acc. (on x_real and x_fake)  81] [G 0.47, acc. (on x_fake)   9]\n",
            "58724/60000 [D 0.16, acc. (on x_real and x_fake)  78] [G 0.51, acc. (on x_fake)   5]\n",
            "58725/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.49, acc. (on x_fake)   7]\n",
            "58726/60000 [D 0.18, acc. (on x_real and x_fake)  78] [G 0.48, acc. (on x_fake)   5]\n",
            "58727/60000 [D 0.15, acc. (on x_real and x_fake)  81] [G 0.50, acc. (on x_fake)   8]\n",
            "58728/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.53, acc. (on x_fake)   9]\n",
            "58729/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)  17]\n",
            "58730/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)  15]\n",
            "58731/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  12]\n",
            "58732/60000 [D 0.17, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)   5]\n",
            "58733/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.49, acc. (on x_fake)   9]\n",
            "58734/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)   8]\n",
            "58735/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.45, acc. (on x_fake)  14]\n",
            "58736/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.46, acc. (on x_fake)  17]\n",
            "58737/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.45, acc. (on x_fake)  16]\n",
            "58738/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)  16]\n",
            "58739/60000 [D 0.15, acc. (on x_real and x_fake)  79] [G 0.52, acc. (on x_fake)   5]\n",
            "58740/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.51, acc. (on x_fake)   5]\n",
            "58741/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.51, acc. (on x_fake)   8]\n",
            "58742/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)  10]\n",
            "58743/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)   6]\n",
            "58744/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.51, acc. (on x_fake)   6]\n",
            "58745/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)   8]\n",
            "58746/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.51, acc. (on x_fake)   7]\n",
            "58747/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)  10]\n",
            "58748/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.46, acc. (on x_fake)  11]\n",
            "58749/60000 [D 0.20, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  11]\n",
            "58750/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.50, acc. (on x_fake)   9]\n",
            "58751/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.51, acc. (on x_fake)  10]\n",
            "58752/60000 [D 0.20, acc. (on x_real and x_fake)  68] [G 0.49, acc. (on x_fake)  12]\n",
            "58753/60000 [D 0.16, acc. (on x_real and x_fake)  77] [G 0.50, acc. (on x_fake)  15]\n",
            "58754/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)   7]\n",
            "58755/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.51, acc. (on x_fake)  11]\n",
            "58756/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.46, acc. (on x_fake)  13]\n",
            "58757/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  13]\n",
            "58758/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  17]\n",
            "58759/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   7]\n",
            "58760/60000 [D 0.18, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)  10]\n",
            "58761/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.49, acc. (on x_fake)   6]\n",
            "58762/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.46, acc. (on x_fake)  13]\n",
            "58763/60000 [D 0.16, acc. (on x_real and x_fake)  81] [G 0.47, acc. (on x_fake)   7]\n",
            "58764/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.50, acc. (on x_fake)  14]\n",
            "58765/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.49, acc. (on x_fake)   6]\n",
            "58766/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)  12]\n",
            "58767/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  12]\n",
            "58768/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)  12]\n",
            "58769/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)  10]\n",
            "58770/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.49, acc. (on x_fake)  12]\n",
            "58771/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)   9]\n",
            "58772/60000 [D 0.16, acc. (on x_real and x_fake)  79] [G 0.48, acc. (on x_fake)   8]\n",
            "58773/60000 [D 0.20, acc. (on x_real and x_fake)  70] [G 0.49, acc. (on x_fake)  12]\n",
            "58774/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)  12]\n",
            "58775/60000 [D 0.19, acc. (on x_real and x_fake)  75] [G 0.46, acc. (on x_fake)  11]\n",
            "58776/60000 [D 0.20, acc. (on x_real and x_fake)  68] [G 0.44, acc. (on x_fake)  15]\n",
            "58777/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)   6]\n",
            "58778/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)  13]\n",
            "58779/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)   9]\n",
            "58780/60000 [D 0.20, acc. (on x_real and x_fake)  68] [G 0.46, acc. (on x_fake)  11]\n",
            "58781/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)  10]\n",
            "58782/60000 [D 0.21, acc. (on x_real and x_fake)  69] [G 0.46, acc. (on x_fake)   9]\n",
            "58783/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.43, acc. (on x_fake)  17]\n",
            "58784/60000 [D 0.16, acc. (on x_real and x_fake)  75] [G 0.46, acc. (on x_fake)  18]\n",
            "58785/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)   9]\n",
            "58786/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  11]\n",
            "58787/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.46, acc. (on x_fake)  14]\n",
            "58788/60000 [D 0.18, acc. (on x_real and x_fake)  77] [G 0.45, acc. (on x_fake)  12]\n",
            "58789/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.51, acc. (on x_fake)   3]\n",
            "58790/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  10]\n",
            "58791/60000 [D 0.19, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  10]\n",
            "58792/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)  11]\n",
            "58793/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.52, acc. (on x_fake)  11]\n",
            "58794/60000 [D 0.16, acc. (on x_real and x_fake)  77] [G 0.52, acc. (on x_fake)   6]\n",
            "58795/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)   7]\n",
            "58796/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)   9]\n",
            "58797/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   8]\n",
            "58798/60000 [D 0.20, acc. (on x_real and x_fake)  70] [G 0.48, acc. (on x_fake)  10]\n",
            "58799/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.52, acc. (on x_fake)   5]\n",
            "58800/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)  10]\n",
            "58801/60000 [D 0.20, acc. (on x_real and x_fake)  68] [G 0.49, acc. (on x_fake)   7]\n",
            "58802/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.49, acc. (on x_fake)  14]\n",
            "58803/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.45, acc. (on x_fake)  17]\n",
            "58804/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.45, acc. (on x_fake)  13]\n",
            "58805/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.45, acc. (on x_fake)  11]\n",
            "58806/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.47, acc. (on x_fake)  11]\n",
            "58807/60000 [D 0.17, acc. (on x_real and x_fake)  73] [G 0.50, acc. (on x_fake)   7]\n",
            "58808/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  11]\n",
            "58809/60000 [D 0.19, acc. (on x_real and x_fake)  67] [G 0.48, acc. (on x_fake)  10]\n",
            "58810/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)   9]\n",
            "58811/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)   8]\n",
            "58812/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  11]\n",
            "58813/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.45, acc. (on x_fake)  15]\n",
            "58814/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)   6]\n",
            "58815/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.47, acc. (on x_fake)  11]\n",
            "58816/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)  11]\n",
            "58817/60000 [D 0.19, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)  10]\n",
            "58818/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  14]\n",
            "58819/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   9]\n",
            "58820/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.47, acc. (on x_fake)  10]\n",
            "58821/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.46, acc. (on x_fake)  12]\n",
            "58822/60000 [D 0.18, acc. (on x_real and x_fake)  77] [G 0.49, acc. (on x_fake)   7]\n",
            "58823/60000 [D 0.16, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  12]\n",
            "58824/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)   9]\n",
            "58825/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.46, acc. (on x_fake)   7]\n",
            "58826/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.46, acc. (on x_fake)  16]\n",
            "58827/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)  10]\n",
            "58828/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  10]\n",
            "58829/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)   8]\n",
            "58830/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)   8]\n",
            "58831/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.46, acc. (on x_fake)  13]\n",
            "58832/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.46, acc. (on x_fake)  11]\n",
            "58833/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  11]\n",
            "58834/60000 [D 0.18, acc. (on x_real and x_fake)  77] [G 0.48, acc. (on x_fake)   7]\n",
            "58835/60000 [D 0.20, acc. (on x_real and x_fake)  67] [G 0.44, acc. (on x_fake)  15]\n",
            "58836/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.52, acc. (on x_fake)   7]\n",
            "58837/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)  11]\n",
            "58838/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.51, acc. (on x_fake)   6]\n",
            "58839/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.46, acc. (on x_fake)  12]\n",
            "58840/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)   5]\n",
            "58841/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.46, acc. (on x_fake)  14]\n",
            "58842/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  12]\n",
            "58843/60000 [D 0.16, acc. (on x_real and x_fake)  76] [G 0.47, acc. (on x_fake)  11]\n",
            "58844/60000 [D 0.19, acc. (on x_real and x_fake)  67] [G 0.48, acc. (on x_fake)  10]\n",
            "58845/60000 [D 0.19, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  11]\n",
            "58846/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.45, acc. (on x_fake)  18]\n",
            "58847/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)   7]\n",
            "58848/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  11]\n",
            "58849/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)  12]\n",
            "58850/60000 [D 0.20, acc. (on x_real and x_fake)  70] [G 0.48, acc. (on x_fake)  14]\n",
            "58851/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.50, acc. (on x_fake)   9]\n",
            "58852/60000 [D 0.16, acc. (on x_real and x_fake)  80] [G 0.49, acc. (on x_fake)   7]\n",
            "58853/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   6]\n",
            "58854/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.47, acc. (on x_fake)  11]\n",
            "58855/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.47, acc. (on x_fake)  13]\n",
            "58856/60000 [D 0.18, acc. (on x_real and x_fake)  69] [G 0.50, acc. (on x_fake)   5]\n",
            "58857/60000 [D 0.17, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)  10]\n",
            "58858/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.50, acc. (on x_fake)   8]\n",
            "58859/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)  15]\n",
            "58860/60000 [D 0.20, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)   9]\n",
            "58861/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   7]\n",
            "58862/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.51, acc. (on x_fake)  10]\n",
            "58863/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.50, acc. (on x_fake)   6]\n",
            "58864/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.50, acc. (on x_fake)   8]\n",
            "58865/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.49, acc. (on x_fake)   7]\n",
            "58866/60000 [D 0.19, acc. (on x_real and x_fake)  68] [G 0.47, acc. (on x_fake)   8]\n",
            "58867/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.48, acc. (on x_fake)   7]\n",
            "58868/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)   8]\n",
            "58869/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)  10]\n",
            "58870/60000 [D 0.20, acc. (on x_real and x_fake)  68] [G 0.49, acc. (on x_fake)   8]\n",
            "58871/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)   7]\n",
            "58872/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)  15]\n",
            "58873/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.46, acc. (on x_fake)  15]\n",
            "58874/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  10]\n",
            "58875/60000 [D 0.20, acc. (on x_real and x_fake)  66] [G 0.47, acc. (on x_fake)  16]\n",
            "58876/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.51, acc. (on x_fake)   7]\n",
            "58877/60000 [D 0.16, acc. (on x_real and x_fake)  82] [G 0.50, acc. (on x_fake)   9]\n",
            "58878/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)  11]\n",
            "58879/60000 [D 0.16, acc. (on x_real and x_fake)  78] [G 0.49, acc. (on x_fake)   5]\n",
            "58880/60000 [D 0.17, acc. (on x_real and x_fake)  79] [G 0.48, acc. (on x_fake)   7]\n",
            "58881/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)   8]\n",
            "58882/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)  13]\n",
            "58883/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)   9]\n",
            "58884/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)  10]\n",
            "58885/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)  10]\n",
            "58886/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.45, acc. (on x_fake)  10]\n",
            "58887/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)   5]\n",
            "58888/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  14]\n",
            "58889/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)   9]\n",
            "58890/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)  11]\n",
            "58891/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.50, acc. (on x_fake)   6]\n",
            "58892/60000 [D 0.21, acc. (on x_real and x_fake)  65] [G 0.47, acc. (on x_fake)  10]\n",
            "58893/60000 [D 0.20, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)  12]\n",
            "58894/60000 [D 0.19, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)   7]\n",
            "58895/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.47, acc. (on x_fake)  15]\n",
            "58896/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.50, acc. (on x_fake)  10]\n",
            "58897/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.51, acc. (on x_fake)  10]\n",
            "58898/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.46, acc. (on x_fake)  16]\n",
            "58899/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.46, acc. (on x_fake)  11]\n",
            "58900/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.50, acc. (on x_fake)   8]\n",
            "58901/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.51, acc. (on x_fake)   6]\n",
            "58902/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)  10]\n",
            "58903/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.50, acc. (on x_fake)   4]\n",
            "58904/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.46, acc. (on x_fake)  12]\n",
            "58905/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)  13]\n",
            "58906/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.50, acc. (on x_fake)  11]\n",
            "58907/60000 [D 0.20, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)  11]\n",
            "58908/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.46, acc. (on x_fake)  13]\n",
            "58909/60000 [D 0.21, acc. (on x_real and x_fake)  66] [G 0.45, acc. (on x_fake)  18]\n",
            "58910/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)   8]\n",
            "58911/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)  11]\n",
            "58912/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.50, acc. (on x_fake)   9]\n",
            "58913/60000 [D 0.21, acc. (on x_real and x_fake)  66] [G 0.45, acc. (on x_fake)  11]\n",
            "58914/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.46, acc. (on x_fake)  14]\n",
            "58915/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.50, acc. (on x_fake)  10]\n",
            "58916/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  16]\n",
            "58917/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  16]\n",
            "58918/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  12]\n",
            "58919/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  14]\n",
            "58920/60000 [D 0.17, acc. (on x_real and x_fake)  80] [G 0.51, acc. (on x_fake)  11]\n",
            "58921/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.52, acc. (on x_fake)  11]\n",
            "58922/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.51, acc. (on x_fake)   6]\n",
            "58923/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.52, acc. (on x_fake)   5]\n",
            "58924/60000 [D 0.16, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)   8]\n",
            "58925/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)  13]\n",
            "58926/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   4]\n",
            "58927/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.45, acc. (on x_fake)   9]\n",
            "58928/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)   6]\n",
            "58929/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.45, acc. (on x_fake)  13]\n",
            "58930/60000 [D 0.18, acc. (on x_real and x_fake)  68] [G 0.48, acc. (on x_fake)  12]\n",
            "58931/60000 [D 0.16, acc. (on x_real and x_fake)  77] [G 0.49, acc. (on x_fake)   4]\n",
            "58932/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)   9]\n",
            "58933/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)   6]\n",
            "58934/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.46, acc. (on x_fake)  13]\n",
            "58935/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)   8]\n",
            "58936/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)  14]\n",
            "58937/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.51, acc. (on x_fake)   7]\n",
            "58938/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.49, acc. (on x_fake)  12]\n",
            "58939/60000 [D 0.19, acc. (on x_real and x_fake)  75] [G 0.46, acc. (on x_fake)  13]\n",
            "58940/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)  10]\n",
            "58941/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.45, acc. (on x_fake)   5]\n",
            "58942/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)   9]\n",
            "58943/60000 [D 0.16, acc. (on x_real and x_fake)  78] [G 0.48, acc. (on x_fake)   9]\n",
            "58944/60000 [D 0.19, acc. (on x_real and x_fake)  66] [G 0.48, acc. (on x_fake)  10]\n",
            "58945/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.50, acc. (on x_fake)  11]\n",
            "58946/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  12]\n",
            "58947/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)   8]\n",
            "58948/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  10]\n",
            "58949/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  14]\n",
            "58950/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.46, acc. (on x_fake)  12]\n",
            "58951/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.47, acc. (on x_fake)  10]\n",
            "58952/60000 [D 0.21, acc. (on x_real and x_fake)  66] [G 0.46, acc. (on x_fake)   9]\n",
            "58953/60000 [D 0.19, acc. (on x_real and x_fake)  76] [G 0.47, acc. (on x_fake)  15]\n",
            "58954/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  14]\n",
            "58955/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.46, acc. (on x_fake)  10]\n",
            "58956/60000 [D 0.20, acc. (on x_real and x_fake)  70] [G 0.46, acc. (on x_fake)  16]\n",
            "58957/60000 [D 0.15, acc. (on x_real and x_fake)  83] [G 0.47, acc. (on x_fake)   9]\n",
            "58958/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   8]\n",
            "58959/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.45, acc. (on x_fake)  12]\n",
            "58960/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  17]\n",
            "58961/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)   9]\n",
            "58962/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)   9]\n",
            "58963/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)   8]\n",
            "58964/60000 [D 0.20, acc. (on x_real and x_fake)  66] [G 0.45, acc. (on x_fake)  14]\n",
            "58965/60000 [D 0.17, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  11]\n",
            "58966/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.52, acc. (on x_fake)   8]\n",
            "58967/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)   8]\n",
            "58968/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)   7]\n",
            "58969/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.47, acc. (on x_fake)  11]\n",
            "58970/60000 [D 0.20, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  14]\n",
            "58971/60000 [D 0.20, acc. (on x_real and x_fake)  66] [G 0.47, acc. (on x_fake)  11]\n",
            "58972/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)  13]\n",
            "58973/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.52, acc. (on x_fake)   8]\n",
            "58974/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.49, acc. (on x_fake)  11]\n",
            "58975/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.51, acc. (on x_fake)   7]\n",
            "58976/60000 [D 0.18, acc. (on x_real and x_fake)  78] [G 0.49, acc. (on x_fake)  13]\n",
            "58977/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.50, acc. (on x_fake)   9]\n",
            "58978/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.52, acc. (on x_fake)   7]\n",
            "58979/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)  12]\n",
            "58980/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  16]\n",
            "58981/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.48, acc. (on x_fake)  11]\n",
            "58982/60000 [D 0.16, acc. (on x_real and x_fake)  77] [G 0.51, acc. (on x_fake)   7]\n",
            "58983/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)   7]\n",
            "58984/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.46, acc. (on x_fake)  16]\n",
            "58985/60000 [D 0.16, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   5]\n",
            "58986/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.52, acc. (on x_fake)   2]\n",
            "58987/60000 [D 0.21, acc. (on x_real and x_fake)  67] [G 0.47, acc. (on x_fake)  13]\n",
            "58988/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.49, acc. (on x_fake)  10]\n",
            "58989/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)  15]\n",
            "58990/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.51, acc. (on x_fake)   6]\n",
            "58991/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  11]\n",
            "58992/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.46, acc. (on x_fake)  13]\n",
            "58993/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  12]\n",
            "58994/60000 [D 0.20, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)  12]\n",
            "58995/60000 [D 0.20, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)  12]\n",
            "58996/60000 [D 0.17, acc. (on x_real and x_fake)  72] [G 0.50, acc. (on x_fake)   9]\n",
            "58997/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)  15]\n",
            "58998/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.48, acc. (on x_fake)   7]\n",
            "58999/60000 [D 0.20, acc. (on x_real and x_fake)  66] [G 0.49, acc. (on x_fake)  10]\n",
            "59000/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.52, acc. (on x_fake)   5]\n",
            "59001/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.45, acc. (on x_fake)  14]\n",
            "59002/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.44, acc. (on x_fake)  14]\n",
            "59003/60000 [D 0.19, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)   9]\n",
            "59004/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.45, acc. (on x_fake)  15]\n",
            "59005/60000 [D 0.17, acc. (on x_real and x_fake)  72] [G 0.45, acc. (on x_fake)  16]\n",
            "59006/60000 [D 0.18, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)  13]\n",
            "59007/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)   8]\n",
            "59008/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.51, acc. (on x_fake)  14]\n",
            "59009/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)  12]\n",
            "59010/60000 [D 0.16, acc. (on x_real and x_fake)  80] [G 0.48, acc. (on x_fake)   9]\n",
            "59011/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)  10]\n",
            "59012/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)  11]\n",
            "59013/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.52, acc. (on x_fake)   5]\n",
            "59014/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.49, acc. (on x_fake)   8]\n",
            "59015/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)  13]\n",
            "59016/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.49, acc. (on x_fake)   8]\n",
            "59017/60000 [D 0.18, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)  14]\n",
            "59018/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.50, acc. (on x_fake)   5]\n",
            "59019/60000 [D 0.16, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   8]\n",
            "59020/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.50, acc. (on x_fake)   7]\n",
            "59021/60000 [D 0.18, acc. (on x_real and x_fake)  78] [G 0.47, acc. (on x_fake)  11]\n",
            "59022/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.50, acc. (on x_fake)   7]\n",
            "59023/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.45, acc. (on x_fake)  16]\n",
            "59024/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.47, acc. (on x_fake)   5]\n",
            "59025/60000 [D 0.19, acc. (on x_real and x_fake)  68] [G 0.47, acc. (on x_fake)   9]\n",
            "59026/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)  12]\n",
            "59027/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)   8]\n",
            "59028/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)   6]\n",
            "59029/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.52, acc. (on x_fake)  10]\n",
            "59030/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  11]\n",
            "59031/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  15]\n",
            "59032/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.46, acc. (on x_fake)  13]\n",
            "59033/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)  10]\n",
            "59034/60000 [D 0.16, acc. (on x_real and x_fake)  77] [G 0.49, acc. (on x_fake)   5]\n",
            "59035/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)   5]\n",
            "59036/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)   6]\n",
            "59037/60000 [D 0.17, acc. (on x_real and x_fake)  73] [G 0.50, acc. (on x_fake)   9]\n",
            "59038/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.51, acc. (on x_fake)   7]\n",
            "59039/60000 [D 0.16, acc. (on x_real and x_fake)  79] [G 0.49, acc. (on x_fake)  12]\n",
            "59040/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)  12]\n",
            "59041/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)   7]\n",
            "59042/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)  12]\n",
            "59043/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.46, acc. (on x_fake)   9]\n",
            "59044/60000 [D 0.16, acc. (on x_real and x_fake)  81] [G 0.49, acc. (on x_fake)  11]\n",
            "59045/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  17]\n",
            "59046/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.49, acc. (on x_fake)   6]\n",
            "59047/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)  14]\n",
            "59048/60000 [D 0.17, acc. (on x_real and x_fake)  73] [G 0.50, acc. (on x_fake)  10]\n",
            "59049/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)  12]\n",
            "59050/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.50, acc. (on x_fake)   8]\n",
            "59051/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.53, acc. (on x_fake)   6]\n",
            "59052/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.49, acc. (on x_fake)   9]\n",
            "59053/60000 [D 0.20, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)  13]\n",
            "59054/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)   9]\n",
            "59055/60000 [D 0.16, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)  14]\n",
            "59056/60000 [D 0.20, acc. (on x_real and x_fake)  71] [G 0.44, acc. (on x_fake)  20]\n",
            "59057/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  13]\n",
            "59058/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)  13]\n",
            "59059/60000 [D 0.19, acc. (on x_real and x_fake)  76] [G 0.47, acc. (on x_fake)   8]\n",
            "59060/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.49, acc. (on x_fake)   8]\n",
            "59061/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  13]\n",
            "59062/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)   8]\n",
            "59063/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)  13]\n",
            "59064/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)   5]\n",
            "59065/60000 [D 0.16, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)   7]\n",
            "59066/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.45, acc. (on x_fake)   9]\n",
            "59067/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)  14]\n",
            "59068/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)   9]\n",
            "59069/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)   8]\n",
            "59070/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  12]\n",
            "59071/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)   4]\n",
            "59072/60000 [D 0.18, acc. (on x_real and x_fake)  70] [G 0.48, acc. (on x_fake)   7]\n",
            "59073/60000 [D 0.15, acc. (on x_real and x_fake)  79] [G 0.49, acc. (on x_fake)   7]\n",
            "59074/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  12]\n",
            "59075/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)  12]\n",
            "59076/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.50, acc. (on x_fake)   7]\n",
            "59077/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   7]\n",
            "59078/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.50, acc. (on x_fake)  11]\n",
            "59079/60000 [D 0.17, acc. (on x_real and x_fake)  73] [G 0.50, acc. (on x_fake)   2]\n",
            "59080/60000 [D 0.20, acc. (on x_real and x_fake)  66] [G 0.48, acc. (on x_fake)  13]\n",
            "59081/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.50, acc. (on x_fake)   9]\n",
            "59082/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.50, acc. (on x_fake)   5]\n",
            "59083/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)  10]\n",
            "59084/60000 [D 0.20, acc. (on x_real and x_fake)  68] [G 0.47, acc. (on x_fake)  11]\n",
            "59085/60000 [D 0.21, acc. (on x_real and x_fake)  65] [G 0.44, acc. (on x_fake)  18]\n",
            "59086/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.44, acc. (on x_fake)  14]\n",
            "59087/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)   9]\n",
            "59088/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)  13]\n",
            "59089/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  11]\n",
            "59090/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)  10]\n",
            "59091/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.50, acc. (on x_fake)   7]\n",
            "59092/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)   9]\n",
            "59093/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.45, acc. (on x_fake)  11]\n",
            "59094/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  11]\n",
            "59095/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)  10]\n",
            "59096/60000 [D 0.20, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)  13]\n",
            "59097/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  11]\n",
            "59098/60000 [D 0.19, acc. (on x_real and x_fake)  67] [G 0.45, acc. (on x_fake)  14]\n",
            "59099/60000 [D 0.20, acc. (on x_real and x_fake)  71] [G 0.46, acc. (on x_fake)  17]\n",
            "59100/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  10]\n",
            "59101/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)   7]\n",
            "59102/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)  13]\n",
            "59103/60000 [D 0.17, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)   9]\n",
            "59104/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  10]\n",
            "59105/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.46, acc. (on x_fake)  10]\n",
            "59106/60000 [D 0.20, acc. (on x_real and x_fake)  67] [G 0.46, acc. (on x_fake)  11]\n",
            "59107/60000 [D 0.20, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  17]\n",
            "59108/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   7]\n",
            "59109/60000 [D 0.16, acc. (on x_real and x_fake)  80] [G 0.51, acc. (on x_fake)   6]\n",
            "59110/60000 [D 0.16, acc. (on x_real and x_fake)  77] [G 0.50, acc. (on x_fake)  13]\n",
            "59111/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.51, acc. (on x_fake)   9]\n",
            "59112/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)   9]\n",
            "59113/60000 [D 0.17, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)  11]\n",
            "59114/60000 [D 0.18, acc. (on x_real and x_fake)  77] [G 0.50, acc. (on x_fake)  11]\n",
            "59115/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.48, acc. (on x_fake)   8]\n",
            "59116/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.47, acc. (on x_fake)  11]\n",
            "59117/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)  12]\n",
            "59118/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  14]\n",
            "59119/60000 [D 0.17, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  11]\n",
            "59120/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.50, acc. (on x_fake)  12]\n",
            "59121/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  10]\n",
            "59122/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.49, acc. (on x_fake)   3]\n",
            "59123/60000 [D 0.16, acc. (on x_real and x_fake)  76] [G 0.49, acc. (on x_fake)   7]\n",
            "59124/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)  13]\n",
            "59125/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  14]\n",
            "59126/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.44, acc. (on x_fake)  19]\n",
            "59127/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)  15]\n",
            "59128/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   8]\n",
            "59129/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)  16]\n",
            "59130/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.48, acc. (on x_fake)   9]\n",
            "59131/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)  13]\n",
            "59132/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)   9]\n",
            "59133/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.50, acc. (on x_fake)   9]\n",
            "59134/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.45, acc. (on x_fake)  14]\n",
            "59135/60000 [D 0.20, acc. (on x_real and x_fake)  66] [G 0.49, acc. (on x_fake)   6]\n",
            "59136/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)  16]\n",
            "59137/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.47, acc. (on x_fake)  11]\n",
            "59138/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)  18]\n",
            "59139/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)   9]\n",
            "59140/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)   8]\n",
            "59141/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)   8]\n",
            "59142/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.50, acc. (on x_fake)   4]\n",
            "59143/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)  10]\n",
            "59144/60000 [D 0.17, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)   7]\n",
            "59145/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.50, acc. (on x_fake)   5]\n",
            "59146/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.50, acc. (on x_fake)   7]\n",
            "59147/60000 [D 0.20, acc. (on x_real and x_fake)  65] [G 0.48, acc. (on x_fake)  13]\n",
            "59148/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)   9]\n",
            "59149/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.49, acc. (on x_fake)  11]\n",
            "59150/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)  11]\n",
            "59151/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)   8]\n",
            "59152/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)   8]\n",
            "59153/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)  12]\n",
            "59154/60000 [D 0.16, acc. (on x_real and x_fake)  79] [G 0.48, acc. (on x_fake)  15]\n",
            "59155/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)  12]\n",
            "59156/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  14]\n",
            "59157/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  14]\n",
            "59158/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.48, acc. (on x_fake)  12]\n",
            "59159/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)  13]\n",
            "59160/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)  11]\n",
            "59161/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  12]\n",
            "59162/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.49, acc. (on x_fake)  14]\n",
            "59163/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)  12]\n",
            "59164/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)   9]\n",
            "59165/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  16]\n",
            "59166/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.49, acc. (on x_fake)  12]\n",
            "59167/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  10]\n",
            "59168/60000 [D 0.16, acc. (on x_real and x_fake)  82] [G 0.51, acc. (on x_fake)   5]\n",
            "59169/60000 [D 0.19, acc. (on x_real and x_fake)  68] [G 0.51, acc. (on x_fake)  13]\n",
            "59170/60000 [D 0.16, acc. (on x_real and x_fake)  77] [G 0.50, acc. (on x_fake)  12]\n",
            "59171/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.47, acc. (on x_fake)   9]\n",
            "59172/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.50, acc. (on x_fake)   9]\n",
            "59173/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.49, acc. (on x_fake)   7]\n",
            "59174/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.51, acc. (on x_fake)  10]\n",
            "59175/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)   7]\n",
            "59176/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)  10]\n",
            "59177/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.52, acc. (on x_fake)   7]\n",
            "59178/60000 [D 0.18, acc. (on x_real and x_fake)  70] [G 0.52, acc. (on x_fake)   6]\n",
            "59179/60000 [D 0.16, acc. (on x_real and x_fake)  80] [G 0.51, acc. (on x_fake)   8]\n",
            "59180/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)   8]\n",
            "59181/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.48, acc. (on x_fake)  11]\n",
            "59182/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  11]\n",
            "59183/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.49, acc. (on x_fake)   5]\n",
            "59184/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)  11]\n",
            "59185/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  12]\n",
            "59186/60000 [D 0.17, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  11]\n",
            "59187/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)  13]\n",
            "59188/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  12]\n",
            "59189/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.45, acc. (on x_fake)  17]\n",
            "59190/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.51, acc. (on x_fake)   7]\n",
            "59191/60000 [D 0.21, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)  15]\n",
            "59192/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.50, acc. (on x_fake)   7]\n",
            "59193/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.50, acc. (on x_fake)  11]\n",
            "59194/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.47, acc. (on x_fake)  13]\n",
            "59195/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.49, acc. (on x_fake)  14]\n",
            "59196/60000 [D 0.19, acc. (on x_real and x_fake)  68] [G 0.50, acc. (on x_fake)  10]\n",
            "59197/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.46, acc. (on x_fake)   8]\n",
            "59198/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)  11]\n",
            "59199/60000 [D 0.20, acc. (on x_real and x_fake)  67] [G 0.47, acc. (on x_fake)   5]\n",
            "59200/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)  10]\n",
            "59201/60000 [D 0.20, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  11]\n",
            "59202/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.50, acc. (on x_fake)   8]\n",
            "59203/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.46, acc. (on x_fake)  13]\n",
            "59204/60000 [D 0.20, acc. (on x_real and x_fake)  74] [G 0.46, acc. (on x_fake)  11]\n",
            "59205/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  15]\n",
            "59206/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)  13]\n",
            "59207/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  15]\n",
            "59208/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.49, acc. (on x_fake)  10]\n",
            "59209/60000 [D 0.21, acc. (on x_real and x_fake)  67] [G 0.47, acc. (on x_fake)   8]\n",
            "59210/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)  12]\n",
            "59211/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.45, acc. (on x_fake)  11]\n",
            "59212/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)   6]\n",
            "59213/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.52, acc. (on x_fake)   8]\n",
            "59214/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)  10]\n",
            "59215/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)  13]\n",
            "59216/60000 [D 0.18, acc. (on x_real and x_fake)  70] [G 0.46, acc. (on x_fake)  10]\n",
            "59217/60000 [D 0.18, acc. (on x_real and x_fake)  70] [G 0.50, acc. (on x_fake)  12]\n",
            "59218/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)  15]\n",
            "59219/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  13]\n",
            "59220/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.48, acc. (on x_fake)  10]\n",
            "59221/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)  15]\n",
            "59222/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.51, acc. (on x_fake)  10]\n",
            "59223/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  10]\n",
            "59224/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.50, acc. (on x_fake)   8]\n",
            "59225/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.48, acc. (on x_fake)  15]\n",
            "59226/60000 [D 0.20, acc. (on x_real and x_fake)  66] [G 0.48, acc. (on x_fake)  13]\n",
            "59227/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)  11]\n",
            "59228/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)  15]\n",
            "59229/60000 [D 0.21, acc. (on x_real and x_fake)  68] [G 0.46, acc. (on x_fake)   9]\n",
            "59230/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.48, acc. (on x_fake)  11]\n",
            "59231/60000 [D 0.16, acc. (on x_real and x_fake)  77] [G 0.50, acc. (on x_fake)   7]\n",
            "59232/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)  14]\n",
            "59233/60000 [D 0.18, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)   9]\n",
            "59234/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.50, acc. (on x_fake)   7]\n",
            "59235/60000 [D 0.18, acc. (on x_real and x_fake)  77] [G 0.48, acc. (on x_fake)  10]\n",
            "59236/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.50, acc. (on x_fake)  10]\n",
            "59237/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)  10]\n",
            "59238/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.46, acc. (on x_fake)  17]\n",
            "59239/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.45, acc. (on x_fake)   8]\n",
            "59240/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.52, acc. (on x_fake)   8]\n",
            "59241/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)   9]\n",
            "59242/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  11]\n",
            "59243/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.51, acc. (on x_fake)   9]\n",
            "59244/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)   8]\n",
            "59245/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.51, acc. (on x_fake)   6]\n",
            "59246/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)   5]\n",
            "59247/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.49, acc. (on x_fake)   9]\n",
            "59248/60000 [D 0.17, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  10]\n",
            "59249/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)   8]\n",
            "59250/60000 [D 0.16, acc. (on x_real and x_fake)  79] [G 0.49, acc. (on x_fake)  10]\n",
            "59251/60000 [D 0.20, acc. (on x_real and x_fake)  66] [G 0.48, acc. (on x_fake)  10]\n",
            "59252/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.48, acc. (on x_fake)  10]\n",
            "59253/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.49, acc. (on x_fake)   9]\n",
            "59254/60000 [D 0.18, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)  13]\n",
            "59255/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  12]\n",
            "59256/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.46, acc. (on x_fake)  16]\n",
            "59257/60000 [D 0.19, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)  10]\n",
            "59258/60000 [D 0.16, acc. (on x_real and x_fake)  76] [G 0.52, acc. (on x_fake)   5]\n",
            "59259/60000 [D 0.20, acc. (on x_real and x_fake)  67] [G 0.45, acc. (on x_fake)  17]\n",
            "59260/60000 [D 0.20, acc. (on x_real and x_fake)  67] [G 0.45, acc. (on x_fake)  17]\n",
            "59261/60000 [D 0.20, acc. (on x_real and x_fake)  71] [G 0.47, acc. (on x_fake)  15]\n",
            "59262/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)   7]\n",
            "59263/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  10]\n",
            "59264/60000 [D 0.16, acc. (on x_real and x_fake)  78] [G 0.49, acc. (on x_fake)  13]\n",
            "59265/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.46, acc. (on x_fake)  15]\n",
            "59266/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)   8]\n",
            "59267/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)   4]\n",
            "59268/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)   7]\n",
            "59269/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)  14]\n",
            "59270/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)   6]\n",
            "59271/60000 [D 0.18, acc. (on x_real and x_fake)  78] [G 0.46, acc. (on x_fake)  13]\n",
            "59272/60000 [D 0.17, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)   8]\n",
            "59273/60000 [D 0.15, acc. (on x_real and x_fake)  80] [G 0.52, acc. (on x_fake)  11]\n",
            "59274/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.51, acc. (on x_fake)   8]\n",
            "59275/60000 [D 0.17, acc. (on x_real and x_fake)  73] [G 0.52, acc. (on x_fake)   6]\n",
            "59276/60000 [D 0.20, acc. (on x_real and x_fake)  67] [G 0.47, acc. (on x_fake)  11]\n",
            "59277/60000 [D 0.16, acc. (on x_real and x_fake)  80] [G 0.47, acc. (on x_fake)  10]\n",
            "59278/60000 [D 0.18, acc. (on x_real and x_fake)  70] [G 0.50, acc. (on x_fake)   8]\n",
            "59279/60000 [D 0.17, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)   9]\n",
            "59280/60000 [D 0.15, acc. (on x_real and x_fake)  78] [G 0.54, acc. (on x_fake)   4]\n",
            "59281/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  17]\n",
            "59282/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)   8]\n",
            "59283/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.51, acc. (on x_fake)   6]\n",
            "59284/60000 [D 0.16, acc. (on x_real and x_fake)  79] [G 0.50, acc. (on x_fake)   9]\n",
            "59285/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)   8]\n",
            "59286/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.46, acc. (on x_fake)  15]\n",
            "59287/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.46, acc. (on x_fake)  12]\n",
            "59288/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  13]\n",
            "59289/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.47, acc. (on x_fake)   8]\n",
            "59290/60000 [D 0.17, acc. (on x_real and x_fake)  70] [G 0.49, acc. (on x_fake)   7]\n",
            "59291/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.50, acc. (on x_fake)   4]\n",
            "59292/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)  12]\n",
            "59293/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.51, acc. (on x_fake)  11]\n",
            "59294/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.46, acc. (on x_fake)  10]\n",
            "59295/60000 [D 0.16, acc. (on x_real and x_fake)  79] [G 0.51, acc. (on x_fake)   6]\n",
            "59296/60000 [D 0.18, acc. (on x_real and x_fake)  79] [G 0.50, acc. (on x_fake)   8]\n",
            "59297/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  10]\n",
            "59298/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  12]\n",
            "59299/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  15]\n",
            "59300/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)  13]\n",
            "59301/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)  11]\n",
            "59302/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)   9]\n",
            "59303/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)  14]\n",
            "59304/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)   8]\n",
            "59305/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  15]\n",
            "59306/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  12]\n",
            "59307/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.50, acc. (on x_fake)  13]\n",
            "59308/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.49, acc. (on x_fake)  12]\n",
            "59309/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.51, acc. (on x_fake)  11]\n",
            "59310/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.51, acc. (on x_fake)   9]\n",
            "59311/60000 [D 0.17, acc. (on x_real and x_fake)  71] [G 0.51, acc. (on x_fake)   5]\n",
            "59312/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.53, acc. (on x_fake)   5]\n",
            "59313/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.50, acc. (on x_fake)   8]\n",
            "59314/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.50, acc. (on x_fake)   7]\n",
            "59315/60000 [D 0.18, acc. (on x_real and x_fake)  70] [G 0.50, acc. (on x_fake)   4]\n",
            "59316/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.49, acc. (on x_fake)  11]\n",
            "59317/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   6]\n",
            "59318/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)  11]\n",
            "59319/60000 [D 0.16, acc. (on x_real and x_fake)  82] [G 0.49, acc. (on x_fake)   4]\n",
            "59320/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)  12]\n",
            "59321/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.49, acc. (on x_fake)   9]\n",
            "59322/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.51, acc. (on x_fake)   8]\n",
            "59323/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.46, acc. (on x_fake)  16]\n",
            "59324/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)  10]\n",
            "59325/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)  13]\n",
            "59326/60000 [D 0.18, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)  16]\n",
            "59327/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.50, acc. (on x_fake)   8]\n",
            "59328/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)   8]\n",
            "59329/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.51, acc. (on x_fake)   9]\n",
            "59330/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)  12]\n",
            "59331/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)  12]\n",
            "59332/60000 [D 0.20, acc. (on x_real and x_fake)  66] [G 0.46, acc. (on x_fake)  15]\n",
            "59333/60000 [D 0.21, acc. (on x_real and x_fake)  70] [G 0.43, acc. (on x_fake)  13]\n",
            "59334/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)  13]\n",
            "59335/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.50, acc. (on x_fake)  12]\n",
            "59336/60000 [D 0.18, acc. (on x_real and x_fake)  70] [G 0.49, acc. (on x_fake)  14]\n",
            "59337/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)  13]\n",
            "59338/60000 [D 0.19, acc. (on x_real and x_fake)  68] [G 0.46, acc. (on x_fake)  17]\n",
            "59339/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.51, acc. (on x_fake)  10]\n",
            "59340/60000 [D 0.18, acc. (on x_real and x_fake)  77] [G 0.47, acc. (on x_fake)  14]\n",
            "59341/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)  10]\n",
            "59342/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.50, acc. (on x_fake)   8]\n",
            "59343/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)  10]\n",
            "59344/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.44, acc. (on x_fake)  13]\n",
            "59345/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  10]\n",
            "59346/60000 [D 0.17, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)  13]\n",
            "59347/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   8]\n",
            "59348/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.46, acc. (on x_fake)  14]\n",
            "59349/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)  12]\n",
            "59350/60000 [D 0.16, acc. (on x_real and x_fake)  77] [G 0.48, acc. (on x_fake)   9]\n",
            "59351/60000 [D 0.20, acc. (on x_real and x_fake)  68] [G 0.47, acc. (on x_fake)  13]\n",
            "59352/60000 [D 0.19, acc. (on x_real and x_fake)  66] [G 0.48, acc. (on x_fake)   5]\n",
            "59353/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.50, acc. (on x_fake)   3]\n",
            "59354/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  10]\n",
            "59355/60000 [D 0.20, acc. (on x_real and x_fake)  65] [G 0.48, acc. (on x_fake)  12]\n",
            "59356/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.45, acc. (on x_fake)   9]\n",
            "59357/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  11]\n",
            "59358/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)   9]\n",
            "59359/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.53, acc. (on x_fake)   9]\n",
            "59360/60000 [D 0.16, acc. (on x_real and x_fake)  82] [G 0.47, acc. (on x_fake)   9]\n",
            "59361/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.46, acc. (on x_fake)  12]\n",
            "59362/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)   9]\n",
            "59363/60000 [D 0.15, acc. (on x_real and x_fake)  82] [G 0.52, acc. (on x_fake)   9]\n",
            "59364/60000 [D 0.19, acc. (on x_real and x_fake)  68] [G 0.50, acc. (on x_fake)   3]\n",
            "59365/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.48, acc. (on x_fake)   8]\n",
            "59366/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)  15]\n",
            "59367/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.45, acc. (on x_fake)   9]\n",
            "59368/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.45, acc. (on x_fake)  15]\n",
            "59369/60000 [D 0.15, acc. (on x_real and x_fake)  78] [G 0.48, acc. (on x_fake)  10]\n",
            "59370/60000 [D 0.20, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)  12]\n",
            "59371/60000 [D 0.17, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)   7]\n",
            "59372/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.50, acc. (on x_fake)   4]\n",
            "59373/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)  10]\n",
            "59374/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.47, acc. (on x_fake)  10]\n",
            "59375/60000 [D 0.17, acc. (on x_real and x_fake)  79] [G 0.51, acc. (on x_fake)  10]\n",
            "59376/60000 [D 0.18, acc. (on x_real and x_fake)  70] [G 0.50, acc. (on x_fake)   6]\n",
            "59377/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.50, acc. (on x_fake)   9]\n",
            "59378/60000 [D 0.20, acc. (on x_real and x_fake)  71] [G 0.44, acc. (on x_fake)  14]\n",
            "59379/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.46, acc. (on x_fake)  11]\n",
            "59380/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)   9]\n",
            "59381/60000 [D 0.21, acc. (on x_real and x_fake)  63] [G 0.46, acc. (on x_fake)  19]\n",
            "59382/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)  16]\n",
            "59383/60000 [D 0.18, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)  10]\n",
            "59384/60000 [D 0.18, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)  10]\n",
            "59385/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.52, acc. (on x_fake)   3]\n",
            "59386/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  12]\n",
            "59387/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)   4]\n",
            "59388/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.49, acc. (on x_fake)  13]\n",
            "59389/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.45, acc. (on x_fake)  15]\n",
            "59390/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  10]\n",
            "59391/60000 [D 0.16, acc. (on x_real and x_fake)  77] [G 0.52, acc. (on x_fake)   8]\n",
            "59392/60000 [D 0.16, acc. (on x_real and x_fake)  76] [G 0.51, acc. (on x_fake)  11]\n",
            "59393/60000 [D 0.17, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)  18]\n",
            "59394/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.50, acc. (on x_fake)  10]\n",
            "59395/60000 [D 0.16, acc. (on x_real and x_fake)  78] [G 0.49, acc. (on x_fake)   8]\n",
            "59396/60000 [D 0.17, acc. (on x_real and x_fake)  72] [G 0.50, acc. (on x_fake)  10]\n",
            "59397/60000 [D 0.20, acc. (on x_real and x_fake)  70] [G 0.52, acc. (on x_fake)   7]\n",
            "59398/60000 [D 0.18, acc. (on x_real and x_fake)  69] [G 0.49, acc. (on x_fake)   7]\n",
            "59399/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.44, acc. (on x_fake)  11]\n",
            "59400/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)   9]\n",
            "59401/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  12]\n",
            "59402/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  13]\n",
            "59403/60000 [D 0.18, acc. (on x_real and x_fake)  70] [G 0.52, acc. (on x_fake)   3]\n",
            "59404/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)  10]\n",
            "59405/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.50, acc. (on x_fake)   8]\n",
            "59406/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  11]\n",
            "59407/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.45, acc. (on x_fake)  17]\n",
            "59408/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  11]\n",
            "59409/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.51, acc. (on x_fake)   6]\n",
            "59410/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.49, acc. (on x_fake)  17]\n",
            "59411/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)  11]\n",
            "59412/60000 [D 0.16, acc. (on x_real and x_fake)  76] [G 0.49, acc. (on x_fake)   7]\n",
            "59413/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.47, acc. (on x_fake)  11]\n",
            "59414/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)   6]\n",
            "59415/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.45, acc. (on x_fake)  13]\n",
            "59416/60000 [D 0.17, acc. (on x_real and x_fake)  79] [G 0.47, acc. (on x_fake)  10]\n",
            "59417/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.51, acc. (on x_fake)   7]\n",
            "59418/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)  11]\n",
            "59419/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.46, acc. (on x_fake)   8]\n",
            "59420/60000 [D 0.20, acc. (on x_real and x_fake)  68] [G 0.49, acc. (on x_fake)   7]\n",
            "59421/60000 [D 0.18, acc. (on x_real and x_fake)  70] [G 0.49, acc. (on x_fake)   9]\n",
            "59422/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.51, acc. (on x_fake)  10]\n",
            "59423/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)   8]\n",
            "59424/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)   9]\n",
            "59425/60000 [D 0.21, acc. (on x_real and x_fake)  67] [G 0.46, acc. (on x_fake)  14]\n",
            "59426/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.52, acc. (on x_fake)   6]\n",
            "59427/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)   9]\n",
            "59428/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)  10]\n",
            "59429/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)   9]\n",
            "59430/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)  11]\n",
            "59431/60000 [D 0.15, acc. (on x_real and x_fake)  81] [G 0.50, acc. (on x_fake)  10]\n",
            "59432/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)   6]\n",
            "59433/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.50, acc. (on x_fake)   7]\n",
            "59434/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  12]\n",
            "59435/60000 [D 0.16, acc. (on x_real and x_fake)  77] [G 0.49, acc. (on x_fake)  13]\n",
            "59436/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  18]\n",
            "59437/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  13]\n",
            "59438/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)   5]\n",
            "59439/60000 [D 0.16, acc. (on x_real and x_fake)  77] [G 0.49, acc. (on x_fake)  13]\n",
            "59440/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)  12]\n",
            "59441/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)  13]\n",
            "59442/60000 [D 0.22, acc. (on x_real and x_fake)  62] [G 0.44, acc. (on x_fake)  15]\n",
            "59443/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)  12]\n",
            "59444/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)   9]\n",
            "59445/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.51, acc. (on x_fake)   3]\n",
            "59446/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.46, acc. (on x_fake)  11]\n",
            "59447/60000 [D 0.16, acc. (on x_real and x_fake)  79] [G 0.50, acc. (on x_fake)   5]\n",
            "59448/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)   7]\n",
            "59449/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.50, acc. (on x_fake)  10]\n",
            "59450/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  13]\n",
            "59451/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.47, acc. (on x_fake)  12]\n",
            "59452/60000 [D 0.21, acc. (on x_real and x_fake)  66] [G 0.45, acc. (on x_fake)  15]\n",
            "59453/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.47, acc. (on x_fake)  12]\n",
            "59454/60000 [D 0.20, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)  11]\n",
            "59455/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  11]\n",
            "59456/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.50, acc. (on x_fake)   6]\n",
            "59457/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.48, acc. (on x_fake)   7]\n",
            "59458/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)   8]\n",
            "59459/60000 [D 0.20, acc. (on x_real and x_fake)  68] [G 0.47, acc. (on x_fake)  15]\n",
            "59460/60000 [D 0.15, acc. (on x_real and x_fake)  83] [G 0.52, acc. (on x_fake)  12]\n",
            "59461/60000 [D 0.20, acc. (on x_real and x_fake)  70] [G 0.46, acc. (on x_fake)  17]\n",
            "59462/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)  15]\n",
            "59463/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)  13]\n",
            "59464/60000 [D 0.19, acc. (on x_real and x_fake)  66] [G 0.50, acc. (on x_fake)  13]\n",
            "59465/60000 [D 0.16, acc. (on x_real and x_fake)  79] [G 0.49, acc. (on x_fake)  10]\n",
            "59466/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.49, acc. (on x_fake)  11]\n",
            "59467/60000 [D 0.20, acc. (on x_real and x_fake)  68] [G 0.47, acc. (on x_fake)   9]\n",
            "59468/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)   9]\n",
            "59469/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)  15]\n",
            "59470/60000 [D 0.20, acc. (on x_real and x_fake)  68] [G 0.49, acc. (on x_fake)   9]\n",
            "59471/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)   8]\n",
            "59472/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.50, acc. (on x_fake)   9]\n",
            "59473/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.45, acc. (on x_fake)   8]\n",
            "59474/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)   6]\n",
            "59475/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  11]\n",
            "59476/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)  11]\n",
            "59477/60000 [D 0.18, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)  12]\n",
            "59478/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   7]\n",
            "59479/60000 [D 0.22, acc. (on x_real and x_fake)  66] [G 0.46, acc. (on x_fake)  11]\n",
            "59480/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)   9]\n",
            "59481/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)   9]\n",
            "59482/60000 [D 0.18, acc. (on x_real and x_fake)  77] [G 0.50, acc. (on x_fake)   6]\n",
            "59483/60000 [D 0.19, acc. (on x_real and x_fake)  66] [G 0.45, acc. (on x_fake)  14]\n",
            "59484/60000 [D 0.19, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)   6]\n",
            "59485/60000 [D 0.20, acc. (on x_real and x_fake)  66] [G 0.47, acc. (on x_fake)  11]\n",
            "59486/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)   7]\n",
            "59487/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)  10]\n",
            "59488/60000 [D 0.21, acc. (on x_real and x_fake)  66] [G 0.43, acc. (on x_fake)  16]\n",
            "59489/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)  11]\n",
            "59490/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  12]\n",
            "59491/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.48, acc. (on x_fake)   5]\n",
            "59492/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)  11]\n",
            "59493/60000 [D 0.19, acc. (on x_real and x_fake)  68] [G 0.51, acc. (on x_fake)   4]\n",
            "59494/60000 [D 0.19, acc. (on x_real and x_fake)  68] [G 0.48, acc. (on x_fake)  13]\n",
            "59495/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)   7]\n",
            "59496/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)   9]\n",
            "59497/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.46, acc. (on x_fake)  14]\n",
            "59498/60000 [D 0.17, acc. (on x_real and x_fake)  79] [G 0.47, acc. (on x_fake)  16]\n",
            "59499/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.44, acc. (on x_fake)  16]\n",
            "59500/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  11]\n",
            "59501/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.50, acc. (on x_fake)   8]\n",
            "59502/60000 [D 0.17, acc. (on x_real and x_fake)  79] [G 0.50, acc. (on x_fake)  10]\n",
            "59503/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)  11]\n",
            "59504/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.51, acc. (on x_fake)   6]\n",
            "59505/60000 [D 0.15, acc. (on x_real and x_fake)  82] [G 0.52, acc. (on x_fake)   7]\n",
            "59506/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.50, acc. (on x_fake)  10]\n",
            "59507/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)   9]\n",
            "59508/60000 [D 0.18, acc. (on x_real and x_fake)  77] [G 0.48, acc. (on x_fake)  14]\n",
            "59509/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.47, acc. (on x_fake)  12]\n",
            "59510/60000 [D 0.16, acc. (on x_real and x_fake)  78] [G 0.48, acc. (on x_fake)  16]\n",
            "59511/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)  14]\n",
            "59512/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.49, acc. (on x_fake)   7]\n",
            "59513/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.49, acc. (on x_fake)  11]\n",
            "59514/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)   7]\n",
            "59515/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)   7]\n",
            "59516/60000 [D 0.18, acc. (on x_real and x_fake)  77] [G 0.49, acc. (on x_fake)  14]\n",
            "59517/60000 [D 0.17, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)  10]\n",
            "59518/60000 [D 0.16, acc. (on x_real and x_fake)  79] [G 0.49, acc. (on x_fake)   9]\n",
            "59519/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)  10]\n",
            "59520/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.51, acc. (on x_fake)   9]\n",
            "59521/60000 [D 0.16, acc. (on x_real and x_fake)  77] [G 0.50, acc. (on x_fake)   9]\n",
            "59522/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)   8]\n",
            "59523/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)  10]\n",
            "59524/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)   6]\n",
            "59525/60000 [D 0.16, acc. (on x_real and x_fake)  78] [G 0.50, acc. (on x_fake)   8]\n",
            "59526/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.49, acc. (on x_fake)  11]\n",
            "59527/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.49, acc. (on x_fake)   9]\n",
            "59528/60000 [D 0.15, acc. (on x_real and x_fake)  83] [G 0.51, acc. (on x_fake)   8]\n",
            "59529/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)   9]\n",
            "59530/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)  12]\n",
            "59531/60000 [D 0.17, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)  11]\n",
            "59532/60000 [D 0.16, acc. (on x_real and x_fake)  78] [G 0.51, acc. (on x_fake)   7]\n",
            "59533/60000 [D 0.18, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)   7]\n",
            "59534/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.48, acc. (on x_fake)   7]\n",
            "59535/60000 [D 0.18, acc. (on x_real and x_fake)  70] [G 0.48, acc. (on x_fake)   9]\n",
            "59536/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  13]\n",
            "59537/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.51, acc. (on x_fake)  10]\n",
            "59538/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)  12]\n",
            "59539/60000 [D 0.20, acc. (on x_real and x_fake)  68] [G 0.45, acc. (on x_fake)  11]\n",
            "59540/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)  13]\n",
            "59541/60000 [D 0.20, acc. (on x_real and x_fake)  63] [G 0.45, acc. (on x_fake)  10]\n",
            "59542/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.49, acc. (on x_fake)  12]\n",
            "59543/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.45, acc. (on x_fake)   9]\n",
            "59544/60000 [D 0.16, acc. (on x_real and x_fake)  80] [G 0.48, acc. (on x_fake)  14]\n",
            "59545/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.48, acc. (on x_fake)  10]\n",
            "59546/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  10]\n",
            "59547/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.50, acc. (on x_fake)  12]\n",
            "59548/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.46, acc. (on x_fake)  12]\n",
            "59549/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.50, acc. (on x_fake)  14]\n",
            "59550/60000 [D 0.20, acc. (on x_real and x_fake)  66] [G 0.48, acc. (on x_fake)  13]\n",
            "59551/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.51, acc. (on x_fake)  11]\n",
            "59552/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.50, acc. (on x_fake)   3]\n",
            "59553/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.49, acc. (on x_fake)  10]\n",
            "59554/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)  10]\n",
            "59555/60000 [D 0.19, acc. (on x_real and x_fake)  75] [G 0.46, acc. (on x_fake)  12]\n",
            "59556/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.46, acc. (on x_fake)  12]\n",
            "59557/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.49, acc. (on x_fake)  10]\n",
            "59558/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  11]\n",
            "59559/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  13]\n",
            "59560/60000 [D 0.20, acc. (on x_real and x_fake)  66] [G 0.47, acc. (on x_fake)  11]\n",
            "59561/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.46, acc. (on x_fake)  17]\n",
            "59562/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)   5]\n",
            "59563/60000 [D 0.15, acc. (on x_real and x_fake)  80] [G 0.50, acc. (on x_fake)   7]\n",
            "59564/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)   7]\n",
            "59565/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.49, acc. (on x_fake)   6]\n",
            "59566/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)  12]\n",
            "59567/60000 [D 0.19, acc. (on x_real and x_fake)  66] [G 0.49, acc. (on x_fake)   7]\n",
            "59568/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  13]\n",
            "59569/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)  12]\n",
            "59570/60000 [D 0.20, acc. (on x_real and x_fake)  67] [G 0.45, acc. (on x_fake)  19]\n",
            "59571/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.47, acc. (on x_fake)  10]\n",
            "59572/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)  11]\n",
            "59573/60000 [D 0.16, acc. (on x_real and x_fake)  81] [G 0.47, acc. (on x_fake)  11]\n",
            "59574/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.49, acc. (on x_fake)   4]\n",
            "59575/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)  10]\n",
            "59576/60000 [D 0.21, acc. (on x_real and x_fake)  67] [G 0.47, acc. (on x_fake)  12]\n",
            "59577/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.46, acc. (on x_fake)  12]\n",
            "59578/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)   8]\n",
            "59579/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.50, acc. (on x_fake)   9]\n",
            "59580/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.48, acc. (on x_fake)  15]\n",
            "59581/60000 [D 0.20, acc. (on x_real and x_fake)  67] [G 0.46, acc. (on x_fake)  17]\n",
            "59582/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)  13]\n",
            "59583/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.50, acc. (on x_fake)   5]\n",
            "59584/60000 [D 0.21, acc. (on x_real and x_fake)  68] [G 0.49, acc. (on x_fake)   5]\n",
            "59585/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.50, acc. (on x_fake)  10]\n",
            "59586/60000 [D 0.19, acc. (on x_real and x_fake)  68] [G 0.48, acc. (on x_fake)  10]\n",
            "59587/60000 [D 0.19, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  13]\n",
            "59588/60000 [D 0.19, acc. (on x_real and x_fake)  68] [G 0.45, acc. (on x_fake)  13]\n",
            "59589/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)   9]\n",
            "59590/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.48, acc. (on x_fake)   9]\n",
            "59591/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.46, acc. (on x_fake)  11]\n",
            "59592/60000 [D 0.16, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)   8]\n",
            "59593/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.46, acc. (on x_fake)  11]\n",
            "59594/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.45, acc. (on x_fake)  13]\n",
            "59595/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)   8]\n",
            "59596/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)  12]\n",
            "59597/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)   9]\n",
            "59598/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)  11]\n",
            "59599/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.50, acc. (on x_fake)  13]\n",
            "59600/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)  15]\n",
            "59601/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)  12]\n",
            "59602/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.46, acc. (on x_fake)  15]\n",
            "59603/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)  14]\n",
            "59604/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.46, acc. (on x_fake)  14]\n",
            "59605/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.46, acc. (on x_fake)  13]\n",
            "59606/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.48, acc. (on x_fake)  15]\n",
            "59607/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)   8]\n",
            "59608/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)  13]\n",
            "59609/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.49, acc. (on x_fake)  11]\n",
            "59610/60000 [D 0.21, acc. (on x_real and x_fake)  66] [G 0.47, acc. (on x_fake)  12]\n",
            "59611/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.50, acc. (on x_fake)   8]\n",
            "59612/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   5]\n",
            "59613/60000 [D 0.21, acc. (on x_real and x_fake)  71] [G 0.45, acc. (on x_fake)   9]\n",
            "59614/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.46, acc. (on x_fake)  10]\n",
            "59615/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.46, acc. (on x_fake)  11]\n",
            "59616/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.52, acc. (on x_fake)   7]\n",
            "59617/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.45, acc. (on x_fake)  13]\n",
            "59618/60000 [D 0.16, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)  10]\n",
            "59619/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   7]\n",
            "59620/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.48, acc. (on x_fake)  13]\n",
            "59621/60000 [D 0.20, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)   9]\n",
            "59622/60000 [D 0.16, acc. (on x_real and x_fake)  76] [G 0.48, acc. (on x_fake)  14]\n",
            "59623/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.48, acc. (on x_fake)  12]\n",
            "59624/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.46, acc. (on x_fake)  16]\n",
            "59625/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)   9]\n",
            "59626/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)  11]\n",
            "59627/60000 [D 0.16, acc. (on x_real and x_fake)  77] [G 0.52, acc. (on x_fake)   5]\n",
            "59628/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.50, acc. (on x_fake)  14]\n",
            "59629/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  14]\n",
            "59630/60000 [D 0.20, acc. (on x_real and x_fake)  70] [G 0.48, acc. (on x_fake)   6]\n",
            "59631/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.53, acc. (on x_fake)   5]\n",
            "59632/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.48, acc. (on x_fake)  15]\n",
            "59633/60000 [D 0.17, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  10]\n",
            "59634/60000 [D 0.20, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)   8]\n",
            "59635/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.49, acc. (on x_fake)  11]\n",
            "59636/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.50, acc. (on x_fake)   7]\n",
            "59637/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.46, acc. (on x_fake)  16]\n",
            "59638/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)   9]\n",
            "59639/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.46, acc. (on x_fake)  20]\n",
            "59640/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  10]\n",
            "59641/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)   6]\n",
            "59642/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   8]\n",
            "59643/60000 [D 0.20, acc. (on x_real and x_fake)  67] [G 0.45, acc. (on x_fake)  13]\n",
            "59644/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  15]\n",
            "59645/60000 [D 0.21, acc. (on x_real and x_fake)  67] [G 0.49, acc. (on x_fake)   8]\n",
            "59646/60000 [D 0.20, acc. (on x_real and x_fake)  68] [G 0.46, acc. (on x_fake)   7]\n",
            "59647/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  10]\n",
            "59648/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.50, acc. (on x_fake)  14]\n",
            "59649/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)  16]\n",
            "59650/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.46, acc. (on x_fake)  11]\n",
            "59651/60000 [D 0.19, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  10]\n",
            "59652/60000 [D 0.19, acc. (on x_real and x_fake)  76] [G 0.47, acc. (on x_fake)   9]\n",
            "59653/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.46, acc. (on x_fake)  14]\n",
            "59654/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.50, acc. (on x_fake)   8]\n",
            "59655/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.46, acc. (on x_fake)  14]\n",
            "59656/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)  11]\n",
            "59657/60000 [D 0.20, acc. (on x_real and x_fake)  68] [G 0.50, acc. (on x_fake)   6]\n",
            "59658/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.51, acc. (on x_fake)   3]\n",
            "59659/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)   8]\n",
            "59660/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)   9]\n",
            "59661/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.47, acc. (on x_fake)  13]\n",
            "59662/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)   7]\n",
            "59663/60000 [D 0.20, acc. (on x_real and x_fake)  63] [G 0.45, acc. (on x_fake)  16]\n",
            "59664/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.50, acc. (on x_fake)   5]\n",
            "59665/60000 [D 0.16, acc. (on x_real and x_fake)  77] [G 0.46, acc. (on x_fake)  11]\n",
            "59666/60000 [D 0.20, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  16]\n",
            "59667/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   6]\n",
            "59668/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.47, acc. (on x_fake)  11]\n",
            "59669/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)   8]\n",
            "59670/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)  11]\n",
            "59671/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)  13]\n",
            "59672/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)   5]\n",
            "59673/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.51, acc. (on x_fake)   8]\n",
            "59674/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.52, acc. (on x_fake)   8]\n",
            "59675/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.50, acc. (on x_fake)  10]\n",
            "59676/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)  13]\n",
            "59677/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.46, acc. (on x_fake)  12]\n",
            "59678/60000 [D 0.19, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)   9]\n",
            "59679/60000 [D 0.19, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)  13]\n",
            "59680/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.48, acc. (on x_fake)   7]\n",
            "59681/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.46, acc. (on x_fake)  16]\n",
            "59682/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  15]\n",
            "59683/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.51, acc. (on x_fake)   9]\n",
            "59684/60000 [D 0.16, acc. (on x_real and x_fake)  81] [G 0.51, acc. (on x_fake)  11]\n",
            "59685/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  16]\n",
            "59686/60000 [D 0.17, acc. (on x_real and x_fake)  73] [G 0.50, acc. (on x_fake)   8]\n",
            "59687/60000 [D 0.20, acc. (on x_real and x_fake)  70] [G 0.49, acc. (on x_fake)   8]\n",
            "59688/60000 [D 0.15, acc. (on x_real and x_fake)  80] [G 0.52, acc. (on x_fake)  10]\n",
            "59689/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.53, acc. (on x_fake)   6]\n",
            "59690/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.51, acc. (on x_fake)   7]\n",
            "59691/60000 [D 0.21, acc. (on x_real and x_fake)  66] [G 0.45, acc. (on x_fake)  16]\n",
            "59692/60000 [D 0.19, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)   6]\n",
            "59693/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)   8]\n",
            "59694/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)  10]\n",
            "59695/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  14]\n",
            "59696/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.49, acc. (on x_fake)  10]\n",
            "59697/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.46, acc. (on x_fake)  13]\n",
            "59698/60000 [D 0.17, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  14]\n",
            "59699/60000 [D 0.20, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)  13]\n",
            "59700/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)  11]\n",
            "59701/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)  11]\n",
            "59702/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)   8]\n",
            "59703/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.50, acc. (on x_fake)   6]\n",
            "59704/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  16]\n",
            "59705/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)  10]\n",
            "59706/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  17]\n",
            "59707/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)  14]\n",
            "59708/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.43, acc. (on x_fake)  20]\n",
            "59709/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.45, acc. (on x_fake)  11]\n",
            "59710/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.51, acc. (on x_fake)  10]\n",
            "59711/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)   9]\n",
            "59712/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)  11]\n",
            "59713/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.52, acc. (on x_fake)   9]\n",
            "59714/60000 [D 0.19, acc. (on x_real and x_fake)  68] [G 0.45, acc. (on x_fake)  15]\n",
            "59715/60000 [D 0.20, acc. (on x_real and x_fake)  71] [G 0.47, acc. (on x_fake)  13]\n",
            "59716/60000 [D 0.21, acc. (on x_real and x_fake)  64] [G 0.47, acc. (on x_fake)  12]\n",
            "59717/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   6]\n",
            "59718/60000 [D 0.15, acc. (on x_real and x_fake)  79] [G 0.51, acc. (on x_fake)   7]\n",
            "59719/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.45, acc. (on x_fake)  13]\n",
            "59720/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.47, acc. (on x_fake)   6]\n",
            "59721/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)  12]\n",
            "59722/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  10]\n",
            "59723/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.46, acc. (on x_fake)  16]\n",
            "59724/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)  15]\n",
            "59725/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.44, acc. (on x_fake)  14]\n",
            "59726/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.45, acc. (on x_fake)  12]\n",
            "59727/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.51, acc. (on x_fake)   7]\n",
            "59728/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.46, acc. (on x_fake)  16]\n",
            "59729/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)   8]\n",
            "59730/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.51, acc. (on x_fake)  10]\n",
            "59731/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)  10]\n",
            "59732/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)   9]\n",
            "59733/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.44, acc. (on x_fake)  14]\n",
            "59734/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.46, acc. (on x_fake)  16]\n",
            "59735/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)   9]\n",
            "59736/60000 [D 0.20, acc. (on x_real and x_fake)  71] [G 0.47, acc. (on x_fake)   8]\n",
            "59737/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.48, acc. (on x_fake)   9]\n",
            "59738/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.49, acc. (on x_fake)  11]\n",
            "59739/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.50, acc. (on x_fake)  12]\n",
            "59740/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  16]\n",
            "59741/60000 [D 0.16, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)   8]\n",
            "59742/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.48, acc. (on x_fake)  12]\n",
            "59743/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)  13]\n",
            "59744/60000 [D 0.21, acc. (on x_real and x_fake)  66] [G 0.47, acc. (on x_fake)  13]\n",
            "59745/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  12]\n",
            "59746/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.50, acc. (on x_fake)  17]\n",
            "59747/60000 [D 0.19, acc. (on x_real and x_fake)  68] [G 0.50, acc. (on x_fake)  11]\n",
            "59748/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.45, acc. (on x_fake)  15]\n",
            "59749/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.49, acc. (on x_fake)  10]\n",
            "59750/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   9]\n",
            "59751/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)  12]\n",
            "59752/60000 [D 0.20, acc. (on x_real and x_fake)  66] [G 0.50, acc. (on x_fake)   6]\n",
            "59753/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.48, acc. (on x_fake)   9]\n",
            "59754/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)   7]\n",
            "59755/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)  10]\n",
            "59756/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.50, acc. (on x_fake)   8]\n",
            "59757/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)   9]\n",
            "59758/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.50, acc. (on x_fake)   8]\n",
            "59759/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)  12]\n",
            "59760/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.48, acc. (on x_fake)  12]\n",
            "59761/60000 [D 0.16, acc. (on x_real and x_fake)  76] [G 0.48, acc. (on x_fake)  13]\n",
            "59762/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.47, acc. (on x_fake)  12]\n",
            "59763/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)  11]\n",
            "59764/60000 [D 0.16, acc. (on x_real and x_fake)  78] [G 0.48, acc. (on x_fake)   9]\n",
            "59765/60000 [D 0.15, acc. (on x_real and x_fake)  81] [G 0.50, acc. (on x_fake)   9]\n",
            "59766/60000 [D 0.16, acc. (on x_real and x_fake)  80] [G 0.48, acc. (on x_fake)  12]\n",
            "59767/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.53, acc. (on x_fake)   7]\n",
            "59768/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.48, acc. (on x_fake)  12]\n",
            "59769/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)   9]\n",
            "59770/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  10]\n",
            "59771/60000 [D 0.16, acc. (on x_real and x_fake)  77] [G 0.49, acc. (on x_fake)  12]\n",
            "59772/60000 [D 0.21, acc. (on x_real and x_fake)  65] [G 0.48, acc. (on x_fake)  12]\n",
            "59773/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.47, acc. (on x_fake)   9]\n",
            "59774/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.50, acc. (on x_fake)  13]\n",
            "59775/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.49, acc. (on x_fake)   9]\n",
            "59776/60000 [D 0.19, acc. (on x_real and x_fake)  76] [G 0.43, acc. (on x_fake)  14]\n",
            "59777/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)  14]\n",
            "59778/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  10]\n",
            "59779/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)   7]\n",
            "59780/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.51, acc. (on x_fake)  10]\n",
            "59781/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.51, acc. (on x_fake)   8]\n",
            "59782/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.50, acc. (on x_fake)   5]\n",
            "59783/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.51, acc. (on x_fake)   9]\n",
            "59784/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.46, acc. (on x_fake)  13]\n",
            "59785/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.46, acc. (on x_fake)  16]\n",
            "59786/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.51, acc. (on x_fake)   6]\n",
            "59787/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.46, acc. (on x_fake)  13]\n",
            "59788/60000 [D 0.19, acc. (on x_real and x_fake)  68] [G 0.45, acc. (on x_fake)  13]\n",
            "59789/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.51, acc. (on x_fake)   8]\n",
            "59790/60000 [D 0.17, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)   9]\n",
            "59791/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.51, acc. (on x_fake)   6]\n",
            "59792/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  10]\n",
            "59793/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)  10]\n",
            "59794/60000 [D 0.19, acc. (on x_real and x_fake)  68] [G 0.45, acc. (on x_fake)  14]\n",
            "59795/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)   4]\n",
            "59796/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)   5]\n",
            "59797/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)  12]\n",
            "59798/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  14]\n",
            "59799/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.49, acc. (on x_fake)   8]\n",
            "59800/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)   7]\n",
            "59801/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.49, acc. (on x_fake)  13]\n",
            "59802/60000 [D 0.20, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)  12]\n",
            "59803/60000 [D 0.18, acc. (on x_real and x_fake)  78] [G 0.51, acc. (on x_fake)   8]\n",
            "59804/60000 [D 0.16, acc. (on x_real and x_fake)  78] [G 0.49, acc. (on x_fake)  14]\n",
            "59805/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)  11]\n",
            "59806/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)   6]\n",
            "59807/60000 [D 0.15, acc. (on x_real and x_fake)  79] [G 0.53, acc. (on x_fake)   7]\n",
            "59808/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)  11]\n",
            "59809/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)   9]\n",
            "59810/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.47, acc. (on x_fake)   7]\n",
            "59811/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)   5]\n",
            "59812/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.46, acc. (on x_fake)  16]\n",
            "59813/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)   9]\n",
            "59814/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)  10]\n",
            "59815/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)  13]\n",
            "59816/60000 [D 0.20, acc. (on x_real and x_fake)  70] [G 0.49, acc. (on x_fake)   7]\n",
            "59817/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  10]\n",
            "59818/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)  11]\n",
            "59819/60000 [D 0.20, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)   8]\n",
            "59820/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)   4]\n",
            "59821/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.51, acc. (on x_fake)   4]\n",
            "59822/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.46, acc. (on x_fake)  11]\n",
            "59823/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)   5]\n",
            "59824/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.50, acc. (on x_fake)  10]\n",
            "59825/60000 [D 0.16, acc. (on x_real and x_fake)  77] [G 0.53, acc. (on x_fake)   9]\n",
            "59826/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.50, acc. (on x_fake)   9]\n",
            "59827/60000 [D 0.16, acc. (on x_real and x_fake)  80] [G 0.50, acc. (on x_fake)   4]\n",
            "59828/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.46, acc. (on x_fake)  13]\n",
            "59829/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.45, acc. (on x_fake)  15]\n",
            "59830/60000 [D 0.17, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)  11]\n",
            "59831/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.46, acc. (on x_fake)  17]\n",
            "59832/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)  11]\n",
            "59833/60000 [D 0.17, acc. (on x_real and x_fake)  72] [G 0.51, acc. (on x_fake)   6]\n",
            "59834/60000 [D 0.18, acc. (on x_real and x_fake)  69] [G 0.53, acc. (on x_fake)  10]\n",
            "59835/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)  13]\n",
            "59836/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.51, acc. (on x_fake)   7]\n",
            "59837/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.51, acc. (on x_fake)   9]\n",
            "59838/60000 [D 0.17, acc. (on x_real and x_fake)  73] [G 0.52, acc. (on x_fake)   8]\n",
            "59839/60000 [D 0.20, acc. (on x_real and x_fake)  70] [G 0.49, acc. (on x_fake)   9]\n",
            "59840/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  14]\n",
            "59841/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.50, acc. (on x_fake)   5]\n",
            "59842/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)  10]\n",
            "59843/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.45, acc. (on x_fake)  14]\n",
            "59844/60000 [D 0.20, acc. (on x_real and x_fake)  67] [G 0.50, acc. (on x_fake)   7]\n",
            "59845/60000 [D 0.16, acc. (on x_real and x_fake)  78] [G 0.47, acc. (on x_fake)  12]\n",
            "59846/60000 [D 0.20, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)   5]\n",
            "59847/60000 [D 0.15, acc. (on x_real and x_fake)  83] [G 0.53, acc. (on x_fake)   9]\n",
            "59848/60000 [D 0.20, acc. (on x_real and x_fake)  68] [G 0.46, acc. (on x_fake)  11]\n",
            "59849/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.52, acc. (on x_fake)   6]\n",
            "59850/60000 [D 0.19, acc. (on x_real and x_fake)  68] [G 0.49, acc. (on x_fake)   7]\n",
            "59851/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.51, acc. (on x_fake)  11]\n",
            "59852/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.51, acc. (on x_fake)   8]\n",
            "59853/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.48, acc. (on x_fake)  11]\n",
            "59854/60000 [D 0.20, acc. (on x_real and x_fake)  70] [G 0.46, acc. (on x_fake)  13]\n",
            "59855/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)   7]\n",
            "59856/60000 [D 0.18, acc. (on x_real and x_fake)  69] [G 0.51, acc. (on x_fake)  10]\n",
            "59857/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.47, acc. (on x_fake)   7]\n",
            "59858/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.46, acc. (on x_fake)  12]\n",
            "59859/60000 [D 0.18, acc. (on x_real and x_fake)  77] [G 0.51, acc. (on x_fake)   5]\n",
            "59860/60000 [D 0.18, acc. (on x_real and x_fake)  78] [G 0.49, acc. (on x_fake)  13]\n",
            "59861/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.50, acc. (on x_fake)  13]\n",
            "59862/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)   9]\n",
            "59863/60000 [D 0.19, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  16]\n",
            "59864/60000 [D 0.20, acc. (on x_real and x_fake)  70] [G 0.46, acc. (on x_fake)  10]\n",
            "59865/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)   9]\n",
            "59866/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.46, acc. (on x_fake)  13]\n",
            "59867/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)   9]\n",
            "59868/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)   9]\n",
            "59869/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)   8]\n",
            "59870/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.49, acc. (on x_fake)  10]\n",
            "59871/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.51, acc. (on x_fake)   9]\n",
            "59872/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)   9]\n",
            "59873/60000 [D 0.20, acc. (on x_real and x_fake)  67] [G 0.48, acc. (on x_fake)   9]\n",
            "59874/60000 [D 0.16, acc. (on x_real and x_fake)  79] [G 0.47, acc. (on x_fake)  10]\n",
            "59875/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.53, acc. (on x_fake)   5]\n",
            "59876/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)  10]\n",
            "59877/60000 [D 0.21, acc. (on x_real and x_fake)  66] [G 0.47, acc. (on x_fake)  11]\n",
            "59878/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  11]\n",
            "59879/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  14]\n",
            "59880/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.49, acc. (on x_fake)  14]\n",
            "59881/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.51, acc. (on x_fake)  10]\n",
            "59882/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  14]\n",
            "59883/60000 [D 0.16, acc. (on x_real and x_fake)  80] [G 0.50, acc. (on x_fake)   6]\n",
            "59884/60000 [D 0.20, acc. (on x_real and x_fake)  67] [G 0.45, acc. (on x_fake)  15]\n",
            "59885/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)   9]\n",
            "59886/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  13]\n",
            "59887/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.46, acc. (on x_fake)  10]\n",
            "59888/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.46, acc. (on x_fake)  13]\n",
            "59889/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.51, acc. (on x_fake)  11]\n",
            "59890/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.49, acc. (on x_fake)   8]\n",
            "59891/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.49, acc. (on x_fake)  11]\n",
            "59892/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  12]\n",
            "59893/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.46, acc. (on x_fake)  12]\n",
            "59894/60000 [D 0.17, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)  13]\n",
            "59895/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)   1]\n",
            "59896/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.50, acc. (on x_fake)   4]\n",
            "59897/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.45, acc. (on x_fake)  15]\n",
            "59898/60000 [D 0.17, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)   4]\n",
            "59899/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.52, acc. (on x_fake)   8]\n",
            "59900/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.48, acc. (on x_fake)   9]\n",
            "59901/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.50, acc. (on x_fake)   5]\n",
            "59902/60000 [D 0.20, acc. (on x_real and x_fake)  66] [G 0.48, acc. (on x_fake)   8]\n",
            "59903/60000 [D 0.17, acc. (on x_real and x_fake)  80] [G 0.47, acc. (on x_fake)   9]\n",
            "59904/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)   7]\n",
            "59905/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.51, acc. (on x_fake)   7]\n",
            "59906/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  10]\n",
            "59907/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)   9]\n",
            "59908/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)  10]\n",
            "59909/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  12]\n",
            "59910/60000 [D 0.17, acc. (on x_real and x_fake)  78] [G 0.50, acc. (on x_fake)  14]\n",
            "59911/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   9]\n",
            "59912/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)   7]\n",
            "59913/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.46, acc. (on x_fake)   8]\n",
            "59914/60000 [D 0.18, acc. (on x_real and x_fake)  77] [G 0.50, acc. (on x_fake)   9]\n",
            "59915/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.46, acc. (on x_fake)  17]\n",
            "59916/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.47, acc. (on x_fake)  10]\n",
            "59917/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  10]\n",
            "59918/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.49, acc. (on x_fake)   7]\n",
            "59919/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)  12]\n",
            "59920/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.50, acc. (on x_fake)   7]\n",
            "59921/60000 [D 0.20, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   9]\n",
            "59922/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  14]\n",
            "59923/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)  10]\n",
            "59924/60000 [D 0.18, acc. (on x_real and x_fake)  76] [G 0.46, acc. (on x_fake)  14]\n",
            "59925/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.49, acc. (on x_fake)  10]\n",
            "59926/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)  12]\n",
            "59927/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.52, acc. (on x_fake)   9]\n",
            "59928/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.50, acc. (on x_fake)  10]\n",
            "59929/60000 [D 0.20, acc. (on x_real and x_fake)  63] [G 0.48, acc. (on x_fake)  15]\n",
            "59930/60000 [D 0.17, acc. (on x_real and x_fake)  76] [G 0.49, acc. (on x_fake)  10]\n",
            "59931/60000 [D 0.20, acc. (on x_real and x_fake)  71] [G 0.46, acc. (on x_fake)  12]\n",
            "59932/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.48, acc. (on x_fake)  10]\n",
            "59933/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)   9]\n",
            "59934/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)   9]\n",
            "59935/60000 [D 0.16, acc. (on x_real and x_fake)  78] [G 0.52, acc. (on x_fake)   8]\n",
            "59936/60000 [D 0.16, acc. (on x_real and x_fake)  77] [G 0.51, acc. (on x_fake)   8]\n",
            "59937/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.47, acc. (on x_fake)   7]\n",
            "59938/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.45, acc. (on x_fake)  11]\n",
            "59939/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.50, acc. (on x_fake)  11]\n",
            "59940/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.45, acc. (on x_fake)  12]\n",
            "59941/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)  10]\n",
            "59942/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.47, acc. (on x_fake)   9]\n",
            "59943/60000 [D 0.19, acc. (on x_real and x_fake)  68] [G 0.46, acc. (on x_fake)  12]\n",
            "59944/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.48, acc. (on x_fake)   4]\n",
            "59945/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)   6]\n",
            "59946/60000 [D 0.20, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  12]\n",
            "59947/60000 [D 0.20, acc. (on x_real and x_fake)  67] [G 0.45, acc. (on x_fake)  12]\n",
            "59948/60000 [D 0.19, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)   7]\n",
            "59949/60000 [D 0.18, acc. (on x_real and x_fake)  70] [G 0.45, acc. (on x_fake)   7]\n",
            "59950/60000 [D 0.17, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  12]\n",
            "59951/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.50, acc. (on x_fake)   6]\n",
            "59952/60000 [D 0.19, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)   9]\n",
            "59953/60000 [D 0.18, acc. (on x_real and x_fake)  74] [G 0.50, acc. (on x_fake)   8]\n",
            "59954/60000 [D 0.17, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)  13]\n",
            "59955/60000 [D 0.20, acc. (on x_real and x_fake)  70] [G 0.47, acc. (on x_fake)  15]\n",
            "59956/60000 [D 0.20, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  10]\n",
            "59957/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  10]\n",
            "59958/60000 [D 0.17, acc. (on x_real and x_fake)  77] [G 0.51, acc. (on x_fake)   5]\n",
            "59959/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.49, acc. (on x_fake)  10]\n",
            "59960/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.50, acc. (on x_fake)   9]\n",
            "59961/60000 [D 0.15, acc. (on x_real and x_fake)  82] [G 0.50, acc. (on x_fake)   8]\n",
            "59962/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  14]\n",
            "59963/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.49, acc. (on x_fake)  10]\n",
            "59964/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)  10]\n",
            "59965/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)  14]\n",
            "59966/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  14]\n",
            "59967/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.46, acc. (on x_fake)  14]\n",
            "59968/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.48, acc. (on x_fake)  10]\n",
            "59969/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.49, acc. (on x_fake)   7]\n",
            "59970/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.45, acc. (on x_fake)  15]\n",
            "59971/60000 [D 0.21, acc. (on x_real and x_fake)  63] [G 0.47, acc. (on x_fake)  13]\n",
            "59972/60000 [D 0.20, acc. (on x_real and x_fake)  71] [G 0.45, acc. (on x_fake)  15]\n",
            "59973/60000 [D 0.18, acc. (on x_real and x_fake)  71] [G 0.48, acc. (on x_fake)   8]\n",
            "59974/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.51, acc. (on x_fake)   5]\n",
            "59975/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  12]\n",
            "59976/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.49, acc. (on x_fake)   9]\n",
            "59977/60000 [D 0.20, acc. (on x_real and x_fake)  69] [G 0.46, acc. (on x_fake)  14]\n",
            "59978/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  15]\n",
            "59979/60000 [D 0.19, acc. (on x_real and x_fake)  69] [G 0.50, acc. (on x_fake)  10]\n",
            "59980/60000 [D 0.18, acc. (on x_real and x_fake)  70] [G 0.49, acc. (on x_fake)  10]\n",
            "59981/60000 [D 0.17, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  14]\n",
            "59982/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  14]\n",
            "59983/60000 [D 0.19, acc. (on x_real and x_fake)  73] [G 0.46, acc. (on x_fake)  14]\n",
            "59984/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.50, acc. (on x_fake)  10]\n",
            "59985/60000 [D 0.20, acc. (on x_real and x_fake)  70] [G 0.48, acc. (on x_fake)  11]\n",
            "59986/60000 [D 0.20, acc. (on x_real and x_fake)  68] [G 0.48, acc. (on x_fake)  14]\n",
            "59987/60000 [D 0.19, acc. (on x_real and x_fake)  70] [G 0.49, acc. (on x_fake)   8]\n",
            "59988/60000 [D 0.18, acc. (on x_real and x_fake)  73] [G 0.47, acc. (on x_fake)   5]\n",
            "59989/60000 [D 0.19, acc. (on x_real and x_fake)  75] [G 0.49, acc. (on x_fake)  11]\n",
            "59990/60000 [D 0.19, acc. (on x_real and x_fake)  68] [G 0.46, acc. (on x_fake)  11]\n",
            "59991/60000 [D 0.15, acc. (on x_real and x_fake)  79] [G 0.49, acc. (on x_fake)  10]\n",
            "59992/60000 [D 0.18, acc. (on x_real and x_fake)  75] [G 0.48, acc. (on x_fake)  10]\n",
            "59993/60000 [D 0.19, acc. (on x_real and x_fake)  71] [G 0.50, acc. (on x_fake)  11]\n",
            "59994/60000 [D 0.17, acc. (on x_real and x_fake)  74] [G 0.48, acc. (on x_fake)  10]\n",
            "59995/60000 [D 0.16, acc. (on x_real and x_fake)  81] [G 0.49, acc. (on x_fake)  11]\n",
            "59996/60000 [D 0.21, acc. (on x_real and x_fake)  69] [G 0.46, acc. (on x_fake)  16]\n",
            "59997/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.48, acc. (on x_fake)  15]\n",
            "59998/60000 [D 0.18, acc. (on x_real and x_fake)  72] [G 0.46, acc. (on x_fake)  10]\n",
            "59999/60000 [D 0.19, acc. (on x_real and x_fake)  72] [G 0.47, acc. (on x_fake)  11]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 3"
      ],
      "metadata": {
        "id": "_4IERvg7QStL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Auto-encoder\n",
        "\n",
        "Auto-encoders are unsupervised deep learning approach which learns to compress the input and then regenerate the data with the original dimension. It is mainly used for dimensionality reduction and performs better than PCA (Principal Component Analysis). A basic auto-encoder has mainly 3 layers:\n",
        "\n",
        "1. Encoder: It takes an input image and compresses it to a latent space representation.\n",
        "\n",
        "2. Bottleneck: It represents the compressed input to be passed further in the layer.\n",
        "\n",
        "3. Decoder: It generates the input image again from the compressed image. The image generated will not be exactly same as input image but it will closely represent the input image.\n",
        "\n",
        "It can be used for anomaly detection, denoising images, and further more."
      ],
      "metadata": {
        "id": "lpS46Y1kQdXl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sample decompressed images generated from Auto-encoder.\n",
        "# get decoded image on test set.\n",
        "decoded_imgs = autoencoder_ae.predict(X_test_ae)\n",
        "plot_images(decoded_imgs.reshape(10000, 28, 28))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "B4FTLf1aQUPW",
        "outputId": "14741b16-614c-4db0-c476-01030a513488"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 9 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot loss of AE.\n",
        "plt.plot(autoencoder_history.history['loss'], label='train')\n",
        "plt.plot(autoencoder_history.history['val_loss'], label='test')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "ZvKSwEj3dVCI",
        "outputId": "bde6ce1e-7af6-4cc9-e0f8-83853ed78075"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Result: AE\n",
        "\n",
        "It can be seen that the image generated after performing Auto-encoding is similar to the original image but it is blur. The edges of the clothes/bags etc. are not clearly visible. Also, the input image has some patterns on t-shirt/shirt but that is not visible after auto-encoding. \n",
        "\n",
        "The loss curve shows that there was no overfitting as we used l1-regualiser as well to prevent it. It also shows that the reconstruction loss decreased over epochs which is a good sign as the output image would be similar to the input image and would not vary much."
      ],
      "metadata": {
        "id": "Cx-6Ph0rQ55c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VAE\n",
        "\n",
        "A variational auto-encoder can be used to generate a new image as it generates a latent space with similar images. It has a similar architecture as that of an Auto-encoder. It consists of an encoder and a decoder which minimises the reconstruction error. However, we encode it here to a distribution. Thus, the input is encoded as a distribution, then sampling is done over the latent space, then the decoder layer tries to reduce reconstruction error and backpropagates. The loss function apart from reconstruction error also contains regularisation term. Kulback-Leibler divergence is used to regularise the latent space by making sure the images encoded lie in the normal distribution and does not become overfit. "
      ],
      "metadata": {
        "id": "ckHfkNdILU6Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sample image generated from VAE.\n",
        "# encode and decode some data taken from the test set.\n",
        "encoded_imgs_vae = encoder_vae.predict(X_test_ae)\n",
        "decoded_imgs_vae = decoder_vae.predict(encoded_imgs_vae)\n",
        "plot_images(decoded_imgs_vae.reshape(10000, 28, 28))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "zvWhI4XsLTsP",
        "outputId": "a2d945bc-63a2-48e2-d68f-3a9a0adac2ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 9 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot loss of VAE.\n",
        "plt.plot(vae_history.history['loss'], label='train')\n",
        "plt.plot(vae_history.history['val_loss'], label='test')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "Gb9lKWMbPYtX",
        "outputId": "99dc46fe-23b3-486e-8664-9e04529692db"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de5RddX338fd3n9tcM5lbrhOYEDGAggEDYgUWispFRagVb1Ta8hTaWh98qrZ4ra5nrT5qK1rXU1FQHq0VKgWpdIk2QIlIUTCEYIJJCIFAJpkkk0nmPmfOOfv8nj9+e2bOJBkml5k5s2c+r7VmnTP77HP29+w589m//du/s7c55xARkfgJyl2AiIgcHwW4iEhMKcBFRGJKAS4iElMKcBGRmEpO58Kamppca2vrdC5SRCT2nnrqqf3OueZDp09rgLe2trJu3brpXKSISOyZ2UtHmq4uFBGRmFKAi4jElAJcRCSmprUPXETkWOXzedra2shms+UuZcpVVFTQ0tJCKpU6qvkV4CIyo7W1tVFbW0traytmVu5ypoxzjs7OTtra2li+fPlRPUddKCIyo2WzWRobG2d1eAOYGY2Njce0p6EAF5EZb7aH97BjfZ+xCPCHN+/l1rXby12GiMiMEosAX7u1g9t/+UK5yxCROaqrq4tvfvObx/y8K664gq6urimoyItFgCcCoxAWy12GiMxR4wV4oVB4xec98MADzJ8/f6rKiscolERgFHXhIBEpk5tvvpnt27ezatUqUqkUFRUV1NfXs2XLFp577jmuuuoqdu7cSTab5aabbuKGG24ARk8f0tfXx+WXX84FF1zA448/ztKlS/nJT35CZWXlCdUVmwAvFNUCF5nrvvgfz/K73T2T+ppnLJnH377rNa84z5e+9CU2bdrEhg0bWLt2Le94xzvYtGnTyHC/O+64g4aGBgYHBzn33HN5z3veQ2Nj45jX2LZtG3fddRe3334711xzDffeey/XXnvtCdUemwBXfovITHHeeeeNGav9jW98g/vuuw+AnTt3sm3btsMCfPny5axatQqA17/+9ezYseOE64hHgJta4CLChC3l6VJdXT1yf+3atTz00EP86le/oqqqiosvvviIY7kzmczI/UQiweDg4AnXEZuDmEXnv6kkIjLdamtr6e3tPeJj3d3d1NfXU1VVxZYtW/j1r389bXVN2AI3s2XAPwMLAQfc5pz7RzP7AvCnQEc066edcw9MRZGJwA9uD4uOZGJuDOgXkZmjsbGRN73pTbz2ta+lsrKShQsXjjx22WWX8a1vfYvTTz+dlStXcv75509bXUfThVIAPu6cW29mtcBTZvZg9NjXnHP/MHXleSMB7lw8+nxEZNa58847jzg9k8nws5/97IiPDfdzNzU1sWnTppHpn/jEJyalpgnz0DnXDrRH93vNbDOwdFKWfpRKW+AiIuIdUx+4mbUCZwNPRJP+0sx+a2Z3mFn9OM+5wczWmdm6jo6OI80yoaQCXETkMEcd4GZWA9wLfMw51wPcCqwAVuFb6F890vOcc7c551Y751Y3Nx92Tc6jK9IU4CIihzqqADezFD68f+ic+zGAc26vcy50zhWB24HzpqrI4QOXCnARkVETBrj58xt+F9jsnLulZPriktmuBjYd+tzJoha4iMjhjmZQx5uAPwQ2mtmGaNqngQ+Y2Sr80MIdwI1TUiElfeAaBy4iMmLCFrhz7jHnnDnnznLOrYp+HnDO/aFz7sxo+pXRaJWpKTIK8EKoABeR6Xe8p5MF+PrXv87AwMAkV+TF4puYGoUiIuU0UwM8Ft+LSagLRUTKqPR0sm9729tYsGABd999N0NDQ1x99dV88YtfpL+/n2uuuYa2tjbCMORzn/sce/fuZffu3bz5zW+mqamJRx55ZFLrileAqwUuMrf97GbYs3FyX3PRmXD5l15xltLTya5Zs4Z77rmHJ598EuccV155JY8++igdHR0sWbKEn/70p4A/R0pdXR233HILjzzyCE1NTZNbNzHpQkloFIqIzBBr1qxhzZo1nH322Zxzzjls2bKFbdu2ceaZZ/Lggw/yN3/zN/zyl7+krq5uymtRC1xE4mOClvJ0cM7xqU99ihtvPHzg3fr163nggQf47Gc/yyWXXMLnP//5Ka0lHi1wBbiIlFHp6WQvvfRS7rjjDvr6+gDYtWsX+/btY/fu3VRVVXHttdfyyU9+kvXr1x/23MkWqxZ4QQEuImVQejrZyy+/nA9+8IO88Y1vBKCmpoZ/+Zd/4fnnn+eTn/wkQRCQSqW49dZbAbjhhhu47LLLWLJkydw+iFnUKBQRKZNDTyd70003jfl9xYoVXHrppYc976Mf/Sgf/ehHp6SmWHWh6Is8IiKjYhHgycCXqRa4iMioWAR4IqpSfeAic9NcuR7usb7PmAR41AJXgIvMORUVFXR2ds76EHfO0dnZSUVFxVE/Jx4HMU2jUETmqpaWFtra2jjeK3rFSUVFBS0tLUc9fzwCXOPAReasVCrF8uXLy13GjBSTLhQFuIjIoeIV4LO8D0xE5FjEK8CLxTJXIiIyc8QiwEcv6FDmQkREZpBYBHigFriIyGFiEeBqgYuIHC4WAR6YWuAiIoeKRYDrosYiIoeLRYAHOh+4iMhhYhHgSZ0PXETkMLEIcF2RR0TkcLEKcJ2NUERkVDwCXGcjFBE5TCwCPAgMM7XARURKxSLAwbfC1QIXERkVnwAPTGcjFBEpEa8A11XpRURGxCvA1QIXERkRrwBXH7iIyIjYBHhSAS4iMkZsAjwwBbiISKnYBLha4CIiY8UmwAMFuIjIGLEJ8KRGoYiIjDFhgJvZMjN7xMx+Z2bPmtlN0fQGM3vQzLZFt/VTWmigb2KKiJQ6mhZ4Afi4c+4M4HzgI2Z2BnAz8LBz7lTg4ej3KZMMTOdCEREpMWGAO+fanXPro/u9wGZgKfBu4PvRbN8HrpqqIsGPQlELXERk1DH1gZtZK3A28ASw0DnXHj20B1g4znNuMLN1Zrauo6PjuAtNJnQQU0Sk1FEHuJnVAPcCH3PO9ZQ+5pxzwBHT1Tl3m3NutXNudXNz83EXmtA4cBGRMY4qwM0shQ/vHzrnfhxN3mtmi6PHFwP7pqZET1+lFxEZ62hGoRjwXWCzc+6WkofuB66L7l8H/GTyyxulABcRGSt5FPO8CfhDYKOZbYimfRr4EnC3mV0PvARcMzUlegpwEZGxJgxw59xjgI3z8CWTW874EoGRD4vTtTgRkRkvNt/ETASBhhGKiJSIT4DrosYiImPEJ8DVAhcRGSNGAa4WuIhIqdgEeDIIKBR1EFNEZFhsAjwIDDXARURGxSbAk4GpBS4iUiI2AZ4IDOW3iMio+AS4qQUuIlIqPgGeMPRFTBGRUfEJcDNCtcBFREbEJ8B1MisRkTEU4CIiMRWbAE8GRugU4CIiw2IT4IFa4CIiY8QmwJMKcBGRMWIT4IH5r9I7daOIiAAxCvBk4C8KpFa4iIgXmwAPogDXOcFFRLzYBPhwC7yoLhQRESBGAZ5QC1xEZIzYBbiuyiMi4sUuwNUCFxHxYhfgaoGLiHjxCXBTC1xEpFR8AlzjwEVExlCAi4jEVPwCXOPARUSAOAa4WuAiIkCMAlznQhERGSseAT7YRdXAbkABLiIyLB4B/vAXOf/h9wIKcBGRYfEI8HQ1iUI/oHHgIiLDYhLgtSTCLAlCnY1QRCQSjwDP1ABQTZZCqAAXEYG4BHh6NMDVBy4i4sUjwIdb4DaoL/KIiETiEeDpWgBqyBIWi2UuRkRkZpgwwM3sDjPbZ2abSqZ9wcx2mdmG6OeKKa2ytAWu/BYRAY6uBf494LIjTP+ac25V9PPA5JZ1iKgPXC1wEZFREwa4c+5R4MA01DK+kVEoaoGLiAw7kT7wvzSz30ZdLPXjzWRmN5jZOjNb19HRcXxLivrAqy1LQS1wERHg+AP8VmAFsApoB7463ozOuducc6udc6ubm5uPb2mZ0S4UfZFHRMQ7rgB3zu11zoXOuSJwO3De5JZ1iGQFzhJU26C+yCMiEjmuADezxSW/Xg1sGm/eSWGGS9dQrRa4iMiI5EQzmNldwMVAk5m1AX8LXGxmqwAH7ABunMIaAXCpamoYJKdvYoqIAEcR4M65Dxxh8nenoJZXriNdQ7VlySrARUSAuHwTEyDju1B0OlkRES8+AR61wHUyKxERLzYBHlTUUs0gA7mw3KWIiMwI8QnwTC21lqVrIF/uUkREZoTYBDiZGmosS9dgrtyViIjMCPEJ8HQN1QzSrRa4iAgQpwDP1JCiQN/AQLkrERGZEeIT4NEJrYYGustciIjIzBCfAI9OaFUY6C1zISIiM0N8Ajy6qEM41IvT+VBERGIU4FELvLI4SN9QoczFiIiUX3wCfPiyajaoseAiIsQwwKvRl3lERCBOAZ4paYHryzwiIjEK8OHrYqoFLiICxCnAK+fjLKDBeugaVICLiMQnwIMEVC9gAV10D6gLRUQkPgEOWO0iliS6OKguFBGReAU4tYtZHHSpD1xEhNgF+EKaOUi3RqGIiMQtwBcz33XT2z9Y7kpERMouZgG+CIBgYF+ZCxERKb+YBfhiANKDCnARkXgFeM1CAKqyHbo6vYjMefEK8KgF3shB9vZky1yMiEh5xSvAq5twlmChHWTnAV1aTUTmtngFeJAgrGpmIQfZeVAjUURkbotXgAPBvMUsCLrUAheROS+WAb400cXOgwpwEZnbYhfg1C5iIQdpO6AuFBGZ2+IX4PXLmed66D+wu9yViIiUVfwCvOVcAJb0P0uuUCxzMSIi5RO/AF+yiqIlOdu2sbtL3SgiMnfFL8BTlQw0vobXB8/pQKaIzGnxC3CAlvM4y16gbX9PuSsRESmbWAZ41Yo3Umk5Bl7eUO5SRETKJpYBHpz0BgBs12/KXImISPnEMsCpa6E32UhD17MUQo1EEZG5acIAN7M7zGyfmW0qmdZgZg+a2bbotn5qyzxcf8MZrORFnu/om+5Fi4jMCEfTAv8ecNkh024GHnbOnQo8HP0+rTLLzuZU28XGHXune9EiIjPChAHunHsUOHDI5HcD34/ufx+4apLrmlDdKa8naUX2Pf/0dC9aRGRGON4+8IXOufbo/h5g4XgzmtkNZrbOzNZ1dHQc5+IOFyxZBUC4+5lJe00RkTg54YOYzjkHjHt9M+fcbc651c651c3NzSe6uFHzTyabqKWpdzO92fzkva6ISEwcb4DvNbPFANHt9F9l2Ixc82s4w3bwyNbJa9mLiMTF8Qb4/cB10f3rgJ9MTjnHpqb19ZwW7OShTTvLsXgRkbI6mmGEdwG/AlaaWZuZXQ98CXibmW0D3hr9Pu2CUy6mghzh1ofI5sNylCAiUjbJiWZwzn1gnIcumeRajt2KN5NL13Pp4C95fPv/4C2njXssVURk1onnNzGHJVIkzryatwVP8cgzL5a7GhGRaRXvAAcSZ11DpeVwW35KWBx3MIyIyKwT+wBn2Rvor2rhXeEa1u049PtGIiKzV/wDPAhIvvHPeEOwhd8+ubbc1YiITJv4BziQOfc6Bq2Kk5/7Hv57RSIis9+sCHAq5rFz+Xt5S/gYTz6tizyIyNwwOwIcOPmdn6BoAd0P/X25SxERmRazJsAzDSexfenVXNz/c555dtPETxARiblZE+AArVd9BjNI3P8RXE/7xE8QEYmxWRXglc3LefKMz/Kq7LPk/+/5cOCFcpckIjJlZlWAA5z3no/xZ9VfI5fLUfz3j0BR18wUkdlp1gV4KhHw4Svfzhfz1xK8/Dj85jvlLklEZErMugAHeMtpC6k898OsDV9HuObz6koRkVlpVgY4wGfeeQb/r/F/MRBC7sd/oa4UEZl1Zm2AZ5IJPvfBt/J34XWk236Fu+9GCHXpNRGZPWZtgAO8akEtp779Rr6Sfx+28W64+zrIZ8tdlojIpJjVAQ7wxxcsp+21f87n8n8EW38Kd74X2tZBUVfwEZF4m/UBbmZ85Q/OYnPL+/hE4S8o7vgVfOcS+N47ICyUuzwRkeM26wMcoCKV4I4/PpcXlryTc4f+iSdP/St4+Vfw2C3lLk1E5LjNiQAHmFeR4p+vfwNnrzyFazauZl3tW3C/+DL84GpY+2V1qYhI7MyZAAeoySS5/cOr+evLVnJ9x/t5LH0hhb79sPbv4N+ug/xguUsUETlqE16VfrYxM/7i4lfRUl/F9XfPo5kMP3rDelqe+N/wrQvh4pvBAljxZqisL3e5IiLjmlMt8FJXvm4J9/z5GwG48NHTufWkrxIO9cO918M9fwzfvgh26+IQIjJzzdkABzirZT4P3HQhN160gq+9sJQL+r/E2ovuIvzQff6bm995K/ziK2O7Vvo7YevPQJduE5Eys+m8huTq1avdunXrpm15x2J7Rx9/9aMNPNPWzbKGSj510QIub7sF23QvJDKw/CI47R1+5ErXy/COW+Dc68tdtojMAWb2lHNu9WHTFeCjwqLjwd/t4Z8e2c7GXd2ct7yBj796H6uzvyax5T+geyfULIL6Vtj9NLzrH2H+Mlj6ekhVlrt8EZmlFODHICw67nzyZb75yPO0d2dprs1wzTmL+UBLBy2nnAmu6PvIe3f7JyQr4PR3weo/gfZn/OOveis0rxx90Z52GOqF5leX502JSGwpwI9DWHSs3bqPu558mf/aso+ig1XL5nPVqiX83kmVvCrZQdC7G7Y9CBvuhHz/2Bd49WWw6oNw4EV49O8hzMFVt8KZf1CeNyQisaQAP0H7erL8+4Zd3PvULrbu7QVgcV0F7zxrMRee2sx5C4pUvPwLaDkXgiRsvBse+0cY6vYvsOIt/kRaLz8Oy86H+pPh4Euw+Cw4+fdgoBMWnOEfCwLo2AovPQ5nXwuJVBnfuYiUmwJ8kjjneKlzgCd3HODnm/bw6HMdFIqO6nSCt56xkFXL5rNyUS0rF9bSmMz61ne6GhpfBYUh+O+vw3P/CX17oa7FD1UMh0YXUNXo5237zWhXzDu/DrWLIZH052/ZtQ6e/gGkquHCj0PtwvKtEBGZcgrwKdI/VGDdSwf52cZ21vxuLwf6cyOPLajNcPrieZyxZB4XvKqJ1a31ZJKJsS+Q7YGDL/rgfvnXsP0R2L/VHxitXw7/+WlwIWBQ1QBDfT7w0zV+g2AGNQshiF73zPf6vYDt/wVNp/qW//xW36oHPwyyZxfseAye/DbMa4E3/U8/n1r6IjOSAnwaOOfo6B1i695etrT3snlPD5vbe3l+Xy/50K/n2kyS1yydx5lL62iqyfDqRbWcsXgedZUpKlKJw1+0/RnY9RT07fOt9nQNLDoLVl7mp627AwYOQLEAgwfh+Qf984IUFKMLWCQroHqB/723ffS1l53vh0T27oZMne/Oqajz89Qvh5WXw+b/8BuJcz7sR99UN0Om1u8JFAuQqpjalSoiCvByGsgVeGzbfja399LZP8TTL3exdW8vucLYy7wta6jkzKV1NNdkaKjO0FiTprE6zakLa1jRXIOZTbywvc/6ES/LL4SDO3yrfv9zvo8dYOFr/dDH+uU+sAs52LYGnvs5dD4P2W4f0rufhqEeqGzwzxs8MLqMmkX+9Yp5Py8GhazfI6hu8s8Z6vF7AAtOh66dkKryexBdL/sNwILT/fh6i567Z5N/7cVn+a6l+lZoPs3Xnu32eyiP/oPfOznrfdC00r+/rT+FRWfC+R+BinnwzF3+PV/yeV/jxnvg1ZdC64V+WSIxpACfYZxz9GQLPLu7m+0d/XQP5Hh2dw9b9vTS2TdET3bsucrrKlO01FeyuK6ChfMqWFxXQToZMJALWTSvgpMaq1hWX0VVOkF1Jnnk1vyxGOr1Lf9lb/C/v7AWBrt890vndqhZ4Pv2u3cC5sfBJ9LQ3+HnS1f5UD6wHeaf5L/NOtAJ80/2ewoD+8cur2aRv+3bM35NyQof6u0lpzhoWOG7oFzJxtASkKmB3MDoXkjz6XDWNdCzG7Jd/nw3+5/ztWRqofUiWHK2f2ywy2+wst1+j6Sq0b+3RNofhwhSvrspkfYHrBMpv9ey/ge+O+vim/26K4Z+TylV7ddPqgp2PuGX2fom2Ps7v/7qW/26KQzBKRf7Ze/ZGA07PR2WnhNt6Ib8xUh6dsO8xf5v0/6M31g2ngrzlo52lR1q8CD85jtwypt991z7Bqg7Caobj/ojIeWjAI+ZfFjkYH+Ojr4hnt3Vw9M7u9jTPUh7d5Y9PVm6Bsa/vqcZLKmrpKk2Q3NNhlOaq6lMJUgnAxbXVVBbkaIiFVCRSjC/MkVjTYb5lSmCYApaqM4d3vJ1zgdlMfT3g4RvnQP07/cBtf85PxKn6VTfoj/4om9Jzz8JDrzgu40q6vzjHc/5PYhC1odaXQv8+E/9vJf+nT8e8MS3Yc9vfRdUdbPv/mlc4buW+jvgpf/2wzyHpWt9i36w6/DhoeNZ+Fq/hzHUc+TH07WQ653gRQw45H+ydokftbT3d6OjmsBvPIolG/pUFcxb4m9d0V8DtliA2kV+XQ7s9xuupldDxxbfbfaGG/3G+OAOP0//Pt89lqnx8xWGoOul0S+r7dsCVfV+PQ52+cd690B+wG9EFr3WP9bdBrk+WHYeLHyN3+i9+KhfN8mM3/uqmAdVTX6vzRV9F+H+bf75rRf4DXY4FO3d5fz9fNbPl+vz89W3+vfb9hu/sU7XQGYe1C31e5npko1nutp/vnav93uYFfPhde/z77d/n3/tRLROs91+VFhVk//sJTO+kZFMj/3bdO/yG8OK+f7zNm+JXx8HX/S3VQ3+vQ/1QMt5UNN8dJ+lQz8VCvDZJZsPyYdFKlMJ2ruzvHxggJ0HBsiFRTr7crzU2c+BgTx7ugfZsd9PfyWBQUN1hrrKJGHRUVeZorWpmobq9EhrfkFthobqNInAaKzOUFuRpOgc9VVpmmoyZJLB1GwEJoNz/h+/esGRW6nZHv8PV1kPlfNHD+g650OsmB8NxDB3+P1kxu8d9O6Bzff7AEpk4IVHotfv9qF28u/5QN3xmJ9/wel+OGlVoz9Yvf2//Aam5Vy/gXrpcT+tZ5cPpDOuhIZTfFfZzif8fDULoXOb35D17fF7O5bwYWSB71JLV8NFn4CN/+Zb8as+5I+XPP+Qry+RgQWn+ZBKpHw4d2z20+cv8y39YsHv8WS7/DIq6kZDK5nxNe3fBrn+0WkHXhhdx0HSB2yY86HsjvCZTGT8uj7SY2McsqGzhH+vxVe4cPmYDd4RNpRHksiMHSVWHQVwmPcbheEv841XV6kP3QOnvm3iZR6BAnwOc85hZgzmQtq7B+kfCskWQrL5kK6BPJ19Q3T259jfl6N7MEcyCDjQn2NHZz9dA3lyYZFi0VEoTvxZSScCMsmATCoR3QZUJBNkUtH0ZIKKVEB1Jslpi2ppqM4QFovUV6WpTCcohH451ZkErY3VVGeSpBMBqYSRCOzojgPI0ct2+5ZnVcMrj0IqDPlQPZpTRpTudfXt86GeH/B7RxXzRufJ9fkW8UCnn7+62XcDDfVA21N+vmTah+jIbSbqvqvxz+/c7rualp7jN1KFIb8x7nrJ71XkB/3GItcfHUtpgCXn+GMtB16ALT/1e3i1C30gFwt+Q5Cuhl3r/d7Zwtf4wO5tjwYBmF9XQ71+D7D1Il/LwRej7q0lfs+gdrHvugrz/n03rBh9/8doSgLczHYAvUAIFI60gFIK8PhyztHZn6N7ME8hdOzvG6JvqEDCjAP9OTr7cwwVQoYKRbJ5fzuULzJUCMlGt36av+0ayLOnJ3tMNZhBKhGMBHpVOkljTZqqdIJ0MjGy8UgnA5KBkUwYySAgmTBqMknmVaTozxXIJBO01FeSSQaYGYH51/b3jUwyoDKVoCKV8Ldp/3tlKkFgxmA+JBHYyPNFptp4AT4ZF3R4s3Nu/8SzSZyZGU01GZpqMgCspPaEX/NAf47+oQJm/v5QoUgyMFKJgK6BPC8d6GcwF1IoOnKFIoWwyFBYJF9w5MMi/UMFOvtzDOZCugfz5ApFcoWQXFgcackXovt9ucKknwE4MKhOJ6nK+LAvhI5MMqCmwndDpZMBDVVp0smARGAkAyMR+I1LIuF/TwbByPGIwKB3yO/i+42U3xj5jZZfL2OmJUenpaLHk8Ho/XTSv25FKqDo4GB/jupMcuR4h3OOooPETO32kgnNuSvyyMzRUJ2modofFGqprzrs8QtomrRlhUVHf65AVSrBQD6kvStLoVjEOSg6N3JbdER7DSGDuSKD+ZDBfEg2528LYZGqjA/owVxIf67AYPRYIjCGCkX6sgWS0f327iz5sEjoHGHRUQij26IjLBbJh45sPhzpnkonAwzIhcUpO+V8MjDqq9P0DxUYzIcsqM0QFqE3mydVshczfJtOBiTMCAIbc5sIhu/7jUBgfq9neOOTTBhh0a/TVMJYNK+SXOi77UbmjzZmCRvdwCUCRjZ0wciGb/QnGT13eK/JiPagGN2bGt54VaYSpBKjG9DS2n2XnP8yXj7a+A53/aWTAcEhe1fJwE58dNckO9EAd8AaM3PAt51zt01CTSKTLhEY8yp8H++8RMC8RTPrW6eFsEjR+eApnZYPHbmwSD76yRWGb/1eSC4ski8UyUd7G/noOcPzZvMh2ej7BvVVKQZyIfv7hujsy1GVTlKd8QfBUwm/fvKhY6gQ+r2Z0HeD5cJiFMR+4+M3QEVyIUeY7uvIFYoUio4gCsuhQsj+vhyJwKirTOEOeU54lMdYys1vEMwfpozKdfguxmGJaC+ytAsvGRj/5/fP4rzlDZNaz4kG+AXOuV1mtgB40My2OOceLZ3BzG4AbgA46aSTTnBxIrNTMnH4yJhkIiCZgEpmVqvveA0VQpJB8IpdNsMHy4suCvbQETq/wRgO/OGf4eB0bjhEweEoFv0w3MF8yGDOj9Yaeb3h1w7dyB5XdSZJKrCRDdbw8ZpD94By0dDe4Q3NcKt/9L6vIyz6DWghdOSjuguhoyYz+R0eJ/SKzrld0e0+M7sPOA949JB5bgNuA38Q80SWJyLxddh5gI4gCIy0+uSP2nFfE9PMqs2sdvg+8HZg02QVJiIir+xEWuALgfuiYVRJ4E7n3M8npSoREZnQcQe4c+4F4HWTWIuIiByD40Omb3QAAAT4SURBVO5CERGR8lKAi4jElAJcRCSmFOAiIjGlABcRialpPZ2smXUALx3n05uAmXjSrJlaF8zc2lTXsZmpdcHMrW221XWyc+6wq0FMa4CfCDNbN9HpasthptYFM7c21XVsZmpdMHNrmyt1qQtFRCSmFOAiIjEVpwCfqaeqnal1wcytTXUdm5laF8zc2uZEXbHpAxcRkbHi1AIXEZESCnARkZiKRYCb2WVmttXMnjezm8tYxzIze8TMfmdmz5rZTdH0L5jZLjPbEP1cUYbadpjZxmj566JpDWb2oJlti27rp7mmlSXrZIOZ9ZjZx8q1vszsDjPbZ2abSqYdcR2Z943oM/dbMztnmuv6ezPbEi37PjObH01vNbPBknX3rWmua9y/nZl9KlpfW83s0mmu60clNe0wsw3R9OlcX+Plw9R9xvwliWbuD5AAtgOnAGngGeCMMtWyGDgnul8LPAecAXwB+ESZ19MOoOmQaV8Bbo7u3wx8ucx/xz3AyeVaX8BFwDnAponWEXAF8DP8lbLOB56Y5rreDiSj+18uqau1dL4yrK8j/u2i/4NngAywPPqfTUxXXYc8/lXg82VYX+Plw5R9xuLQAj8PeN4594JzLgf8K/DuchTinGt3zq2P7vcCm4Gl5ajlKL0b+H50//vAVWWs5RJgu3PueL+Je8Kcv17rgUMmj7eO3g38s/N+Dcw3s8XTVZdzbo1zrhD9+mugZSqWfax1vYJ3A//qnBtyzr0IPI//353WusxfYeYa4K6pWPYreYV8mLLPWBwCfCmws+T3NmZAaJpZK3A28EQ06S+j3aA7prurIuKANWb2lPkLSQMsdM61R/f34K+iVC7vZ+w/VbnX17Dx1tFM+tz9Cb6lNmy5mT1tZr8wswvLUM+R/nYzZX1dCOx1zm0rmTbt6+uQfJiyz1gcAnzGMbMa4F7gY865HuBWYAWwCmjH78JNtwucc+cAlwMfMbOLSh90fp+tLGNGzSwNXAn8WzRpJqyvw5RzHY3HzD4DFIAfRpPagZOcc2cDfwXcaWbzprGkGfm3K/EBxjYUpn19HSEfRkz2ZywOAb4LWFbye0s0rSzMLIX/4/zQOfdjAOfcXudc6JwrArczRbuOr8Q5tyu63QfcF9Wwd3iXLLrdN911RS4H1jvn9kY1ln19lRhvHZX9c2dmfwS8E/hQ9I9P1EXRGd1/Ct/X/OrpqukV/nYzYX0lgd8HfjQ8bbrX15HygSn8jMUhwH8DnGpmy6OW3PuB+8tRSNS/9l1gs3PulpLppf1WVwObDn3uFNdVbWa1w/fxB8A24dfTddFs1wE/mc66SoxpFZV7fR1ivHV0P/DhaKTA+UB3yW7wlDOzy4C/Bq50zg2UTG82s0R0/xTgVOCFaaxrvL/d/cD7zSxjZsujup6crroibwW2OOfahidM5/oaLx+Yys/YdBydnYSju1fgj+huBz5TxjouwO/+/BbYEP1cAfwA2BhNvx9YPM11nYIfAfAM8OzwOgIagYeBbcBDQEMZ1lk10AnUlUwry/rCb0TagTy+v/H68dYRfmTAP0WfuY3A6mmu63l8/+jw5+xb0bzvif7GG4D1wLumua5x/3bAZ6L1tRW4fDrriqZ/D/izQ+adzvU1Xj5M2WdMX6UXEYmpOHShiIjIESjARURiSgEuIhJTCnARkZhSgIuIxJQCXEQkphTgIiIx9f8Bu4JrZEBs7ykAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Result: VAE\n",
        "\n",
        "It is observed that the output image generated is similar to the input image but is blurry. However, it is more clear than an Auto-encoder but still the edges are not sharp. The patterns on clothes are somewhat visible but still not that clear. Also in comparison to AE, the image is slightly light while AE has more dark color which makes the patterns on clothes invisible.\n",
        "\n",
        "The loss curve shows that the reconstruction loss decreased over epochs which is a good thing as the new image does not lie far from the original image.\n",
        "\n",
        "A smooth latent space is generated which was not the case in auto-encoder. It is generated with the help of distribution, mean and standard deviation which ensures that the image generated is similar to the input image but deviates to some extent when required to generate some new features in the latent space."
      ],
      "metadata": {
        "id": "28LvSPTjUtIu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GAN\n",
        "\n",
        "A generative adversarial network has a generative model and a discriminator model. The generative model generates images and tries to fool the discriminator model. Discriminator model classifies the image as real or fake. If the image is fake then generator will create a new image and if the discriminator classifies it as real image then the image is similar to input image."
      ],
      "metadata": {
        "id": "piM3GXMbeLu9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the sample image generated from GAN.\n",
        "img = mpimg.imread('gan_mnist.png')\n",
        "imgplot = plt.imshow(img)\n",
        "plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "6CUKMvqmeKxS",
        "outputId": "bddef58d-bd4d-4337-b58a-ff6b77f248d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Result: GAN\n",
        "\n",
        "The images generated from GAN looks reasonable. Even though the quality of image is not the same as that of the input, but the image is closely similar to the input image. It performed better than the other two models in the sense that the edges are visible and is not a blur. With more iterations, the image could have been more similar to the reality. However, in comparison to other models it is more creative and real-looking. Some patterns on shirt are also visible."
      ],
      "metadata": {
        "id": "gqXPjW9OXrwW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Discussion on performance of models\n",
        "\n",
        "We can see that images generated from GAN are more real-world like in comparison to others. Next VAE performed better than AE. We also know that GAN and VAE are the only generative algorithms which are capable of learning new features and generating new images. However, AE only does dimensionality reduction and does not generate any new images. \n",
        "\n",
        "The performance of VAE was better than AE in terms of image quality because instead of simply compressing the image, VAE learnt the input image characteristics. This could be the size of product whether it's a bad or shoes or shirt, is it long-sleeve or short-sleeve etc. This is done by using mean and standard deviation. For each feature like shirts/tops etc. a probability distribution is created which learns how likely a feature's value like shirt's sleeve length is. Thus, the new samples generated mixes these values and does not lie far from the original image.\n",
        "\n",
        "The performance of GAN was even better than VAE because it generated real-like images and is based on a generator-discriminator model. The discriminator acts as a supervised model which learns real and fake images during training. The task of generator is to fool the discriminator and in order to do so it generates more real-like images. Hence, the image generated by GAN are more close to input image. This discriminator model is not present in any other model, thus the images are not real-world like. \n",
        "\n",
        "\n",
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "OdnT7TS5bD5k"
      }
    }
  ]
}